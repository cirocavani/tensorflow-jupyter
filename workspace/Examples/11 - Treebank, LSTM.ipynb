{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "https://www.tensorflow.org/versions/r0.11/tutorials/recurrent/index.html\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/tree/r0.11/tensorflow/models/rnn/ptb\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/models/rnn/ptb/ptb_word_lm.py\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/models/rnn/ptb/reader.py\n",
    "\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "https://arxiv.org/abs/1409.2329\n",
    "\n",
    "http://www.cis.upenn.edu/~treebank/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking treebank dataset...\n",
      "Extracting ./simple-examples/data/ptb.test.txt\n",
      "Extracting ./simple-examples/data/ptb.train.txt\n",
      "Extracting ./simple-examples/data/ptb.valid.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "HOME_DIR = 'treebank'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "\n",
    "print('Unpacking treebank dataset...')\n",
    "\n",
    "TAR_FILE = 'simple-examples.tgz'\n",
    "TAR_PATH = os.path.join(DATA_DIR, TAR_FILE)\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets.base import maybe_download\n",
    "maybe_download(TAR_FILE, DATA_DIR, 'http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz')\n",
    "\n",
    "def extract(tar, filename, dst_path):\n",
    "    print('Extracting', filename)\n",
    "    dst_file = os.path.join(dst_path, os.path.basename(filename))\n",
    "    with open(dst_file, 'wb') as fout:\n",
    "        fin = tar.extractfile(filename)\n",
    "        shutil.copyfileobj(fin, fout)\n",
    "\n",
    "with tarfile.open(TAR_PATH, mode='r:gz') as t:\n",
    "    extract(t, './simple-examples/data/ptb.test.txt', DATA_DIR)\n",
    "    extract(t, './simple-examples/data/ptb.train.txt', DATA_DIR)\n",
    "    extract(t, './simple-examples/data/ptb.valid.txt', DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 929589\n",
      "Validation size: 73760\n",
      "Test size: 82430\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.models.rnn.ptb import reader\n",
    "\n",
    "raw_data = reader.ptb_raw_data(DATA_DIR)\n",
    "train_data, valid_data, test_data, _ = raw_data\n",
    "\n",
    "print(\"Train size:\", len(train_data))\n",
    "print(\"Validation size:\", len(valid_data))\n",
    "print(\"Test size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Small config\n",
    "init_scale = 0.1\n",
    "learning_rate = 1.0\n",
    "max_grad_norm = 5\n",
    "num_layers = 2\n",
    "num_steps = 20\n",
    "hidden_size = 200\n",
    "max_epoch = 4\n",
    "max_max_epoch = 13\n",
    "keep_prob = 1.0\n",
    "lr_decay = 0.5\n",
    "batch_size = 20\n",
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    initializer = tf.random_uniform_initializer(-init_scale, init_scale)\n",
    "    \n",
    "    with tf.variable_scope(\"model\", reuse=None, initializer=initializer):\n",
    "        size = hidden_size\n",
    "        \n",
    "        input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "        targets = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "\n",
    "        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(size, forget_bias=0.0, state_is_tuple=True)\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * num_layers, state_is_tuple=True)\n",
    "        \n",
    "        initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "        \n",
    "        embedding = tf.get_variable(\"embedding\", [vocab_size, size], dtype=tf.float32)\n",
    "        inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "        \n",
    "        outputs = []\n",
    "        state = initial_state\n",
    "        with tf.variable_scope(\"RNN\"):\n",
    "            for time_step in range(num_steps):\n",
    "                if time_step > 0: tf.get_variable_scope().reuse_variables()\n",
    "                (cell_output, state) = cell(inputs[:, time_step, :], state)\n",
    "                outputs.append(cell_output)\n",
    "\n",
    "        output = tf.reshape(tf.concat(1, outputs), [-1, size])\n",
    "        softmax_w = tf.get_variable(\"softmax_w\", [size, vocab_size], dtype=tf.float32)\n",
    "        softmax_b = tf.get_variable(\"softmax_b\", [vocab_size], dtype=tf.float32)\n",
    "        logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        \n",
    "        loss = tf.nn.seq2seq.sequence_loss_by_example(\n",
    "            [logits],\n",
    "            [tf.reshape(targets, [-1])],\n",
    "            [tf.ones([batch_size * num_steps], dtype=tf.float32)])\n",
    "        \n",
    "        cost = tf.reduce_sum(loss) / batch_size\n",
    "        final_state = state\n",
    "\n",
    "        lr = tf.Variable(0.0, trainable=False)\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "        train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "        new_lr = tf.placeholder(tf.float32, shape=[], name=\"new_learning_rate\")\n",
    "        lr_update = tf.assign(lr, new_lr)\n",
    "        \n",
    "    init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 1 Learning rate: 1.000\n",
      "0.004 perplexity: 5390.795 speed: 949 wps\n",
      "0.104 perplexity: 829.494 speed: 994 wps\n",
      "0.204 perplexity: 616.211 speed: 1004 wps\n",
      "0.304 perplexity: 499.248 speed: 1008 wps\n",
      "0.404 perplexity: 432.527 speed: 1011 wps\n",
      "0.504 perplexity: 387.496 speed: 1010 wps\n",
      "0.604 perplexity: 349.120 speed: 1010 wps\n",
      "0.703 perplexity: 322.719 speed: 1011 wps\n",
      "0.803 perplexity: 301.941 speed: 1011 wps\n",
      "0.903 perplexity: 282.687 speed: 1011 wps\n",
      "Epoch: 1 Train Perplexity: 268.426\n",
      "Epoch: 1 Valid Perplexity: 178.786\n",
      "Epoch: 2 Learning rate: 1.000\n",
      "0.004 perplexity: 211.240 speed: 991 wps\n",
      "0.104 perplexity: 150.767 speed: 1008 wps\n",
      "0.204 perplexity: 157.818 speed: 1011 wps\n",
      "0.304 perplexity: 152.909 speed: 1011 wps\n",
      "0.404 perplexity: 149.949 speed: 1011 wps\n",
      "0.504 perplexity: 147.430 speed: 1011 wps\n",
      "0.604 perplexity: 142.870 speed: 1011 wps\n",
      "0.703 perplexity: 140.730 speed: 1012 wps\n",
      "0.803 perplexity: 138.650 speed: 1011 wps\n",
      "0.903 perplexity: 134.994 speed: 1011 wps\n",
      "Epoch: 2 Train Perplexity: 132.901\n",
      "Epoch: 2 Valid Perplexity: 143.139\n",
      "Epoch: 3 Learning rate: 1.000\n",
      "0.004 perplexity: 145.081 speed: 993 wps\n",
      "0.104 perplexity: 104.564 speed: 1007 wps\n",
      "0.204 perplexity: 113.434 speed: 1009 wps\n",
      "0.304 perplexity: 110.779 speed: 1011 wps\n",
      "0.404 perplexity: 109.780 speed: 1012 wps\n",
      "0.504 perplexity: 108.835 speed: 1012 wps\n",
      "0.604 perplexity: 106.284 speed: 1013 wps\n",
      "0.703 perplexity: 105.589 speed: 1014 wps\n",
      "0.803 perplexity: 104.909 speed: 1014 wps\n",
      "0.903 perplexity: 102.712 speed: 1015 wps\n",
      "Epoch: 3 Train Perplexity: 101.742\n",
      "Epoch: 3 Valid Perplexity: 132.148\n",
      "Epoch: 4 Learning rate: 1.000\n",
      "0.004 perplexity: 115.947 speed: 962 wps\n",
      "0.104 perplexity: 84.609 speed: 1014 wps\n",
      "0.204 perplexity: 92.666 speed: 1016 wps\n",
      "0.304 perplexity: 90.625 speed: 1017 wps\n",
      "0.404 perplexity: 90.206 speed: 1015 wps\n",
      "0.504 perplexity: 89.780 speed: 1015 wps\n",
      "0.604 perplexity: 88.006 speed: 1015 wps\n",
      "0.703 perplexity: 87.711 speed: 1015 wps\n",
      "0.803 perplexity: 87.423 speed: 1016 wps\n",
      "0.903 perplexity: 85.829 speed: 1016 wps\n",
      "Epoch: 4 Train Perplexity: 85.268\n",
      "Epoch: 4 Valid Perplexity: 126.649\n",
      "Epoch: 5 Learning rate: 0.500\n",
      "0.004 perplexity: 97.507 speed: 1006 wps\n",
      "0.104 perplexity: 70.832 speed: 1017 wps\n",
      "0.204 perplexity: 76.531 speed: 1018 wps\n",
      "0.304 perplexity: 73.737 speed: 1017 wps\n",
      "0.404 perplexity: 72.640 speed: 1020 wps\n",
      "0.504 perplexity: 71.574 speed: 1019 wps\n",
      "0.604 perplexity: 69.496 speed: 1018 wps\n",
      "0.703 perplexity: 68.662 speed: 1018 wps\n",
      "0.803 perplexity: 67.872 speed: 1018 wps\n",
      "0.903 perplexity: 66.013 speed: 1018 wps\n",
      "Epoch: 5 Train Perplexity: 65.010\n",
      "Epoch: 5 Valid Perplexity: 117.703\n",
      "Epoch: 6 Learning rate: 0.250\n",
      "0.004 perplexity: 78.984 speed: 1006 wps\n",
      "0.104 perplexity: 58.290 speed: 1016 wps\n",
      "0.204 perplexity: 63.219 speed: 1018 wps\n",
      "0.304 perplexity: 60.806 speed: 1018 wps\n",
      "0.404 perplexity: 59.797 speed: 1018 wps\n",
      "0.504 perplexity: 58.831 speed: 1018 wps\n",
      "0.604 perplexity: 57.049 speed: 1017 wps\n",
      "0.703 perplexity: 56.259 speed: 1017 wps\n",
      "0.803 perplexity: 55.460 speed: 1017 wps\n",
      "0.903 perplexity: 53.769 speed: 1017 wps\n",
      "Epoch: 6 Train Perplexity: 52.801\n",
      "Epoch: 6 Valid Perplexity: 117.695\n",
      "Epoch: 7 Learning rate: 0.125\n",
      "0.004 perplexity: 71.127 speed: 1000 wps\n",
      "0.104 perplexity: 51.884 speed: 1014 wps\n",
      "0.204 perplexity: 56.317 speed: 1014 wps\n",
      "0.304 perplexity: 54.068 speed: 1013 wps\n",
      "0.404 perplexity: 53.116 speed: 1015 wps\n",
      "0.504 perplexity: 52.216 speed: 1015 wps\n",
      "0.604 perplexity: 50.594 speed: 1015 wps\n",
      "0.703 perplexity: 49.831 speed: 1015 wps\n",
      "0.803 perplexity: 49.070 speed: 1015 wps\n",
      "0.903 perplexity: 47.482 speed: 1015 wps\n",
      "Epoch: 7 Train Perplexity: 46.560\n",
      "Epoch: 7 Valid Perplexity: 118.926\n",
      "Epoch: 8 Learning rate: 0.062\n",
      "0.004 perplexity: 66.585 speed: 999 wps\n",
      "0.104 perplexity: 48.492 speed: 1015 wps\n",
      "0.204 perplexity: 52.803 speed: 1013 wps\n",
      "0.304 perplexity: 50.648 speed: 998 wps\n",
      "0.404 perplexity: 49.734 speed: 1001 wps\n",
      "0.504 perplexity: 48.888 speed: 1003 wps\n",
      "0.604 perplexity: 47.342 speed: 1005 wps\n",
      "0.703 perplexity: 46.590 speed: 1007 wps\n",
      "0.803 perplexity: 45.845 speed: 1008 wps\n",
      "0.903 perplexity: 44.316 speed: 1010 wps\n",
      "Epoch: 8 Train Perplexity: 43.414\n",
      "Epoch: 8 Valid Perplexity: 119.851\n",
      "Epoch: 9 Learning rate: 0.031\n",
      "0.004 perplexity: 64.162 speed: 1000 wps\n",
      "0.104 perplexity: 46.749 speed: 1019 wps\n",
      "0.204 perplexity: 50.979 speed: 1019 wps\n",
      "0.304 perplexity: 48.874 speed: 1018 wps\n",
      "0.404 perplexity: 47.992 speed: 1017 wps\n",
      "0.504 perplexity: 47.174 speed: 1017 wps\n",
      "0.604 perplexity: 45.668 speed: 1017 wps\n",
      "0.703 perplexity: 44.917 speed: 1017 wps\n",
      "0.803 perplexity: 44.171 speed: 1018 wps\n",
      "0.903 perplexity: 42.674 speed: 1018 wps\n",
      "Epoch: 9 Train Perplexity: 41.778\n",
      "Epoch: 9 Valid Perplexity: 120.042\n",
      "Epoch: 10 Learning rate: 0.016\n",
      "0.004 perplexity: 62.853 speed: 1003 wps\n",
      "0.104 perplexity: 45.782 speed: 1007 wps\n",
      "0.204 perplexity: 49.962 speed: 1012 wps\n",
      "0.304 perplexity: 47.886 speed: 1015 wps\n",
      "0.404 perplexity: 47.035 speed: 1016 wps\n",
      "0.504 perplexity: 46.231 speed: 1017 wps\n",
      "0.604 perplexity: 44.749 speed: 1017 wps\n",
      "0.703 perplexity: 44.000 speed: 1018 wps\n",
      "0.803 perplexity: 43.252 speed: 1018 wps\n",
      "0.903 perplexity: 41.775 speed: 1020 wps\n",
      "Epoch: 10 Train Perplexity: 40.884\n",
      "Epoch: 10 Valid Perplexity: 119.757\n",
      "Epoch: 11 Learning rate: 0.008\n",
      "0.004 perplexity: 62.038 speed: 1002 wps\n",
      "0.104 perplexity: 45.201 speed: 1015 wps\n",
      "0.204 perplexity: 49.357 speed: 1018 wps\n",
      "0.304 perplexity: 47.299 speed: 1019 wps\n",
      "0.404 perplexity: 46.470 speed: 1019 wps\n",
      "0.504 perplexity: 45.679 speed: 1020 wps\n",
      "0.604 perplexity: 44.216 speed: 1020 wps\n",
      "0.703 perplexity: 43.472 speed: 1020 wps\n",
      "0.803 perplexity: 42.727 speed: 1020 wps\n",
      "0.903 perplexity: 41.263 speed: 1020 wps\n",
      "Epoch: 11 Train Perplexity: 40.378\n",
      "Epoch: 11 Valid Perplexity: 119.360\n",
      "Epoch: 12 Learning rate: 0.004\n",
      "0.004 perplexity: 61.553 speed: 1006 wps\n",
      "0.104 perplexity: 44.860 speed: 1018 wps\n",
      "0.204 perplexity: 49.004 speed: 1019 wps\n",
      "0.304 perplexity: 46.961 speed: 1019 wps\n",
      "0.404 perplexity: 46.147 speed: 1020 wps\n",
      "0.504 perplexity: 45.365 speed: 1020 wps\n",
      "0.604 perplexity: 43.916 speed: 1021 wps\n",
      "0.703 perplexity: 43.177 speed: 1020 wps\n",
      "0.803 perplexity: 42.436 speed: 1020 wps\n",
      "0.903 perplexity: 40.980 speed: 1020 wps\n",
      "Epoch: 12 Train Perplexity: 40.100\n",
      "Epoch: 12 Valid Perplexity: 119.048\n",
      "Epoch: 13 Learning rate: 0.002\n",
      "0.004 perplexity: 61.269 speed: 1005 wps\n",
      "0.104 perplexity: 44.663 speed: 1021 wps\n",
      "0.204 perplexity: 48.799 speed: 1019 wps\n",
      "0.304 perplexity: 46.771 speed: 1019 wps\n",
      "0.404 perplexity: 45.967 speed: 1020 wps\n",
      "0.504 perplexity: 45.193 speed: 1020 wps\n",
      "0.604 perplexity: 43.753 speed: 1020 wps\n",
      "0.703 perplexity: 43.017 speed: 1020 wps\n",
      "0.803 perplexity: 42.278 speed: 1020 wps\n",
      "0.903 perplexity: 40.828 speed: 1020 wps\n",
      "Epoch: 13 Train Perplexity: 39.952\n",
      "Epoch: 13 Valid Perplexity: 118.866\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 1) for Tensor u'model/Placeholder_1:0', which has shape '(20, 20)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-165e37696d32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mtest_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Perplexity: %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtest_perplexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-165e37696d32>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(session, data, eval_op, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mbatch_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mcosts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0miters\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cavani/Source/tensorflow-jupyter/deps/tensorflow-0.11/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cavani/Source/tensorflow-jupyter/deps/tensorflow-0.11/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    895\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 1) for Tensor u'model/Placeholder_1:0', which has shape '(20, 20)'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def run_epoch(session, data, eval_op, verbose):\n",
    "    epoch_size = ((len(data) // batch_size) - 1) // num_steps\n",
    "    start_time = time.time()\n",
    "    costs = 0.0\n",
    "    iters = 0\n",
    "    state = session.run(initial_state)\n",
    "\n",
    "    for step, (x, y) in enumerate(reader.ptb_iterator(data, batch_size, num_steps)):\n",
    "        fetches = [cost, final_state, eval_op]\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[input_data] = x\n",
    "        feed_dict[targets] = y\n",
    "        for k, (c, h) in enumerate(initial_state):\n",
    "            feed_dict[c] = state[k].c\n",
    "            feed_dict[h] = state[k].h\n",
    "\n",
    "        batch_cost, state, _ = session.run(fetches, feed_dict)\n",
    "        costs += batch_cost\n",
    "        iters += num_steps\n",
    "\n",
    "        if verbose and step % (epoch_size // 10) == 10:\n",
    "            print(\"%.3f perplexity: %.3f speed: %.0f wps\" % (\n",
    "                step * 1.0 / epoch_size,\n",
    "                np.exp(costs / iters),\n",
    "                iters * batch_size / (time.time() - start_time)))\n",
    "\n",
    "    return np.exp(costs / iters)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    init.run()\n",
    "    print(\"Initialized\")\n",
    "\n",
    "    for i in range(max_max_epoch):\n",
    "        decay = lr_decay ** max(i + 1 - max_epoch, 0.0)\n",
    "        lr_value = learning_rate * decay\n",
    "        session.run(lr_update, feed_dict={new_lr: lr_value})\n",
    "        \n",
    "        print(\"Epoch: %d Learning rate: %.3f\" % (i + 1, session.run(lr)))\n",
    "        \n",
    "        train_perplexity = run_epoch(session, train_data, train_op, True)\n",
    "        print(\"Epoch: %d Train Perplexity: %.3f\" % (i + 1, train_perplexity))\n",
    "        \n",
    "        valid_perplexity = run_epoch(session, valid_data, tf.no_op(), False)\n",
    "        print(\"Epoch: %d Valid Perplexity: %.3f\" % (i + 1, valid_perplexity))\n",
    "        \n",
    "    #batch_size = 1\n",
    "    #num_steps = 1\n",
    "    #test_perplexity = run_epoch(session, test_data, tf.no_op(), False)\n",
    "    #print(\"Test Perplexity: %.3f\" % test_perplexity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 0.11 (CPU, Python 2)",
   "language": "python",
   "name": "tensorflow-0.11-py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
