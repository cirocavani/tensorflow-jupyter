{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Representations of Sentences and Documents\n",
    "\n",
    "https://arxiv.org/abs/1405.4053\n",
    "\n",
    "http://research.google.com/pubs/pub44894.html\n",
    "\n",
    "http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python 3.6.1\n",
    "from typing import Dict, List, Deque, Tuple, Iterable, Callable\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking Stanford Sentiment Treebank dataset...\n",
      "Extracting stanfordSentimentTreebank/datasetSentences.txt\n",
      "Extracting stanfordSentimentTreebank/datasetSplit.txt\n",
      "Extracting stanfordSentimentTreebank/dictionary.txt\n",
      "Extracting stanfordSentimentTreebank/original_rt_snippets.txt\n",
      "Extracting stanfordSentimentTreebank/README.txt\n",
      "Extracting stanfordSentimentTreebank/sentiment_labels.txt\n",
      "Extracting stanfordSentimentTreebank/SOStr.txt\n",
      "Extracting stanfordSentimentTreebank/STree.txt\n"
     ]
    }
   ],
   "source": [
    "HOME_DIR = 'rotten_tomatoes'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "DATASET_URL = 'http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip'\n",
    "DATASET_FILENAME = DATASET_URL.split('/')[-1]\n",
    "DATASET_PACKAGE = os.path.join(DATA_DIR, DATASET_FILENAME)\n",
    "\n",
    "package_missing = not os.path.isfile(DATASET_PACKAGE)\n",
    "\n",
    "if package_missing:\n",
    "    print('Downloading {}...'.format(DATASET_FILENAME))\n",
    "    r = requests.get(DATASET_URL, stream=True)\n",
    "    with open(DATASET_PACKAGE, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=32768):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    print('Done!')\n",
    "\n",
    "print('Unpacking Stanford Sentiment Treebank dataset...')\n",
    "\n",
    "FILE_PATTERN = re.compile(r'^stanfordSentimentTreebank/.+\\.txt$')\n",
    "\n",
    "def extract(zip_file, filename, dst_path):\n",
    "    print('Extracting', filename)\n",
    "    dst_file = os.path.join(dst_path, os.path.basename(filename))\n",
    "    with open(dst_file, 'wb') as fout:\n",
    "        fin = zip_file.open(filename)\n",
    "        shutil.copyfileobj(fin, fout)\n",
    "\n",
    "with zipfile.ZipFile(DATASET_PACKAGE) as f:\n",
    "    files = list(name for name in f.namelist() if FILE_PATTERN.match(name))\n",
    "    for filename in files:\n",
    "        extract(f, filename, DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show(file, lines=10):\n",
    "    with open(file) as f:\n",
    "        for _ in range(lines):\n",
    "            print(next(f).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_index\tsentence\n",
      "1\tThe Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
      "2\tThe gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\/director Peter Jackson 's expanded vision of J.R.R. Tolkien 's Middle-earth .\n",
      "3\tEffective but too-tepid biopic\n",
      "4\tIf you sometimes like to go to the movies to have fun , Wasabi is a good place to start .\n",
      "5\tEmerges as something rare , an issue movie that 's so honest and keenly observed that it does n't feel like one .\n",
      "6\tThe film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "7\tOffers that rare combination of entertainment and education .\n",
      "8\tPerhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "9\tSteers turns in a snappy screenplay that curls at the edges ; it 's so clever you want to hate it .\n"
     ]
    }
   ],
   "source": [
    "SENTENCES_FILE = os.path.join(DATA_DIR, 'datasetSentences.txt')\n",
    "show(SENTENCES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!|0\n",
      "! '|22935\n",
      "! ''|18235\n",
      "! Alas|179257\n",
      "! Brilliant|22936\n",
      "! Brilliant !|40532\n",
      "! Brilliant ! '|22937\n",
      "! C'mon|60624\n",
      "! Gollum 's ` performance ' is incredible|13402\n",
      "! Oh , look at that clever angle ! Wow , a jump cut !|179258\n"
     ]
    }
   ],
   "source": [
    "PHRASES_FILE = os.path.join(DATA_DIR, 'dictionary.txt')\n",
    "show(PHRASES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase ids|sentiment values\n",
      "0|0.5\n",
      "1|0.5\n",
      "2|0.44444\n",
      "3|0.5\n",
      "4|0.42708\n",
      "5|0.375\n",
      "6|0.41667\n",
      "7|0.54167\n",
      "8|0.33333\n"
     ]
    }
   ],
   "source": [
    "SENTIMENT_FILE = os.path.join(DATA_DIR, 'sentiment_labels.txt')\n",
    "show(SENTIMENT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_index,splitset_label\n",
      "1,1\n",
      "2,1\n",
      "3,2\n",
      "4,2\n",
      "5,2\n",
      "6,2\n",
      "7,2\n",
      "8,2\n",
      "9,2\n"
     ]
    }
   ],
   "source": [
    "SPLIT_FILE = os.path.join(DATA_DIR, 'datasetSplit.txt')\n",
    "show(SPLIT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrases: 239,232\n"
     ]
    }
   ],
   "source": [
    "phrases: Dict[str, str] = dict()\n",
    "\n",
    "with open(PHRASES_FILE) as f:\n",
    "    for line in f:\n",
    "        phrase_text, phrase_id = line.rstrip().split('|')\n",
    "        phrases[phrase_text] = phrase_id\n",
    "\n",
    "print('Phrases: {:,d}'.format(len(phrases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiments: 239,232\n"
     ]
    }
   ],
   "source": [
    "sentiments: Dict[str, float] = dict()\n",
    "\n",
    "with open(SENTIMENT_FILE) as f:\n",
    "    next(f) # skip header\n",
    "    for line in f:\n",
    "        phrase_id, sentiment_score = line.rstrip().split('|')\n",
    "        sentiments[phrase_id] = float(sentiment_score)\n",
    "\n",
    "print('Sentiments: {:,d}'.format(len(sentiments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 11,855\n"
     ]
    }
   ],
   "source": [
    "sentences: Dict[str, str] = dict()\n",
    "\n",
    "with open(SENTENCES_FILE) as f:\n",
    "    next(f) # skip header\n",
    "    for line in f:\n",
    "        sentence_id, sentence_text = line.rstrip().split('\\t')\n",
    "        sentences[sentence_id] = sentence_text\n",
    "\n",
    "print('Sentences: {:,d}'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(missing sentence)\n",
      "\n",
      "But in Imax 3-D , the clichÃ©s disappear into the vertiginous perspectives opened up by the photography .\n",
      "\n",
      "(missing sentence)\n",
      "\n",
      "-LRB- But it 's -RRB- worth recommending because of two marvelous performances by Michael Caine and Brendan Fraser .\n",
      "\n",
      "(missing sentence)\n",
      "\n",
      "JirÃ­ Hubac 's script is a gem .\n",
      "\n",
      "(missing sentence)\n",
      "\n",
      "You would n't call The Good Girl a date movie -LRB- an anti-date movie is more like it -RRB- , but when it 's good , it 's good and horrid .\n",
      "\n",
      "(missing sentence)\n",
      "\n",
      "An incendiary , deeply thought-provoking look at one of the most peculiar -LRB- and peculiarly venomous -RRB- bigotries in our increasingly frightening theocracy\n",
      "\n",
      "(missing sentence)\n",
      "\n",
      "MÃ¼nch 's genuine insight makes the film 's occasional overindulgence forgivable .\n",
      "\n",
      "(missing sentence)\n",
      "\n",
      "I enjoyed the ride -LRB- bumps and all -RRB- , creamy depth , and ultimate theme .\n",
      "\n",
      "(missing sentence)\n",
      "\n",
      "As a randy film about sexy people in gorgeous places being pushed and pulled -LRB- literally and figuratively -RRB- by desire ... -LRB- Sex and LucÃ­a -RRB- makes for an arousing good time .\n",
      "\n",
      "(missing sentence)\n",
      "\n",
      "Absorbing character study by AndrÃ© Turpin .\n",
      "\n",
      "(missing sentence)\n",
      "\n",
      "As Bundy , Michael Reilly Burke -LRB- Octopus 2 : River of Fear -RRB- has just the right amount of charisma and menace .\n",
      "\n",
      "Total missing: 569\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for sentence_text in sentences.values():\n",
    "    if sentence_text not in phrases:\n",
    "        if n < 10:\n",
    "            print('(missing sentence)\\n\\n{}\\n'.format(sentence_text))\n",
    "        n += 1\n",
    "\n",
    "print('Total missing: {:,d}'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 11,855\n"
     ]
    }
   ],
   "source": [
    "sentence_replace = {\n",
    "    '-LRB-': '(',\n",
    "    '-RRB-': ')',\n",
    "    'Ã¡': 'á',\n",
    "    'Ã ': 'à',\n",
    "    'Ã¢': 'â',\n",
    "    'Ã£': 'ã',\n",
    "    'Ã©': 'é',\n",
    "    'Ã¨': 'è',\n",
    "    'Ã­': 'í',\n",
    "    'Ã¯': 'ï',\n",
    "    'Ã³': 'ó',\n",
    "    'Ã´': 'ô',\n",
    "    'Ã¶': 'ö',\n",
    "    'Ã»': 'û',\n",
    "    'Ã¼': 'ü',\n",
    "    'Ã¦': 'æ',\n",
    "    'Ã§': 'ç',\n",
    "    'Ã±': 'ñ',\n",
    "    '2Â': '2',\n",
    "    '8Â': '8',    \n",
    "}\n",
    "\n",
    "def text_fix(txt):\n",
    "    for k, v in sentence_replace.items():\n",
    "        if k in txt:\n",
    "            txt = txt.replace(k, v)\n",
    "    return txt\n",
    "\n",
    "sentences: Dict[str, str] = dict()\n",
    "\n",
    "with open(SENTENCES_FILE) as f:\n",
    "    next(f) # skip header\n",
    "    for line in f:\n",
    "        sentence_id, sentence_text = line.rstrip().split('\\t')\n",
    "        sentences[sentence_id] = text_fix(sentence_text)\n",
    "\n",
    "print('Sentences: {:,d}'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing: 0\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for sentence_text in sentences.values():\n",
    "    if sentence_text not in phrases:\n",
    "        if n < 10:\n",
    "            print('(missing sentence)\\n\\n{}\\n'.format(sentence_text))\n",
    "        n += 1\n",
    "\n",
    "print('Total missing: {:,d}'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
      "\n",
      "2\n",
      "\n",
      "The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\/director Peter Jackson 's expanded vision of J.R.R. Tolkien 's Middle-earth .\n",
      "\n",
      "3\n",
      "\n",
      "Effective but too-tepid biopic\n",
      "\n",
      "4\n",
      "\n",
      "If you sometimes like to go to the movies to have fun , Wasabi is a good place to start .\n",
      "\n",
      "5\n",
      "\n",
      "Emerges as something rare , an issue movie that 's so honest and keenly observed that it does n't feel like one .\n",
      "\n",
      "6\n",
      "\n",
      "The film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "\n",
      "7\n",
      "\n",
      "Offers that rare combination of entertainment and education .\n",
      "\n",
      "8\n",
      "\n",
      "Perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "\n",
      "9\n",
      "\n",
      "Steers turns in a snappy screenplay that curls at the edges ; it 's so clever you want to hate it .\n",
      "\n",
      "10\n",
      "\n",
      "But he somehow pulls it off .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(sentences.items()):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print('{}\\n\\n{}\\n'.format(*s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences to phrase: 11,855\n"
     ]
    }
   ],
   "source": [
    "sentence_to_phrase: Dict[str, str] = dict(\n",
    "    (sentence_id, phrases[sentence_text])\n",
    "    for sentence_id, sentence_text in sentences.items())\n",
    "\n",
    "print('Sentences to phrase: {:,d}'.format(len(sentence_to_phrase)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sentences: 8,544\n",
      "Valid sentences: 1,101\n",
      "Test sentences: 2,210\n"
     ]
    }
   ],
   "source": [
    "train_sentiment: List[Tuple[str, float]] = list()\n",
    "valid_sentiment: List[Tuple[str, float]] = list()\n",
    "test_sentiment: List[Tuple[str, float]] = list()\n",
    "\n",
    "splits = {\n",
    "    '1': train_sentiment,\n",
    "    '2': test_sentiment,\n",
    "    '3': valid_sentiment,\n",
    "}\n",
    "\n",
    "with open(SPLIT_FILE) as f:\n",
    "    next(f) # skip header\n",
    "    for line in f:\n",
    "        sentence_id, split = line.rstrip().split(',')\n",
    "        phrase_id = sentence_to_phrase[sentence_id]\n",
    "        sentiment_score = sentiments[phrase_id]\n",
    "        splits[split].append((phrase_id, sentiment_score))\n",
    "\n",
    "print('Train sentences: {:,d}'.format(len(train_sentiment)))\n",
    "print('Valid sentences: {:,d}'.format(len(valid_sentiment)))\n",
    "print('Test sentences: {:,d}'.format(len(test_sentiment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('226166', 0.69444),\n",
       " ('226300', 0.83333),\n",
       " ('225801', 0.625),\n",
       " ('14646', 0.5),\n",
       " ('14644', 0.72222),\n",
       " ('227114', 0.83333),\n",
       " ('224508', 0.875),\n",
       " ('225402', 0.72222),\n",
       " ('228134', 0.83333),\n",
       " ('227472', 0.73611)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentiment[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phrases = True\n",
    "min_word_freq = 5\n",
    "# all_phrases = False\n",
    "# min_word_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', '!'),\n",
       " ('22935', \"! '\"),\n",
       " ('18235', \"! ''\"),\n",
       " ('179257', '! Alas'),\n",
       " ('22936', '! Brilliant'),\n",
       " ('40532', '! Brilliant !'),\n",
       " ('22937', \"! Brilliant ! '\"),\n",
       " ('60624', \"! C'mon\"),\n",
       " ('13402', \"! Gollum 's ` performance ' is incredible\"),\n",
       " ('179258', '! Oh , look at that clever angle ! Wow , a jump cut !')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_phrases = set(sentence_to_phrase.values())\n",
    "raw_text = list((phrase_ref, phrase_text)\n",
    "               for phrase_text, phrase_ref in phrases.items()\n",
    "               if all_phrases or phrase_ref in sentence_phrases)\n",
    "\n",
    "raw_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text (tokenized): 239,232\n"
     ]
    }
   ],
   "source": [
    "def transform_tokenize(data: List[Tuple[str, str]]) -> List[Tuple[str, List[str]]]:\n",
    "    return list((ref, text.lower().split()) for ref, text in data)\n",
    "\n",
    "text_tokens = transform_tokenize(raw_text)\n",
    "\n",
    "print('Text (tokenized): {:,d}'.format(len(text_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 lengths\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Last 10 lengths\n",
      "\n",
      "[51, 51, 51, 51, 51, 52, 52, 52, 55, 56]\n",
      "\n",
      "Statistics\n",
      "\n",
      "Min: 1\n",
      "Max: 56\n",
      "Mean: 7.8\n",
      "Stdev: 7.5\n",
      "25%: 2.0\n",
      "50%: 5.0\n",
      "75%: 10.0 \n",
      "\n",
      "Most common:\n",
      "\n",
      "2: 37,489\n",
      "3: 30,949\n",
      "1: 22,346\n",
      "4: 21,403\n",
      "5: 16,711\n",
      "6: 13,739\n",
      "7: 11,518\n",
      "8: 9,791\n",
      "9: 8,314\n",
      "10: 7,291\n",
      "\n",
      "Least common:\n",
      "\n",
      "45: 68\n",
      "46: 42\n",
      "47: 30\n",
      "48: 26\n",
      "49: 13\n",
      "50: 8\n",
      "51: 7\n",
      "52: 3\n",
      "55: 1\n",
      "56: 1\n",
      "\n",
      "Length <= 10:\n",
      "\n",
      "2: 37,489\n",
      "3: 30,949\n",
      "1: 22,346\n",
      "4: 21,403\n",
      "5: 16,711\n",
      "6: 13,739\n",
      "7: 11,518\n",
      "8: 9,791\n",
      "9: 8,314\n",
      "10: 7,291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_length = list(len(tokens) for _, tokens in text_tokens)\n",
    "text_length = sorted(text_length)\n",
    "\n",
    "print('First 10 lengths\\n\\n{}\\n'.format(text_length[:10]))\n",
    "print('Last 10 lengths\\n\\n{}\\n'.format(text_length[-10:]))\n",
    "\n",
    "l_min = np.amin(text_length)\n",
    "l_max = np.amax(text_length)\n",
    "l_mean = np.mean(text_length)\n",
    "l_stdev = np.std(text_length)\n",
    "l_50 = np.median(text_length)\n",
    "l_25 = np.percentile(text_length, 25)\n",
    "l_75 = np.percentile(text_length, 75)\n",
    "\n",
    "print('Statistics\\n')\n",
    "print('Min: {:,d}'.format(l_min))\n",
    "print('Max: {:,d}'.format(l_max))\n",
    "print('Mean: {:,.1f}'.format(l_mean))\n",
    "print('Stdev: {:,.1f}'.format(l_stdev))\n",
    "print('25%: {:,.1f}'.format(l_25))\n",
    "print('50%: {:,.1f}'.format(l_50))\n",
    "print('75%: {:,.1f}'.format(l_75), '\\n')\n",
    "\n",
    "l_hist = collections.Counter(text_length).most_common()\n",
    "\n",
    "print('Most common:\\n')\n",
    "for length, freq in l_hist[:10]:\n",
    "    print('{}: {:,d}'.format(length, freq))\n",
    "print('\\nLeast common:\\n')\n",
    "for length, freq in l_hist[-10:]:\n",
    "    print('{}: {:,d}'.format(length, freq))\n",
    "print('\\nLength <= 10:\\n')\n",
    "for length, freq in (c for c in l_hist if c[0] <= 10):\n",
    "    print('{}: {:,d}'.format(length, freq))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens (total): 1,855,983\n"
     ]
    }
   ],
   "source": [
    "def transform_flat(data: List[Tuple[str, List[str]]]) -> List[str]:\n",
    "    return list(token for _, tokens in data for token in tokens)\n",
    "\n",
    "tokens = transform_flat(text_tokens)\n",
    "\n",
    "print('Tokens (total): {:,d}'.format(len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens (unique): 19,795\n"
     ]
    }
   ],
   "source": [
    "def transform_freq(data: List[str]) -> List[Tuple[str, int]]:\n",
    "    return collections.Counter(data).most_common()\n",
    "\n",
    "tokens_freq = transform_freq(tokens)\n",
    "\n",
    "print('Tokens (unique): {:,d}'.format(len(tokens_freq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common:\n",
      "\n",
      "the (83,351)\n",
      ", (70,577)\n",
      "a (58,742)\n",
      "and (51,804)\n",
      "of (51,771)\n",
      ". (38,004)\n",
      "to (36,937)\n",
      "'s (28,200)\n",
      "is (23,073)\n",
      "in (22,602)\n",
      "it (20,930)\n",
      "that (20,057)\n",
      "as (14,224)\n",
      "with (12,573)\n",
      "for (12,080)\n",
      "its (11,473)\n",
      "film (10,518)\n",
      "an (10,262)\n",
      "this (10,120)\n",
      "movie (9,688)\n",
      "\n",
      "Least common:\n",
      "\n",
      "ryosuke (2)\n",
      "schnieder (2)\n",
      "sensitively (2)\n",
      "snoots (2)\n",
      "spectators (2)\n",
      "spiderman (2)\n",
      "symbolically (2)\n",
      "theirs (2)\n",
      "topkapi (2)\n",
      "touché (2)\n",
      "two-bit (2)\n",
      "ub (2)\n",
      "unflinchingly (2)\n",
      "unintelligible (2)\n",
      "unspools (2)\n",
      "unsurprisingly (2)\n",
      "vereté (2)\n",
      "ou (2)\n",
      "overburdened (2)\n",
      "unk (1)\n"
     ]
    }
   ],
   "source": [
    "print('Most common:\\n')\n",
    "for token, freq in tokens_freq[:20]:\n",
    "    print('{} ({:,d})'.format(token, freq))\n",
    "print('\\nLeast common:\\n')\n",
    "for token, freq in tokens_freq[-20:]:\n",
    "    print('{} ({:,d})'.format(token, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens (unique): 19,795\n",
      "Tokens 5+: 19,212\n"
     ]
    }
   ],
   "source": [
    "tokens_vocab = list(token for token, freq in tokens_freq if freq >= min_word_freq)\n",
    "\n",
    "print('Tokens (unique): {:,d}'.format(len(tokens_freq)))\n",
    "print('Tokens {}+: {:,d}'.format(min_word_freq, len(tokens_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19,214\n",
      "Tokens (to id): 19,214\n",
      "Tokens (from id): 19,214\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(tokens_vocab) + 2\n",
    "\n",
    "NULL_ID = 0\n",
    "UNK_ID = 1\n",
    "token_to_id: Dict[str, int] = dict((token, token_id)\n",
    "                                   for token_id, token in enumerate(tokens_vocab, 2))\n",
    "token_to_id['NULL'] = NULL_ID\n",
    "token_to_id['UNK'] = UNK_ID\n",
    "\n",
    "token_from_id: Dict[int, str] = dict((token_id, token)\n",
    "                                     for token, token_id in token_to_id.items())\n",
    "\n",
    "print('Vocabulary size: {:,d}'.format(vocabulary_size))\n",
    "print('Tokens (to id): {:,d}'.format(len(token_to_id)))\n",
    "print('Tokens (from id): {:,d}'.format(len(token_from_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection size: 239,232\n",
      "Documents (to id): 239,232\n",
      "Documents (from id): 239,232\n"
     ]
    }
   ],
   "source": [
    "collection_size = len(raw_text)\n",
    "\n",
    "document_to_id: Dict[str, int] = dict((doc_ref, doc_id) for doc_id, (doc_ref, _) in enumerate(raw_text))\n",
    "document_from_id: Dict[int, str] = dict((doc_id, doc_ref) for doc_ref, doc_id in document_to_id.items())\n",
    "\n",
    "print('Collection size: {:,d}'.format(collection_size))\n",
    "print('Documents (to id): {:,d}'.format(len(document_to_id)))\n",
    "print('Documents (from id): {:,d}'.format(len(document_from_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary file size: 170,052 bytes\n"
     ]
    }
   ],
   "source": [
    "VOCABULARY_FILE = os.path.join(HOME_DIR, 'vocabulary.txt')\n",
    "\n",
    "with open(VOCABULARY_FILE, 'w') as f:\n",
    "    for token_id in range(len(token_from_id)):\n",
    "        f.write(token_from_id[token_id] + '\\n')\n",
    "\n",
    "print('Vocabulary file size: {:,d} bytes'.format(os.stat(VOCABULARY_FILE).st_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents file size: 1,563,514 bytes\n"
     ]
    }
   ],
   "source": [
    "DOCUMENTS_FILE = os.path.join(HOME_DIR, 'documents.txt')\n",
    "\n",
    "with open(DOCUMENTS_FILE, 'w') as f:\n",
    "    for doc_id in range(len(document_from_id)):\n",
    "        f.write(document_from_id[doc_id] + '\\n')\n",
    "\n",
    "print('Documents file size: {:,d} bytes'.format(os.stat(DOCUMENTS_FILE).st_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens (total):\n",
      "\n",
      "1,855,983\n",
      "\n",
      "Text (IDs):\n",
      "\n",
      "[(0, 255), (1, 255), (1, 44), (2, 255), (2, 27), (3, 255), (3, 2796), (4, 255), (4, 653), (5, 255)]\n",
      "\n",
      "Text (Tokens):\n",
      "\n",
      "[('0', '!'), ('22935', '!'), ('22935', \"'\"), ('18235', '!'), ('18235', \"''\"), ('179257', '!'), ('179257', 'alas'), ('22936', '!'), ('22936', 'brilliant'), ('40532', '!')]\n"
     ]
    }
   ],
   "source": [
    "def transform_text(data: List[Tuple[str, List[str]]],\n",
    "                   key_to_id: Dict[str, int],\n",
    "                   value_to_id: Dict[str, int],\n",
    "                   unk_id: str) \\\n",
    "    -> List[Tuple[int, int]]:\n",
    "    return list((key_to_id[key], value_to_id.get(value_, unk_id))\n",
    "                for key, value in data\n",
    "                for value_ in value)\n",
    "\n",
    "data = transform_text(text_tokens, document_to_id, token_to_id, UNK_ID)\n",
    "\n",
    "print('Tokens (total):\\n\\n{:,d}\\n'.format(len(data)))\n",
    "print('Text (IDs):\\n\\n{}\\n'.format(data[:10]))\n",
    "print('Text (Tokens):\\n\\n{}'.format(list((document_from_id[doc_id], token_from_id[token_id])\n",
    "                                         for doc_id, token_id in data[:10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 8,544\n",
      "Valid data size: 1,101\n",
      "Test data size: 2,210\n"
     ]
    }
   ],
   "source": [
    "def transform_sentiment(data: List[Tuple[str, int]],\n",
    "                        key_to_id: Dict[str, int],\n",
    "                        threshold=0.5) \\\n",
    "    -> List[Tuple[int, int]]:\n",
    "    return list((key_to_id[doc_ref], int(score > threshold))\n",
    "                 for doc_ref, score in data)\n",
    "\n",
    "train_data = transform_sentiment(train_sentiment, document_to_id)\n",
    "valid_data = transform_sentiment(valid_sentiment, document_to_id)\n",
    "test_data = transform_sentiment(test_sentiment, document_to_id)\n",
    "\n",
    "print('Train data size: {:,d}'.format(len(train_data)))\n",
    "print('Valid data size: {:,d}'.format(len(valid_data)))\n",
    "print('Test data size: {:,d}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50444, 1),\n",
       " (52284, 1),\n",
       " (47441, 1),\n",
       " (60951, 0),\n",
       " (60905, 1),\n",
       " (59623, 1),\n",
       " (37093, 1),\n",
       " (43737, 1),\n",
       " (69284, 1),\n",
       " (61884, 1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4300), (0, 4244)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(x[1] for x in train_data).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 558), (1, 543)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(x[1] for x in valid_data).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1143), (1, 1067)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(x[1] for x in test_data).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del phrases, sentiments, sentences, sentence_to_phrase, sentence_phrases\n",
    "del raw_text, text_tokens, text_length, l_hist, tokens, tokens_freq, tokens_vocab\n",
    "del train_sentiment, valid_sentiment, test_sentiment\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "* **`token_to_id: Dict[str, int]`** - token text to index\n",
    "* **`token_from_id: Dict[int, str]`** - index to token text\n",
    "* **`document_to_id: Dict[str, int]`** - phrase id (reference) to index\n",
    "* **`document_from_id: Dict[int, str]`** - index to phrase id (reference)\n",
    "* **`data: List[Tuple[int, int]]`** - list of tuples (phrase index, token index)\n",
    "* **`train_data: List[Tuple[int, int]]`** - list of tuples (phrase index, sentiment class)\n",
    "* **`valid_data: List[Tuple[int, int]]`** - list of tuples (phrase index, sentiment class)\n",
    "* **`test_data: List[Tuple[int, int]]`** - list of tuples (phrase index, sentiment class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Memory (DM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples (window_size=4): 1,311,252\n",
      "Batches (batch_size=64): 20,489\n",
      "Last (batch_size=64): 20\n"
     ]
    }
   ],
   "source": [
    "def count_windows(data: List[Tuple[int, int]],\n",
    "                  window_size: int) -> int:\n",
    "    doc_length = collections.Counter(doc_id for doc_id, _ in data).values()\n",
    "    windows_per_doc = (1 + max(0, length - window_size)\n",
    "                        for length in doc_length)\n",
    "    return sum(windows_per_doc)\n",
    "\n",
    "assert count_windows([(0, 1)], 4) == 1\n",
    "assert count_windows([(0, 1), (1, 1)], 4) == 1 + 1\n",
    "assert count_windows([(0, 1), (1, 1), (1, 2), (1, 3), (1, 4)], 4) == 1 + 1\n",
    "assert count_windows([(0, 1), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5)], 4) == 1 + 1 + 1\n",
    "assert count_windows([(0, 1), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6)], 4) == 1 + 1 + 2\n",
    "\n",
    "num_examples_4 = count_windows(data, 4)\n",
    "num_batches_64 = math.ceil(num_examples_4 / 64)\n",
    "last_batch_64 = num_examples_4 % 64\n",
    "\n",
    "print('Examples (window_size=4): {:,d}'.format(num_examples_4))\n",
    "print('Batches (batch_size=64): {:,d}'.format(num_batches_64))\n",
    "print('Last (batch_size=64): {:,d}'.format(last_batch_64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_document(data: Deque[Tuple[int, int]],\n",
    "                   window_size: int,\n",
    "                   pad_value=NULL_ID) \\\n",
    "    -> Tuple[int, Deque[int], Deque[int]]:\n",
    "\n",
    "    doc_id, token_id = data.popleft()\n",
    "    window = collections.deque(maxlen=window_size)\n",
    "    window.append(token_id)\n",
    "    tail = collections.deque()\n",
    "    while data and data[0][0] == doc_id:\n",
    "        _, token_id = data.popleft()\n",
    "        if len(window) < window_size:\n",
    "            window.append(token_id)\n",
    "        else:\n",
    "            tail.append(token_id)\n",
    "    pad_size = window_size - len(window) \n",
    "    if pad_size > 0:\n",
    "        window.extendleft([pad_value] * pad_size)\n",
    "    return doc_id, window, tail\n",
    "\n",
    "fake_data = collections.deque([(0, 1),\n",
    "                               (1, 1), (1, 2),\n",
    "                               (2, 1), (2, 2), (2, 3), (2, 4),\n",
    "                               (3, 1), (3, 2), (3, 3), (3, 4), (3, 5)])\n",
    "assert slice_document(fake_data, 4) == (0, collections.deque([0, 0, 0, 1]), collections.deque())\n",
    "assert slice_document(fake_data, 4) == (1, collections.deque([0, 0, 1, 2]), collections.deque())\n",
    "assert slice_document(fake_data, 4) == (2, collections.deque([1, 2, 3, 4]), collections.deque())\n",
    "assert slice_document(fake_data, 4) == (3, collections.deque([1, 2, 3, 4]), collections.deque([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examples_generator_dm(data: List[Tuple[int, int]],\n",
    "                          window_size: int) \\\n",
    "    -> Tuple[int, List[int], int]:\n",
    "    \n",
    "    num_examples = count_windows(data, window_size)\n",
    "    data_tail = collections.deque(data)\n",
    "    doc_id, window, tail = None, None, None\n",
    "\n",
    "    for _ in range(num_examples):\n",
    "        if not tail:\n",
    "            doc_id, window, tail = slice_document(data_tail, window_size)\n",
    "        else:\n",
    "            window.append(tail.popleft())\n",
    "        _window = list(window)\n",
    "        yield doc_id, _window[:-1], _window[-1]\n",
    "\n",
    "assert len(list(examples_generator_dm(data, 4))) == count_windows(data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dm(data: List[Tuple[int, int]],\n",
    "             batch_size: int,\n",
    "             window_size: int,\n",
    "             shuffle=True) \\\n",
    "    -> Iterable[Tuple[np.ndarray, np.ndarray, np.ndarray]]:\n",
    "    \n",
    "    examples = list(examples_generator_dm(data, window_size))\n",
    "    if shuffle:\n",
    "        random.shuffle(examples)\n",
    "    \n",
    "    num_examples = len(examples)\n",
    "    while num_examples > 0:\n",
    "        batch_size_i = min(batch_size, num_examples)\n",
    "        \n",
    "        doc_batch = np.ndarray(shape=(batch_size_i, 1), dtype=np.int32)\n",
    "        words_batch = \\\n",
    "            np.ndarray(shape=(batch_size_i, window_size-1), dtype=np.int32)\n",
    "        target_batch = np.ndarray(shape=(batch_size_i, 1), dtype=np.int32)\n",
    "        \n",
    "        for i in range(batch_size_i):\n",
    "            doc_id, words, target = examples.pop()\n",
    "            doc_batch[i, 0] = doc_id\n",
    "            words_batch[i, :] = words\n",
    "            target_batch[i, 0] = target\n",
    "        \n",
    "        num_examples -= batch_size_i\n",
    "        yield doc_batch, words_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch steps: 20,489\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "window_size = 4\n",
    "\n",
    "n = 0\n",
    "for _ in input_dm(data, batch_size, window_size):\n",
    "    n += 1\n",
    "print('Epoch steps: {:,d}'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "\n",
      "165942: paint the -> castro\n",
      "152210: metaphor for -> the\n",
      "199649: -- a -> dearth\n",
      "115802: everyday lives -> of\n",
      "\n",
      "Batch 2\n",
      "\n",
      "198730: to the -> soggy\n",
      "53466: far from -> painful\n",
      "11911: just how -> ridiculous\n",
      "63847: effective portrait -> of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "window_size = 3\n",
    "num_iters = 2\n",
    "\n",
    "data_iter = input_dm(data, batch_size, window_size)\n",
    "\n",
    "for k in range(1, num_iters+1):\n",
    "    print('Batch {}\\n'.format(k))\n",
    "    doc_batch, words_batch, target_batch = next(data_iter)\n",
    "    for i in range(batch_size):\n",
    "        doc_ref = document_from_id[doc_batch[i, 0]]\n",
    "        words = ' '.join(token_from_id[token_id]\n",
    "                         for token_id in words_batch[i])\n",
    "        target = token_from_id[target_batch[i, 0]]\n",
    "        print('{}: {} -> {}'.format(doc_ref, words, target))\n",
    "    print()\n",
    "\n",
    "del data_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f9d9fcd4588>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "window_size = 3\n",
    "collection_size = 5\n",
    "vocabulary_size = 20\n",
    "embedding_size = 3\n",
    "num_sampled = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(4, 1), dtype=int32) \n",
      "\n",
      "[[3]\n",
      " [0]\n",
      " [2]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "X_doc = tf.constant(np.random.randint(low=0,\n",
    "                                      high=collection_size,\n",
    "                                      size=(batch_size, 1),\n",
    "                                      dtype=np.int32))\n",
    "\n",
    "print(X_doc, '\\n')\n",
    "print(X_doc.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(4, 2), dtype=int32) \n",
      "\n",
      "[[ 6 12]\n",
      " [13  4]\n",
      " [11  5]\n",
      " [ 3  7]]\n"
     ]
    }
   ],
   "source": [
    "X_words = tf.constant(np.random.randint(low=0,\n",
    "                                        high=vocabulary_size,\n",
    "                                        size=(batch_size, window_size-1),\n",
    "                                        dtype=np.int32))\n",
    "\n",
    "print(X_words, '\\n')\n",
    "print(X_words.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(4, 1), dtype=int32) \n",
      "\n",
      "[[18]\n",
      " [11]\n",
      " [ 7]\n",
      " [17]]\n"
     ]
    }
   ],
   "source": [
    "y = tf.constant(np.random.randint(low=0,\n",
    "                                  high=vocabulary_size,\n",
    "                                  size=(batch_size, 1),\n",
    "                                  dtype=np.int32))\n",
    "\n",
    "print(y, '\\n')\n",
    "print(y.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32_ref> \n",
      "\n",
      "[[ 0.61695331 -0.83561099  0.10422225]\n",
      " [ 0.01217361  0.48313096 -0.78804368]\n",
      " [-0.88473046 -0.86139524  0.17132476]\n",
      " [-0.99765617  0.31212142 -0.67784834]\n",
      " [-0.98943394 -0.74844962 -0.75118273]]\n"
     ]
    }
   ],
   "source": [
    "# ~ tf.random_uniform(shape=(collection_size, embedding_size),\n",
    "#                     minval=-1.0, maxval=1.0)\n",
    "doc_embeddings = tf.Variable(\n",
    "    2 * np.random.rand(collection_size, embedding_size) - 1, dtype=tf.float32)\n",
    "\n",
    "doc_embeddings.initializer.run()\n",
    "\n",
    "print(doc_embeddings, '\\n')\n",
    "print(doc_embeddings.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"zeros:0\", shape=(1, 3), dtype=float32) \n",
      "\n",
      "[[ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "NULL = tf.zeros(shape=(1, embedding_size))\n",
    "\n",
    "print(NULL, '\\n')\n",
    "print(NULL.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_1:0' shape=(19, 3) dtype=float32_ref> \n",
      "\n",
      "[[ 0.34873706  0.60267746 -0.51587909]\n",
      " [ 0.33118272 -0.82778776 -0.55520707]\n",
      " [ 0.4912844   0.34662133  0.85085076]\n",
      " [-0.835271    0.17302893 -0.18058257]\n",
      " [-0.37621927 -0.85698396 -0.62743801]\n",
      " [-0.75230187  0.13368917  0.99833119]\n",
      " [-0.33602506  0.35631764 -0.23668386]\n",
      " [-0.57253391 -0.05880897  0.78443813]\n",
      " [ 0.72282249 -0.38552123 -0.79930961]\n",
      " [-0.68327624  0.463929    0.84884042]\n",
      " [ 0.18314609 -0.24641821 -0.41466221]\n",
      " [-0.2665945  -0.15293165 -0.12184247]\n",
      " [ 0.29443887  0.70825493 -0.17377342]\n",
      " [-0.04638245  0.14809784  0.05762608]\n",
      " [ 0.68977821 -0.82786703  0.30497012]\n",
      " [ 0.80665559 -0.7813338   0.80110413]\n",
      " [-0.63951135 -0.83063197  0.41020012]\n",
      " [-0.85422176  0.95679355 -0.51974726]\n",
      " [ 0.32139546 -0.39768055 -0.79400396]]\n"
     ]
    }
   ],
   "source": [
    "# ~ tf.random_uniform(shape=(vocabulary_size - 1, embedding_size),\n",
    "#                     minval=-1.0, maxval=1.0)\n",
    "word_embeddings_ = tf.Variable(\n",
    "    2 * np.random.rand(vocabulary_size - 1, embedding_size) - 1, dtype=tf.float32)\n",
    "\n",
    "word_embeddings_.initializer.run()\n",
    "\n",
    "print(word_embeddings_, '\\n')\n",
    "print(word_embeddings_.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", shape=(20, 3), dtype=float32) \n",
      "\n",
      "[[ 0.          0.          0.        ]\n",
      " [ 0.34873706  0.60267746 -0.51587909]\n",
      " [ 0.33118272 -0.82778776 -0.55520707]\n",
      " [ 0.4912844   0.34662133  0.85085076]\n",
      " [-0.835271    0.17302893 -0.18058257]\n",
      " [-0.37621927 -0.85698396 -0.62743801]\n",
      " [-0.75230187  0.13368917  0.99833119]\n",
      " [-0.33602506  0.35631764 -0.23668386]\n",
      " [-0.57253391 -0.05880897  0.78443813]\n",
      " [ 0.72282249 -0.38552123 -0.79930961]\n",
      " [-0.68327624  0.463929    0.84884042]\n",
      " [ 0.18314609 -0.24641821 -0.41466221]\n",
      " [-0.2665945  -0.15293165 -0.12184247]\n",
      " [ 0.29443887  0.70825493 -0.17377342]\n",
      " [-0.04638245  0.14809784  0.05762608]\n",
      " [ 0.68977821 -0.82786703  0.30497012]\n",
      " [ 0.80665559 -0.7813338   0.80110413]\n",
      " [-0.63951135 -0.83063197  0.41020012]\n",
      " [-0.85422176  0.95679355 -0.51974726]\n",
      " [ 0.32139546 -0.39768055 -0.79400396]]\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = tf.concat([NULL, word_embeddings_], axis=0)\n",
    "\n",
    "print(word_embeddings, '\\n')\n",
    "print(word_embeddings.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(4, 1, 3), dtype=float32) \n",
      "\n",
      "[[[-0.99765617  0.31212142 -0.67784834]]\n",
      "\n",
      " [[ 0.61695331 -0.83561099  0.10422225]]\n",
      "\n",
      " [[-0.88473046 -0.86139524  0.17132476]]\n",
      "\n",
      " [[-0.98943394 -0.74844962 -0.75118273]]]\n"
     ]
    }
   ],
   "source": [
    "D_embed = tf.nn.embedding_lookup(doc_embeddings, X_doc)\n",
    "\n",
    "print(D_embed, '\\n')\n",
    "print(D_embed.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup_1:0\", shape=(4, 2, 3), dtype=float32) \n",
      "\n",
      "[[[-0.75230187  0.13368917  0.99833119]\n",
      "  [-0.2665945  -0.15293165 -0.12184247]]\n",
      "\n",
      " [[ 0.29443887  0.70825493 -0.17377342]\n",
      "  [-0.835271    0.17302893 -0.18058257]]\n",
      "\n",
      " [[ 0.18314609 -0.24641821 -0.41466221]\n",
      "  [-0.37621927 -0.85698396 -0.62743801]]\n",
      "\n",
      " [[ 0.4912844   0.34662133  0.85085076]\n",
      "  [-0.33602506  0.35631764 -0.23668386]]]\n"
     ]
    }
   ],
   "source": [
    "W_embed = tf.nn.embedding_lookup(word_embeddings, X_words)\n",
    "\n",
    "print(W_embed, '\\n')\n",
    "print(W_embed.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_1:0\", shape=(4, 3, 3), dtype=float32) \n",
      "\n",
      "[[[-0.99765617  0.31212142 -0.67784834]\n",
      "  [-0.75230187  0.13368917  0.99833119]\n",
      "  [-0.2665945  -0.15293165 -0.12184247]]\n",
      "\n",
      " [[ 0.61695331 -0.83561099  0.10422225]\n",
      "  [ 0.29443887  0.70825493 -0.17377342]\n",
      "  [-0.835271    0.17302893 -0.18058257]]\n",
      "\n",
      " [[-0.88473046 -0.86139524  0.17132476]\n",
      "  [ 0.18314609 -0.24641821 -0.41466221]\n",
      "  [-0.37621927 -0.85698396 -0.62743801]]\n",
      "\n",
      " [[-0.98943394 -0.74844962 -0.75118273]\n",
      "  [ 0.4912844   0.34662133  0.85085076]\n",
      "  [-0.33602506  0.35631764 -0.23668386]]]\n"
     ]
    }
   ],
   "source": [
    "X_embed = tf.concat([D_embed, W_embed], axis=1)\n",
    "\n",
    "print(X_embed, '\\n')\n",
    "print(X_embed.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(4, 9), dtype=float32) \n",
      "\n",
      "[[-0.99765617  0.31212142 -0.67784834 -0.75230187  0.13368917  0.99833119\n",
      "  -0.2665945  -0.15293165 -0.12184247]\n",
      " [ 0.61695331 -0.83561099  0.10422225  0.29443887  0.70825493 -0.17377342\n",
      "  -0.835271    0.17302893 -0.18058257]\n",
      " [-0.88473046 -0.86139524  0.17132476  0.18314609 -0.24641821 -0.41466221\n",
      "  -0.37621927 -0.85698396 -0.62743801]\n",
      " [-0.98943394 -0.74844962 -0.75118273  0.4912844   0.34662133  0.85085076\n",
      "  -0.33602506  0.35631764 -0.23668386]]\n"
     ]
    }
   ],
   "source": [
    "# concatenate\n",
    "X_linear = tf.reshape(X_embed, [-1, window_size * embedding_size])\n",
    "\n",
    "print(X_linear, '\\n')\n",
    "print(X_linear.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(4, 3), dtype=float32) \n",
      "\n",
      "[[-0.67218417  0.09762631  0.06621346]\n",
      " [ 0.02537374  0.01522429 -0.08337792]\n",
      " [-0.35926786 -0.6549325  -0.2902585 ]\n",
      " [-0.2780582  -0.01517022 -0.04567194]]\n"
     ]
    }
   ],
   "source": [
    "# average\n",
    "X_linear_ = tf.reduce_mean(X_embed, axis=1)\n",
    "\n",
    "print(X_linear_, '\\n')\n",
    "print(X_linear_.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_2:0' shape=(20, 9) dtype=float32_ref> \n",
      "\n",
      "[[ 0.50300145  0.0552301   0.01993387  0.03547276  0.20155744 -0.27312559\n",
      "  -0.02927397 -0.86327475  0.10278616]\n",
      " [ 0.17196627 -0.21156923 -0.31027129  0.43497968  0.08492911  0.08177979\n",
      "  -0.07587215  0.41648802  0.18212952]\n",
      " [ 0.44487646 -0.35043812 -0.51195747  0.00614848 -0.04894156 -0.54465908\n",
      "   0.11943867  0.14217165  0.5565322 ]\n",
      " [-0.35984975  0.10350386  0.71107525  0.44209716  0.12714341  0.02990536\n",
      "   0.31134015  0.18437816 -0.85236979]\n",
      " [ 0.31551623 -0.07670244 -0.14918286 -0.08804412 -0.34384787  0.51661211\n",
      "  -0.18063158  0.16129385  0.32392266]\n",
      " [ 0.95518899 -0.17771925 -0.09204181 -0.54479259 -0.72058147 -0.64434087\n",
      "  -0.01533921  0.10319012  0.0417698 ]\n",
      " [-0.04822987 -0.30193558  0.11717546 -0.00480292 -0.41884765  0.14872152\n",
      "  -0.28904089  0.04287879  0.22426446]\n",
      " [-0.53877252  0.19082838 -0.15504326  0.18127279 -0.29014444  0.13743672\n",
      "  -0.71249241 -0.04261471 -0.17864887]\n",
      " [-0.03443231 -0.39198354  0.31877732 -0.26667163 -0.06353394  0.15386935\n",
      "  -0.13273954  0.47301164  0.04060997]\n",
      " [ 0.30318677 -0.07019307  0.21135975  0.24471663 -0.13964407 -0.14832906\n",
      "  -0.06236446  0.33782744  0.35017627]\n",
      " [ 0.65960592  0.29692549 -0.47947302  0.29262802  0.07198036  0.47362146\n",
      "   0.3357704   0.15880296 -0.01380933]\n",
      " [-0.31749743 -0.0525659   0.03590889  0.42834523  0.01369238  0.52060628\n",
      "   0.07709087 -0.14472577 -0.00331451]\n",
      " [-0.44917101 -0.23417947 -0.39217865 -0.36496928  0.09991626 -0.38408139\n",
      "   0.74646538 -0.18545814  0.07017881]\n",
      " [-0.34929958  0.35721645 -0.49516326 -0.52486533  0.41439971  0.50705355\n",
      "   0.27181706 -0.62682247 -0.05477846]\n",
      " [-0.26709741 -0.16666105  0.07861218  0.11158692  0.44187143  0.04357956\n",
      "  -0.0359804   1.32700503 -0.05715876]\n",
      " [ 0.14762817 -0.18513921 -0.25153291 -0.50920129 -0.08179636  0.24030069\n",
      "   0.01251742 -0.28962511 -0.05873429]\n",
      " [-0.09844504 -0.97870314  0.52286893  0.41277629  0.31687862  0.04632142\n",
      "   0.39533594  0.20599709 -0.1756952 ]\n",
      " [-0.06660772  0.33508667 -0.2282117   0.30364639  0.2960121  -0.14826429\n",
      "   0.18025851  0.25156969 -0.6617589 ]\n",
      " [ 0.01440493  0.16325448  0.03728702 -0.1373248   0.11003217 -0.09890968\n",
      "  -0.11745241 -0.08456859  0.65125382]\n",
      " [-0.10647241  0.1612476  -0.27512938  0.08602465  0.16558301  0.54433829\n",
      "  -0.38369304  0.33354646 -0.3751049 ]]\n"
     ]
    }
   ],
   "source": [
    "# ~ tf.truncated_normal(shape=(vocabulary_size, window_size * embedding_size),\n",
    "#                       stddev=1.0 / np.sqrt(window_size * embedding_size))\n",
    "W_linear = tf.Variable(\n",
    "    np.random.randn(vocabulary_size,\n",
    "                    window_size * embedding_size) \\\n",
    "        / np.sqrt(window_size * embedding_size),\n",
    "    dtype=tf.float32)\n",
    "\n",
    "W_linear.initializer.run()\n",
    "\n",
    "print(W_linear, '\\n')\n",
    "print(W_linear.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_3:0' shape=(20,) dtype=float32_ref> \n",
      "\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# ~ tf.zeros(shape=(vocabulary_size,))\n",
    "b_linear = tf.Variable(np.zeros(vocabulary_size), dtype=tf.float32)\n",
    "\n",
    "b_linear.initializer.run()\n",
    "\n",
    "print(b_linear, '\\n')\n",
    "print(b_linear.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_3:0\", shape=(4,), dtype=float32) \n",
      "\n",
      "[ 0.1228271   0.46898732  0.17658222  0.19335443]\n"
     ]
    }
   ],
   "source": [
    "sampled_loss = tf.nn.sampled_softmax_loss(weights=W_linear,\n",
    "                                          biases=b_linear,\n",
    "                                          inputs=X_linear,\n",
    "                                          labels=y,\n",
    "                                          num_sampled=num_sampled,\n",
    "                                          num_classes=vocabulary_size)\n",
    "\n",
    "print(sampled_loss, '\\n')\n",
    "print(sampled_loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32) \n",
      "\n",
      "0.410072\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(sampled_loss)\n",
    "\n",
    "print(loss, '\\n')\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.close()\n",
    "del X_doc, X_words, y, doc_embeddings, NULL, word_embeddings_, word_embeddings\n",
    "del D_embed, W_embed, X_embed, X_linear, X_linear_, W_linear, b_linear\n",
    "del sampled_loss, loss\n",
    "del graph, session\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dm(collection_size: int,\n",
    "             vocabulary_size: int,\n",
    "             embedding_size: int,\n",
    "             window_size: int,\n",
    "             num_sampled: int,\n",
    "             linear_input='concatenate') \\\n",
    "    -> Tuple[List[tf.Tensor], List[tf.Tensor], tf.Tensor]:\n",
    "    \n",
    "    X_doc = tf.placeholder_with_default([[0]],\n",
    "                                        shape=(None, 1),\n",
    "                                        name='X_doc')\n",
    "    X_words = tf.placeholder_with_default([[0]*(window_size-1)],\n",
    "                                          shape=(None, window_size-1),\n",
    "                                          name='X_words')\n",
    "    y = tf.placeholder_with_default([[0]],\n",
    "                                    shape=(None, 1),\n",
    "                                    name='y')\n",
    "\n",
    "    doc_embeddings = tf.Variable(\n",
    "        tf.random_uniform(shape=(collection_size, embedding_size),\n",
    "                          minval=-1.0, maxval=1.0),\n",
    "        name='doc_embeddings')\n",
    "    NULL = tf.zeros(shape=(1, embedding_size))\n",
    "    word_embeddings_ = tf.Variable(\n",
    "        tf.random_uniform(shape=(vocabulary_size - 1, embedding_size),\n",
    "                          minval=-1.0, maxval=1.0))\n",
    "    word_embeddings = tf.concat([NULL, word_embeddings_], axis=0,\n",
    "                                name='word_embeddings')\n",
    "\n",
    "    D_embed = tf.nn.embedding_lookup(doc_embeddings, X_doc)\n",
    "    W_embed = tf.nn.embedding_lookup(word_embeddings, X_words)\n",
    "    X_embed = tf.concat([D_embed, W_embed], axis=1)\n",
    "    \n",
    "    if linear_input == 'concatenate':\n",
    "        linear_input_size = window_size * embedding_size\n",
    "        X_linear = tf.reshape(X_embed, [-1, linear_input_size])\n",
    "    elif linear_input == 'average':\n",
    "        linear_input_size = embedding_size\n",
    "        X_linear = tf.reduce_mean(X_embed, axis=1)\n",
    "    \n",
    "    W_linear = tf.Variable(\n",
    "        tf.truncated_normal(shape=(vocabulary_size, linear_input_size),\n",
    "                            stddev=1.0 / np.sqrt(linear_input_size)),\n",
    "        name='W')\n",
    "    b_linear = tf.Variable(\n",
    "        tf.zeros(shape=(vocabulary_size,)),\n",
    "        name='b')\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        sampled_loss = tf.nn.sampled_softmax_loss(weights=W_linear,\n",
    "                                                  biases=b_linear,\n",
    "                                                  inputs=X_linear,\n",
    "                                                  labels=y,\n",
    "                                                  num_sampled=num_sampled,\n",
    "                                                  num_classes=vocabulary_size)\n",
    "        loss = tf.reduce_mean(sampled_loss, name='mean')\n",
    "\n",
    "\n",
    "    inputs = [X_doc, X_words, y]\n",
    "    embeddings = [doc_embeddings, word_embeddings]\n",
    "    return inputs, embeddings, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:\n",
      "\n",
      "1.093\n",
      "\n",
      "Document embeddings:\n",
      "\n",
      "[[ 0.45113659  0.77803659 -0.67613029]\n",
      " [ 0.94764209  0.39480782 -0.2601161 ]\n",
      " [-0.49436474 -0.47757936 -0.70696068]\n",
      " [ 0.42527127 -0.17255878 -0.35939431]\n",
      " [-0.98591185 -0.40841484  0.00539851]]\n",
      "\n",
      "Word embeddings:\n",
      "\n",
      "[[ 0.          0.          0.        ]\n",
      " [-0.84714127 -0.76014662  0.27584815]\n",
      " [ 0.59547353  0.46513414 -0.82155466]\n",
      " [ 0.19842935 -0.22104239  0.01252961]\n",
      " [ 0.94651079  0.81266451  0.6597259 ]\n",
      " [-0.30908179  0.4171741  -0.50931215]\n",
      " [-0.86100388 -0.35169339  0.74930382]\n",
      " [-0.15820646  0.06676936 -0.19249582]\n",
      " [-0.38554835  0.99897957  0.28609705]\n",
      " [-0.56098485 -0.32115078 -0.53414893]\n",
      " [ 0.76078367  0.12152863 -0.61840367]\n",
      " [-0.91746092  0.06317115 -0.78675151]\n",
      " [ 0.58433509 -0.75683093 -0.02150941]\n",
      " [ 0.93951225 -0.03575969 -0.95609236]\n",
      " [-0.05698776 -0.2371254  -0.34965897]\n",
      " [-0.19159937 -0.89720178  0.1561265 ]\n",
      " [-0.51984644  0.10438085 -0.34959316]\n",
      " [ 0.95687032 -0.54687071 -0.19117522]\n",
      " [ 0.63521814 -0.57325006  0.05669355]\n",
      " [ 0.66683841 -0.55953646  0.59265637]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "window_size = 3\n",
    "vocabulary_size = 20\n",
    "collection_size = 5\n",
    "embedding_size = 3\n",
    "num_sampled = 2\n",
    "\n",
    "X_doc_batch = np.random.randint(low=0,\n",
    "                                high=collection_size,\n",
    "                                size=(batch_size, 1),\n",
    "                                dtype=np.int32)\n",
    "X_words_batch = np.random.randint(low=0,\n",
    "                                  high=vocabulary_size,\n",
    "                                  size=(batch_size, window_size-1),\n",
    "                                  dtype=np.int32)\n",
    "y_batch = np.random.randint(low=0,\n",
    "                            high=vocabulary_size,\n",
    "                            size=(batch_size, 1),\n",
    "                            dtype=np.int32)\n",
    "data_batch = (X_doc_batch, X_words_batch, y_batch)\n",
    "\n",
    "with tf.Graph().as_default() as graph, \\\n",
    "    tf.Session(graph=graph) as session:\n",
    "\n",
    "    inputs, embeddings, loss_op = \\\n",
    "        model_dm(collection_size,\n",
    "                 vocabulary_size,\n",
    "                 embedding_size,\n",
    "                 window_size,\n",
    "                 num_sampled)\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    data_feed = dict(zip(inputs, data_batch))\n",
    "    loss, doc_embeddings, word_embeddings = \\\n",
    "        session.run([loss_op,  *embeddings], data_feed)\n",
    "\n",
    "    print('Average loss:\\n\\n{:,.3f}\\n'.format(loss))\n",
    "    print('Document embeddings:\\n\\n{}\\n'.format(doc_embeddings))\n",
    "    print('Word embeddings:\\n\\n{}\\n'.format(word_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Bag-of-Words (DBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examples_generator_dbow(data: List[Tuple[int, int]],\n",
    "                            window_size: int) \\\n",
    "    -> Tuple[int, List[int], int]:\n",
    "    \n",
    "    num_examples = count_windows(data, window_size)\n",
    "    data_tail = collections.deque(data)\n",
    "    doc_id, window, tail = None, None, None\n",
    "\n",
    "    for _ in range(num_examples):\n",
    "        if not tail:\n",
    "            doc_id, window, tail = slice_document(data_tail, window_size)\n",
    "        else:\n",
    "            window.append(tail.popleft())\n",
    "        yield doc_id, list(window)\n",
    "\n",
    "assert len(list(examples_generator_dbow(data, 4))) == count_windows(data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dbow(data: List[Tuple[int, int]],\n",
    "               batch_size: int,\n",
    "               window_size: int,\n",
    "               shuffle=True) \\\n",
    "    -> Iterable[Tuple[np.ndarray, np.ndarray]]:\n",
    "    \n",
    "    examples = list(examples_generator_dbow(data, window_size))\n",
    "    if shuffle:\n",
    "        random.shuffle(examples)\n",
    "\n",
    "    num_examples = len(examples)\n",
    "    while num_examples > 0:\n",
    "        batch_size_i = min(batch_size, num_examples)\n",
    "        \n",
    "        doc_batch = np.ndarray(shape=(batch_size_i, 1), dtype=np.int32)\n",
    "        target_batch = \\\n",
    "            np.ndarray(shape=(batch_size_i, window_size), dtype=np.int32)\n",
    "\n",
    "        for i in range(batch_size_i):\n",
    "            doc_id, words = examples.pop()\n",
    "            doc_batch[i, 0] = doc_id\n",
    "            target_batch[i, :] = words\n",
    "        \n",
    "        num_examples -= batch_size_i\n",
    "        yield doc_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch steps: 20,489\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "window_size = 4\n",
    "\n",
    "n = 0\n",
    "for _ in input_dbow(data, batch_size, window_size):\n",
    "    n += 1\n",
    "print('Epoch steps: {:,d}'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "\n",
      "220991 -> can be said\n",
      "141095 -> hard to understand\n",
      "112899 -> of whatever idealism\n",
      "143158 -> or post-production stages\n",
      "\n",
      "Batch 2\n",
      "\n",
      "69597 -> sweetness , with\n",
      "184949 -> like a human\n",
      "182188 -> does n't galvanize\n",
      "221968 -> from her dangerous\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "window_size = 3\n",
    "num_iters = 2\n",
    "\n",
    "data_iter = input_dbow(data, batch_size, window_size)\n",
    "\n",
    "for k in range(1, num_iters+1):\n",
    "    print('Batch {}\\n'.format(k))\n",
    "    doc_batch, target_batch = next(data_iter)\n",
    "    for i in range(batch_size):\n",
    "        doc_ref = document_from_id[doc_batch[i, 0]]\n",
    "        target = ' '.join(token_from_id[token_id]\n",
    "                          for token_id in target_batch[i])\n",
    "        print('{} -> {}'.format(doc_ref, target))\n",
    "    print()\n",
    "\n",
    "del data_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f9da3baaac8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "window_size = 3\n",
    "collection_size = 5\n",
    "vocabulary_size = 20\n",
    "embedding_size = 3\n",
    "num_sampled = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(4, 1), dtype=int32) \n",
      "\n",
      "[[1]\n",
      " [4]\n",
      " [4]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant(np.random.randint(low=0,\n",
    "                                  high=collection_size,\n",
    "                                  size=(batch_size, 1),\n",
    "                                  dtype=np.int32))\n",
    "\n",
    "print(X, '\\n')\n",
    "print(X.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(4, 3), dtype=int32) \n",
      "\n",
      "[[ 0  4  6]\n",
      " [ 6  2  3]\n",
      " [ 9 11 19]\n",
      " [ 9 17 16]]\n"
     ]
    }
   ],
   "source": [
    "y = tf.constant(np.random.randint(low=0,\n",
    "                                  high=vocabulary_size,\n",
    "                                  size=(batch_size, window_size),\n",
    "                                  dtype=np.int32))\n",
    "\n",
    "print(y, '\\n')\n",
    "print(y.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32_ref> \n",
      "\n",
      "[[-0.61349183  0.77466398  0.45858532]\n",
      " [ 0.66857857 -0.04503886 -0.12617138]\n",
      " [ 0.60222524 -0.96931243 -0.58015776]\n",
      " [-0.5013777  -0.65873313  0.3652117 ]\n",
      " [-0.48010617 -0.93881094 -0.16271667]]\n"
     ]
    }
   ],
   "source": [
    "# ~ tf.random_uniform(shape=(collection_size, embedding_size),\n",
    "#                     minval=-1.0, maxval=1.0)\n",
    "doc_embeddings = tf.Variable(\n",
    "    2 * np.random.rand(collection_size, embedding_size) - 1, dtype=tf.float32)\n",
    "\n",
    "doc_embeddings.initializer.run()\n",
    "\n",
    "print(doc_embeddings, '\\n')\n",
    "print(doc_embeddings.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(4, 1, 3), dtype=float32) \n",
      "\n",
      "[[[ 0.66857857 -0.04503886 -0.12617138]]\n",
      "\n",
      " [[-0.48010617 -0.93881094 -0.16271667]]\n",
      "\n",
      " [[-0.48010617 -0.93881094 -0.16271667]]\n",
      "\n",
      " [[-0.61349183  0.77466398  0.45858532]]]\n"
     ]
    }
   ],
   "source": [
    "D_embed = tf.nn.embedding_lookup(doc_embeddings, X)\n",
    "\n",
    "print(D_embed, '\\n')\n",
    "print(D_embed.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze:0\", shape=(4, 3), dtype=float32) \n",
      "\n",
      "[[ 0.66857857 -0.04503886 -0.12617138]\n",
      " [-0.48010617 -0.93881094 -0.16271667]\n",
      " [-0.48010617 -0.93881094 -0.16271667]\n",
      " [-0.61349183  0.77466398  0.45858532]]\n"
     ]
    }
   ],
   "source": [
    "X_linear = tf.squeeze(D_embed, axis=1)\n",
    "\n",
    "print(X_linear, '\\n')\n",
    "print(X_linear.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_1:0' shape=(20, 3) dtype=float32_ref> \n",
      "\n",
      "[[-0.82627457 -0.39039791  0.81090957]\n",
      " [ 0.56913507 -0.41484466 -0.1717644 ]\n",
      " [-0.36643881 -0.40700886  0.40026474]\n",
      " [ 0.43798104 -0.11199692 -0.38186169]\n",
      " [-0.83280349  0.32550862 -0.70675701]\n",
      " [-0.17739746 -1.37478101  0.45252252]\n",
      " [-0.46652669 -0.27244434 -0.18778431]\n",
      " [ 0.53468007 -0.27579314  0.33644667]\n",
      " [-1.36255693  0.4423517  -0.28640082]\n",
      " [ 0.34280732 -0.45193434 -0.71272874]\n",
      " [ 0.32164633  0.69007677 -0.62571734]\n",
      " [-1.32908964 -0.05086939  0.12795296]\n",
      " [ 0.90208244  0.20637964 -0.16464441]\n",
      " [ 0.38290766 -0.06800617 -0.73474473]\n",
      " [-0.85834175  0.16015102  0.22423425]\n",
      " [ 0.74233687  0.10035369  0.05704785]\n",
      " [ 0.01810645  0.74310029 -0.06171733]\n",
      " [-0.8623957   0.02693488  0.28534612]\n",
      " [ 0.68768942 -0.81597233  0.30073568]\n",
      " [-0.01739639  0.08307558 -0.1174571 ]]\n"
     ]
    }
   ],
   "source": [
    "# ~ tf.truncated_normal(shape=(vocabulary_size, embedding_size),\n",
    "#                       stddev=1.0 / np.sqrt(embedding_size))\n",
    "W_linear = tf.Variable(\n",
    "    np.random.randn(vocabulary_size, embedding_size) / np.sqrt(embedding_size),\n",
    "    dtype=tf.float32)\n",
    "\n",
    "W_linear.initializer.run()\n",
    "\n",
    "print(W_linear, '\\n')\n",
    "print(W_linear.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_2:0' shape=(20,) dtype=float32_ref> \n",
      "\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# ~ tf.zeros(shape=(vocabulary_size,))\n",
    "b_linear = tf.Variable(np.zeros(vocabulary_size), dtype=tf.float32)\n",
    "\n",
    "b_linear.initializer.run()\n",
    "\n",
    "print(b_linear, '\\n')\n",
    "print(b_linear.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_2:0\", shape=(4,), dtype=float32) \n",
      "\n",
      "[ 2.75929332  1.84279549  1.40849543  1.84590399]\n"
     ]
    }
   ],
   "source": [
    "sampled_loss = tf.nn.sampled_softmax_loss(weights=W_linear,\n",
    "                                          biases=b_linear,\n",
    "                                          inputs=X_linear,\n",
    "                                          labels=y,\n",
    "                                          num_sampled=num_sampled,\n",
    "                                          num_classes=vocabulary_size,\n",
    "                                          num_true=window_size)\n",
    "\n",
    "print(sampled_loss, '\\n')\n",
    "print(sampled_loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32) \n",
      "\n",
      "1.84419\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(sampled_loss)\n",
    "\n",
    "print(loss, '\\n')\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.close()\n",
    "del X, y, doc_embeddings, D_embed\n",
    "del X_linear, W_linear, b_linear, sampled_loss, loss\n",
    "del graph, session\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dbow(collection_size: int,\n",
    "               vocabulary_size: int,\n",
    "               embedding_size: int,\n",
    "               window_size: int,\n",
    "               num_sampled: int) \\\n",
    "    -> Tuple[List[tf.Tensor], tf.Tensor, tf.Tensor]:\n",
    "    \n",
    "    X = tf.placeholder_with_default([[0]],\n",
    "                                    shape=(None, 1),\n",
    "                                    name='X')\n",
    "    y = tf.placeholder_with_default([[0]*window_size],\n",
    "                                    shape=(None, window_size),\n",
    "                                    name='y')\n",
    "\n",
    "    doc_embeddings = tf.Variable(\n",
    "        tf.random_uniform(shape=(collection_size, embedding_size),\n",
    "                          minval=-1.0, maxval=1.0),\n",
    "        name='doc_embeddings')\n",
    "\n",
    "    D_embed = tf.nn.embedding_lookup(doc_embeddings, X)\n",
    "    X_linear = tf.squeeze(D_embed, axis=1)\n",
    "    \n",
    "    W_linear = tf.Variable(\n",
    "        tf.truncated_normal(shape=(vocabulary_size, embedding_size),\n",
    "                            stddev=1.0 / np.sqrt(embedding_size)),\n",
    "        name='W')\n",
    "    b_linear = tf.Variable(\n",
    "        tf.zeros(shape=(vocabulary_size,)),\n",
    "        name='b')\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        sampled_loss = tf.nn.sampled_softmax_loss(weights=W_linear,\n",
    "                                                  biases=b_linear,\n",
    "                                                  inputs=X_linear,\n",
    "                                                  labels=y,\n",
    "                                                  num_sampled=num_sampled,\n",
    "                                                  num_classes=vocabulary_size,\n",
    "                                                  num_true=window_size)\n",
    "        loss = tf.reduce_mean(sampled_loss, name='mean')\n",
    "        \n",
    "    inputs = [X, y]\n",
    "    return inputs, doc_embeddings, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:\n",
      "\n",
      "1.398\n",
      "\n",
      "Document embeddings:\n",
      "\n",
      "[[ 0.94213724  0.11667156  0.86827254]\n",
      " [ 0.66263461  0.35906649  0.8484571 ]\n",
      " [ 0.31185198  0.13261962 -0.03142118]\n",
      " [ 0.10023284  0.80146909 -0.01191282]\n",
      " [-0.78691721  0.38137054  0.86561298]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "window_size = 3\n",
    "vocabulary_size = 20\n",
    "collection_size = 5\n",
    "embedding_size = 3\n",
    "num_sampled = 2\n",
    "\n",
    "X_batch = np.random.randint(low=0,\n",
    "                            high=collection_size,\n",
    "                            size=(batch_size, 1),\n",
    "                            dtype=np.int32)\n",
    "y_batch = np.random.randint(low=0,\n",
    "                            high=vocabulary_size,\n",
    "                            size=(batch_size, window_size),\n",
    "                            dtype=np.int32)\n",
    "data_batch = (X_batch, y_batch)\n",
    "\n",
    "with tf.Graph().as_default() as graph, \\\n",
    "    tf.Session(graph=graph) as session:\n",
    "\n",
    "    inputs, embeddings, loss_op = \\\n",
    "        model_dbow(collection_size,\n",
    "                   vocabulary_size,\n",
    "                   embedding_size,\n",
    "                   window_size,\n",
    "                   num_sampled)\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    data_feed = dict(zip(inputs, data_batch))\n",
    "    loss, doc_embeddings = \\\n",
    "        session.run([loss_op, embeddings], data_feed)\n",
    "\n",
    "    print('Average loss:\\n\\n{:,.3f}\\n'.format(loss))\n",
    "    print('Document embeddings:\\n\\n{}\\n'.format(doc_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: 8,544\n",
      "Batches (batch_size=16): 534\n",
      "Last (batch_size=16): 0\n"
     ]
    }
   ],
   "source": [
    "num_examples = len(train_data)\n",
    "num_batches_16 = math.ceil(num_examples / 16)\n",
    "last_batch_16 = num_examples % 16\n",
    "\n",
    "print('Examples: {:,d}'.format(num_examples))\n",
    "print('Batches (batch_size=16): {:,d}'.format(num_batches_16))\n",
    "print('Last (batch_size=16): {:,d}'.format(last_batch_16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_sentiment(data: List[Tuple[int, int]],\n",
    "                    batch_size: int,\n",
    "                    shuffle=True) \\\n",
    "    -> Iterable[Tuple[np.ndarray, np.ndarray]]:\n",
    "    \n",
    "    num_examples = len(data)\n",
    "    data_tail = collections.deque(data)\n",
    "    if shuffle:\n",
    "        random.shuffle(data_tail)\n",
    "    \n",
    "    while num_examples > 0:\n",
    "        batch_size_i = min(batch_size, num_examples)\n",
    "        \n",
    "        doc_batch = np.ndarray(shape=(batch_size_i, 1), dtype=np.int32)\n",
    "        target_batch = np.ndarray(shape=(batch_size_i, 1), dtype=np.int32)\n",
    "        \n",
    "        for i in range(batch_size_i):\n",
    "            doc_id, sentiment = data_tail.popleft()\n",
    "            doc_batch[i, 0] = doc_id\n",
    "            target_batch[i, 0] = sentiment\n",
    "        \n",
    "        num_examples -= batch_size_i\n",
    "        yield doc_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epcoh steps: 534\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "n = 0\n",
    "for _ in input_sentiment(train_data, batch_size):\n",
    "    n += 1\n",
    "print('Epcoh steps: {:,d}'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "\n",
      "224012 -> 0\n",
      "226719 -> 0\n",
      "63663 -> 1\n",
      "66646 -> 1\n",
      "\n",
      "Batch 2\n",
      "\n",
      "183842 -> 0\n",
      "66594 -> 1\n",
      "223497 -> 0\n",
      "110576 -> 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "num_iters = 2\n",
    "\n",
    "data_iter = input_sentiment(train_data, batch_size)\n",
    "\n",
    "for k in range(1, num_iters + 1):\n",
    "    print('Batch {}\\n'.format(k))\n",
    "    doc_batch, target_batch = next(data_iter)\n",
    "    for i in range(batch_size):\n",
    "        doc_ref = document_from_id[doc_batch[i, 0]]\n",
    "        sentiment_class = target_batch[i, 0]\n",
    "        print('{} -> {}'.format(doc_ref, sentiment_class))\n",
    "    print()\n",
    "\n",
    "del data_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f9da4aaafd0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "collection_size = 5\n",
    "embedding_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(4, 1), dtype=int32) \n",
      "\n",
      "[[2]\n",
      " [4]\n",
      " [4]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant(np.random.randint(low=0,\n",
    "                                  high=collection_size,\n",
    "                                  size=(batch_size, 1),\n",
    "                                  dtype=np.int32))\n",
    "\n",
    "print(X, '\\n')\n",
    "print(X.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(4, 1), dtype=int32) \n",
      "\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "y = tf.constant(np.random.randint(low=0,\n",
    "                                  high=2,\n",
    "                                  size=(batch_size, 1),\n",
    "                                  dtype=np.int32))\n",
    "\n",
    "print(y, '\\n')\n",
    "print(y.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32_ref> \n",
      "\n",
      "[[ 0.43830919  0.85851675  0.27750978]\n",
      " [-1.04084623  0.07217167 -1.79794228]\n",
      " [-0.29914698 -0.30388564  0.21007468]\n",
      " [ 0.12226102  0.35672107 -0.90264189]\n",
      " [-0.24634524 -0.98216307  0.30227593]]\n"
     ]
    }
   ],
   "source": [
    "embeddings_dm = tf.Variable(\n",
    "    np.random.randn(collection_size, embedding_size),\n",
    "    dtype=tf.float32,\n",
    "    trainable=False)\n",
    "\n",
    "embeddings_dm.initializer.run()\n",
    "\n",
    "print(embeddings_dm, '\\n')\n",
    "print(embeddings_dm.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_1:0' shape=(5, 3) dtype=float32_ref> \n",
      "\n",
      "[[-1.49994326  1.92934251  1.87464392]\n",
      " [ 0.1671124   0.17607364 -1.13918853]\n",
      " [-0.97666603 -0.20756362 -1.22162235]\n",
      " [-0.82695103 -0.28422162 -0.68925583]\n",
      " [ 0.49236581  0.86827451 -0.21970809]]\n"
     ]
    }
   ],
   "source": [
    "embeddings_dbow = tf.Variable(\n",
    "    np.random.randn(collection_size, embedding_size),\n",
    "    dtype=tf.float32,\n",
    "    trainable=False)\n",
    "\n",
    "embeddings_dbow.initializer.run()\n",
    "\n",
    "print(embeddings_dbow, '\\n')\n",
    "print(embeddings_dbow.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(4, 1, 3), dtype=float32) \n",
      "\n",
      "[[[-0.29914698 -0.30388564  0.21007468]]\n",
      "\n",
      " [[-0.24634524 -0.98216307  0.30227593]]\n",
      "\n",
      " [[-0.24634524 -0.98216307  0.30227593]]\n",
      "\n",
      " [[ 0.43830919  0.85851675  0.27750978]]]\n"
     ]
    }
   ],
   "source": [
    "X_dm = tf.nn.embedding_lookup(embeddings_dm, X)\n",
    "\n",
    "print(X_dm, '\\n')\n",
    "print(X_dm.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup_1:0\", shape=(4, 1, 3), dtype=float32) \n",
      "\n",
      "[[[-0.97666603 -0.20756362 -1.22162235]]\n",
      "\n",
      " [[ 0.49236581  0.86827451 -0.21970809]]\n",
      "\n",
      " [[ 0.49236581  0.86827451 -0.21970809]]\n",
      "\n",
      " [[-1.49994326  1.92934251  1.87464392]]]\n"
     ]
    }
   ],
   "source": [
    "X_dbow = tf.nn.embedding_lookup(embeddings_dbow, X)\n",
    "\n",
    "print(X_dbow, '\\n')\n",
    "print(X_dbow.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", shape=(4, 1, 6), dtype=float32) \n",
      "\n",
      "[[[-0.29914698 -0.30388564  0.21007468 -0.97666603 -0.20756362 -1.22162235]]\n",
      "\n",
      " [[-0.24634524 -0.98216307  0.30227593  0.49236581  0.86827451 -0.21970809]]\n",
      "\n",
      " [[-0.24634524 -0.98216307  0.30227593  0.49236581  0.86827451 -0.21970809]]\n",
      "\n",
      " [[ 0.43830919  0.85851675  0.27750978 -1.49994326  1.92934251  1.87464392]]]\n"
     ]
    }
   ],
   "source": [
    "X_embed = tf.concat([X_dm, X_dbow], axis=2)\n",
    "\n",
    "print(X_embed, '\\n')\n",
    "print(X_embed.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze:0\", shape=(4, 6), dtype=float32) \n",
      "\n",
      "[[-0.29914698 -0.30388564  0.21007468 -0.97666603 -0.20756362 -1.22162235]\n",
      " [-0.24634524 -0.98216307  0.30227593  0.49236581  0.86827451 -0.21970809]\n",
      " [-0.24634524 -0.98216307  0.30227593  0.49236581  0.86827451 -0.21970809]\n",
      " [ 0.43830919  0.85851675  0.27750978 -1.49994326  1.92934251  1.87464392]]\n"
     ]
    }
   ],
   "source": [
    "X_linear = tf.squeeze(X_embed, axis=1)\n",
    "\n",
    "print(X_linear, '\\n')\n",
    "print(X_linear.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_2:0' shape=(6, 1) dtype=float32_ref> \n",
      "\n",
      "[[-0.94533986]\n",
      " [-0.61754084]\n",
      " [-0.02720818]\n",
      " [ 0.04461898]\n",
      " [ 1.42896974]\n",
      " [ 0.06104174]]\n"
     ]
    }
   ],
   "source": [
    "# ~ tf.truncated_normal(shape=(2 * embedding_size, 1))\n",
    "W = tf.Variable(\n",
    "    np.random.randn(2 * embedding_size, 1),\n",
    "    dtype=tf.float32)\n",
    "\n",
    "W.initializer.run()\n",
    "\n",
    "print(W, '\\n')\n",
    "print(W.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_3:0' shape=(1,) dtype=float32_ref> \n",
      "\n",
      "[ 0.]\n"
     ]
    }
   ],
   "source": [
    "# ~ tf.zeros(shape=(1,))\n",
    "b = tf.Variable(np.zeros(1), dtype=tf.float32)\n",
    "\n",
    "b.initializer.run()\n",
    "\n",
    "print(b, '\\n')\n",
    "print(b.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"xw_plus_b:0\", shape=(4, 1), dtype=float32) \n",
      "\n",
      "[[ 0.04999167]\n",
      " [ 2.080477  ]\n",
      " [ 2.080477  ]\n",
      " [ 1.85240686]]\n"
     ]
    }
   ],
   "source": [
    "logits = tf.nn.xw_plus_b(X_linear, W, b)\n",
    "\n",
    "print(logits, '\\n')\n",
    "print(logits.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sigmoid:0\", shape=(4, 1), dtype=float32) \n",
      "\n",
      "[[ 0.51249534]\n",
      " [ 0.88899112]\n",
      " [ 0.88899112]\n",
      " [ 0.86440945]]\n"
     ]
    }
   ],
   "source": [
    "y_prob = tf.sigmoid(logits)\n",
    "\n",
    "print(y_prob, '\\n')\n",
    "print(y_prob.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast:0\", shape=(4, 1), dtype=int32) \n",
      "\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.cast(tf.greater_equal(y_prob, 0.5), tf.int32)\n",
    "\n",
    "print(y_hat, '\\n')\n",
    "print(y_hat.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sigmoid_cross_entropy_loss/value:0\", shape=(), dtype=float32) \n",
      "\n",
      "0.274875\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.sigmoid_cross_entropy(y, logits)\n",
    "\n",
    "print(loss, '\\n')\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"accuracy/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"accuracy/update_op:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "acc_tensor, acc_op = tf.metrics.accuracy(labels=y,\n",
    "                                         predictions=y_hat)\n",
    "\n",
    "print(acc_tensor)\n",
    "print(acc_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'accuracy/total:0' shape=() dtype=float32_ref> \n",
      "\n",
      "0.0 \n",
      "\n",
      "<tf.Variable 'accuracy/count:0' shape=() dtype=float32_ref> \n",
      "\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "*_, acc_total, acc_count = tf.local_variables()\n",
    "\n",
    "acc_init = tf.variables_initializer([acc_total, acc_count])\n",
    "acc_init.run()\n",
    "\n",
    "print(acc_total, '\\n')\n",
    "print(acc_total.eval(), '\\n')\n",
    "print(acc_count, '\\n')\n",
    "print(acc_count.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(acc_tensor.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]] \n",
      "\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]] \n",
      "\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(y.eval(), '\\n')\n",
    "print(y_hat.eval(), '\\n')\n",
    "print(acc_op.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "3.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(acc_tensor.eval())\n",
    "print(acc_total.eval())\n",
    "print(acc_count.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "acc_init.run()\n",
    "\n",
    "print(acc_tensor.eval())\n",
    "print(acc_total.eval())\n",
    "print(acc_count.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8168"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.close()\n",
    "del X, y, embeddings_dm, embeddings_dbow\n",
    "del X_dm, X_dbow, X_embed, X_linear\n",
    "del W, b, logits, y_prob, y_hat, loss\n",
    "del acc_tensor, acc_op, acc_total, acc_count, acc_init\n",
    "del graph, session\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_sentiment(collection_size: int,\n",
    "                    embedding_size: int,\n",
    "                    threshold=0.5) \\\n",
    "    -> Tuple[Tuple[List[tf.Tensor], tf.Operation], List[tf.Tensor], List[tf.Tensor], tf.Tensor]:\n",
    "\n",
    "    X = tf.placeholder_with_default([[0]], shape=(None, 1), name='X')\n",
    "    y = tf.placeholder_with_default([[0]], shape=(None, 1), name='y')\n",
    "    \n",
    "    embeddings_dm = tf.Variable(tf.zeros(shape=(collection_size, embedding_size)),\n",
    "                                trainable=False,\n",
    "                                name='embeddings_dm')\n",
    "    embeddings_dbow = tf.Variable(tf.zeros(shape=(collection_size, embedding_size)),\n",
    "                                  trainable=False,\n",
    "                                  name='embeddings_dbow')\n",
    "    \n",
    "    X_dm = tf.nn.embedding_lookup(embeddings_dm, X)\n",
    "    X_dbow = tf.nn.embedding_lookup(embeddings_dbow, X)\n",
    "    X_embed = tf.concat([X_dm, X_dbow], axis=2)\n",
    "    X_linear = tf.squeeze(X_embed, axis=1)\n",
    "\n",
    "    W = tf.Variable(\n",
    "        tf.truncated_normal(shape=(2 * embedding_size, 1)),\n",
    "        name='W')\n",
    "    b = tf.Variable(\n",
    "        tf.zeros(shape=(1,)),\n",
    "        name = 'b')\n",
    "    logits = tf.nn.xw_plus_b(X_linear, W, b)\n",
    "    y_prob = tf.sigmoid(logits)\n",
    "    y_hat = tf.cast(tf.greater_equal(y_prob, threshold), tf.int32)\n",
    "    \n",
    "    loss = tf.losses.sigmoid_cross_entropy(y, logits)\n",
    "    \n",
    "    embeddings_dm_input = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape=(collection_size, embedding_size),\n",
    "        name='embeddings_dm_input')\n",
    "    embeddings_dbow_input = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape=(collection_size, embedding_size),\n",
    "        name='embeddings_dbow_input')\n",
    "    embeddings_init_op = tf.group(\n",
    "        tf.assign(embeddings_dm, embeddings_dm_input),\n",
    "        tf.assign(embeddings_dbow, embeddings_dbow_input))\n",
    "    embeddings_inputs = [embeddings_dm_input, embeddings_dbow_input]\n",
    "    embeddings_init = (embeddings_inputs, embeddings_init_op)\n",
    "\n",
    "    inputs = [X, y]\n",
    "    predictions = [y_prob, y_hat]\n",
    "    return embeddings_init, inputs, predictions, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.981\n",
      "\n",
      "y=0, ŷ=0 (10.89%)\n",
      "y=1, ŷ=1 (78.08%)\n",
      "y=1, ŷ=0 (12.95%)\n",
      "y=0, ŷ=1 (78.08%)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "collection_size = 5\n",
    "embedding_size = 3\n",
    "\n",
    "embeddings1 = np.random.randn(collection_size,\n",
    "                              embedding_size)\n",
    "embeddings2 = np.random.randn(collection_size,\n",
    "                              embedding_size)\n",
    "embeddings = [embeddings1.astype(np.float32),\n",
    "              embeddings2.astype(np.float32)]\n",
    "\n",
    "X_batch = np.random.randint(low=0,\n",
    "                            high=collection_size,\n",
    "                            size=(batch_size, 1),\n",
    "                            dtype=np.int32)\n",
    "y_batch = np.random.randint(low=0,\n",
    "                            high=2,\n",
    "                            size=(batch_size, 1),\n",
    "                            dtype=np.int32)\n",
    "data_batch = (X_batch, y_batch)\n",
    "\n",
    "with tf.Graph().as_default() as graph, \\\n",
    "    tf.Session(graph=graph) as session:\n",
    "\n",
    "    init, inputs, predictions, loss_op = \\\n",
    "        model_sentiment(collection_size, embedding_size)\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    init_feed = dict(zip(init[0], embeddings))\n",
    "    session.run(init[1], init_feed)\n",
    "    \n",
    "    data_feed = dict(zip(inputs, data_batch))\n",
    "    loss, y_prob, y_hat = session.run([loss_op, *predictions],\n",
    "                                      data_feed)\n",
    "    \n",
    "    print('Average loss: {:,.3f}\\n'.format(loss))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        print('y={}, ŷ={} ({:.2f}%)'.format(y_batch[i, 0],\n",
    "                                            y_hat[i, 0],\n",
    "                                            100 * y_prob[i, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_DIR =  os.path.join(HOME_DIR, 'xxx')\n",
    "\n",
    "DM_DIR = os.path.join(EXP_DIR, 'pv_dm')\n",
    "DBOW_DIR = os.path.join(EXP_DIR, 'pv_dbow')\n",
    "SENT_DIR = os.path.join(EXP_DIR, 'sentiment_linear')\n",
    "\n",
    "DM_FILE = os.path.join(EXP_DIR, 'pv_dm.txt')\n",
    "DM_WORDS_FILE = os.path.join(EXP_DIR, 'pv_dm_words.txt')\n",
    "DBOW_FILE = os.path.join(EXP_DIR, 'pv_dbow.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dir(path):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "remove_dir(EXP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_adagrad(loss, learning_rate=1.0):\n",
    "    return tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        optimizer='Adagrad',\n",
    "        learning_rate=learning_rate,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        summaries=['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_average_loss(loss_op, summary_key):\n",
    "    value, update = tf.metrics.mean(loss_op, name='metrics/average_loss')\n",
    "    *_, total, count = tf.local_variables()\n",
    "    reset = tf.variables_initializer([total, count])\n",
    "    tf.summary.scalar('average_loss', value, [summary_key])\n",
    "    return value, update, reset\n",
    "    \n",
    "def train_embeddings(model_fn, input_fn, opt_fn, num_epochs=1, last_print=True,\n",
    "                     model_dir='/tmp/embedding_model', remove_model=True):\n",
    "    if remove_model:\n",
    "        remove_dir(model_dir)\n",
    "\n",
    "    EPOCH_SUMMARIES = 'epoch_summaries'\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        global_step = tf.train.create_global_step()\n",
    "\n",
    "        inputs, embeddings, loss_op = model_fn()\n",
    "        train_op = opt_fn(loss_op)\n",
    "\n",
    "        avg_tensor, avg_op, avg_reset = \\\n",
    "            metrics_average_loss(loss_op, EPOCH_SUMMARIES)\n",
    "\n",
    "        epoch_summary_op = tf.summary.merge_all(EPOCH_SUMMARIES)\n",
    "\n",
    "        with tf.train.MonitoredTrainingSession(\n",
    "            checkpoint_dir=model_dir) as session:\n",
    "\n",
    "            for epoch in range(1, num_epochs+1):\n",
    "                #print('Epoch {}...'.format(epoch))\n",
    "\n",
    "                for data_batch in input_fn():\n",
    "                    data_feed = dict(zip(inputs, data_batch))\n",
    "                    session.run([train_op, avg_op], data_feed)\n",
    "\n",
    "                epoch_summary_proto, step_ = session.run([epoch_summary_op,\n",
    "                                                          global_step])\n",
    "                summary_writer = tf.summary.FileWriterCache.get(model_dir)\n",
    "                summary_writer.add_summary(epoch_summary_proto, step_)\n",
    "                summary_writer.flush()\n",
    "\n",
    "                avg_loss = session.run(avg_tensor)\n",
    "                session.run(avg_reset)\n",
    "            \n",
    "            embeddings_ = session.run(embeddings)\n",
    "        \n",
    "        tf.summary.FileWriterCache.clear()\n",
    "    \n",
    "    if last_print:\n",
    "        print('Last average loss: {:.4f}'.format(avg_loss))\n",
    "    return embeddings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last average loss: 3.8960\n",
      "CPU times: user 2min 24s, sys: 8.21 s, total: 2min 32s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "collection_size = len(document_to_id)\n",
    "vocabulary_size = len(token_to_id)\n",
    "embedding_size = 25\n",
    "window_size = 4\n",
    "num_sampled = 100\n",
    "batch_size = 64\n",
    "\n",
    "model_fn = lambda: model_dm(collection_size,\n",
    "                            vocabulary_size,\n",
    "                            embedding_size,\n",
    "                            window_size,\n",
    "                            num_sampled,\n",
    "                            linear_input='average')\n",
    "input_fn = lambda: input_dm(data,\n",
    "                            batch_size,\n",
    "                            window_size)\n",
    "\n",
    "embeddings_dm, embeddings_dm_words = \\\n",
    "    train_embeddings(model_fn,\n",
    "                     input_fn,\n",
    "                     opt_adagrad,\n",
    "                     num_epochs=1,\n",
    "                     model_dir=DM_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last average loss: 4.5411\n",
      "CPU times: user 1min 53s, sys: 4.05 s, total: 1min 57s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "collection_size = len(document_to_id)\n",
    "vocabulary_size = len(token_to_id)\n",
    "embedding_size = 25\n",
    "window_size = 4\n",
    "num_sampled = 100\n",
    "batch_size = 64\n",
    "\n",
    "model_fn = lambda: model_dbow(collection_size,\n",
    "                              vocabulary_size,\n",
    "                              embedding_size,\n",
    "                              window_size,\n",
    "                              num_sampled)\n",
    "input_fn = lambda: input_dbow(data,\n",
    "                              batch_size,\n",
    "                              window_size)\n",
    "\n",
    "embeddings_dbow = train_embeddings(model_fn,\n",
    "                                   input_fn,\n",
    "                                   opt_adagrad,\n",
    "                                   num_epochs=1,\n",
    "                                   model_dir=DBOW_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_ftrl(loss, learning_rate=0.1):\n",
    "    return tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        optimizer='Ftrl',\n",
    "        learning_rate=learning_rate,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        summaries=['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_accuracy(mode, labels, predictions, summary_key):\n",
    "    value, update = tf.metrics.accuracy(labels=labels,\n",
    "                                        predictions=predictions,\n",
    "                                        name='metrics/accuracy/' + mode)\n",
    "    *_, total, count = tf.local_variables()\n",
    "    reset = tf.variables_initializer([total, count])\n",
    "    tf.summary.scalar('accuracy/' + mode, value, [summary_key])\n",
    "    return value, update, reset\n",
    "\n",
    "def metrics_auc(mode, labels, predictions, summary_key):\n",
    "    value, update = tf.metrics.auc(labels=labels,\n",
    "                                   predictions=predictions,\n",
    "                                   name='metrics/auc/' + mode)\n",
    "    *_, tp, tn, fp, fn = tf.local_variables()\n",
    "    reset = tf.variables_initializer([tp, tn, fp, fn])\n",
    "    tf.summary.scalar('auc/' + mode, value, [summary_key])\n",
    "    return value, update, reset\n",
    "\n",
    "\n",
    "def train_sentiment_pv(model_fn, input_fn, opt_fn, embeddings,\n",
    "                       eval_data, num_epochs=1, last_print=True,\n",
    "                       model_dir='/tmp/classifier_model', remove_model=True):\n",
    "    if remove_model:\n",
    "        remove_dir(model_dir)\n",
    "\n",
    "    EPOCH_SUMMARIES = 'epoch_summaries'\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        global_step = tf.train.create_global_step()\n",
    "        \n",
    "        init, inputs, predictions, loss_op = model_fn()\n",
    "        train_op = opt_fn(loss_op)\n",
    "\n",
    "        avg_tensor, avg_op, avg_reset = \\\n",
    "            metrics_average_loss(loss_op, EPOCH_SUMMARIES)\n",
    "        \n",
    "        _, y = inputs\n",
    "        y_prob, y_hat = predictions\n",
    "        \n",
    "        auc_tensor, auc_op, auc_reset = \\\n",
    "            metrics_auc('train', y, y_prob, EPOCH_SUMMARIES)\n",
    "        auc_eval_tensor, auc_eval_op, auc_eval_reset = \\\n",
    "            metrics_auc('eval', y, y_prob, EPOCH_SUMMARIES)\n",
    "\n",
    "        acc_tensor, acc_op, acc_reset = \\\n",
    "            metrics_accuracy('train', y, y_hat, EPOCH_SUMMARIES)\n",
    "        acc_eval_tensor, acc_eval_op, acc_eval_reset = \\\n",
    "            metrics_accuracy('eval', y, y_hat, EPOCH_SUMMARIES)\n",
    "\n",
    "        eval_feed = dict(zip(inputs, eval_data))\n",
    "        \n",
    "        epoch_summary_op = tf.summary.merge_all(EPOCH_SUMMARIES)\n",
    "        \n",
    "        loop_ops = [train_op, avg_op, auc_op, acc_op]\n",
    "        eval_ops = [auc_eval_op, acc_eval_op]\n",
    "        reset_ops = [avg_reset, auc_reset, acc_reset,\n",
    "                     auc_eval_reset, acc_eval_reset]\n",
    "        \n",
    "        with tf.train.MonitoredTrainingSession(\n",
    "            checkpoint_dir=model_dir) as session:\n",
    "            \n",
    "            init_feed = dict(zip(init[0], embeddings))\n",
    "            session.run(init[1], init_feed)\n",
    "            \n",
    "            for epoch in range(1, num_epochs+1):\n",
    "                #print('Epoch {}...'.format(epoch))\n",
    "                \n",
    "                for data_batch in input_fn():\n",
    "                    data_feed = dict(zip(inputs, data_batch))\n",
    "                    session.run(loop_ops, data_feed)\n",
    "\n",
    "                session.run(eval_ops, eval_feed)\n",
    "                \n",
    "                epoch_summary_proto, step_ = session.run([epoch_summary_op,\n",
    "                                                          global_step])\n",
    "                summary_writer = tf.summary.FileWriterCache.get(model_dir)\n",
    "                summary_writer.add_summary(epoch_summary_proto, step_)\n",
    "                summary_writer.flush()\n",
    "\n",
    "                avg_loss = session.run(avg_tensor)\n",
    "                auc = session.run(auc_tensor)\n",
    "                auc_eval = session.run(auc_eval_tensor)\n",
    "                acc = session.run(acc_tensor)\n",
    "                acc_eval = session.run(acc_eval_tensor)\n",
    "\n",
    "                session.run(reset_ops)\n",
    "\n",
    "            tf.summary.FileWriterCache.clear()\n",
    "\n",
    "    if last_print:\n",
    "        print('Last average loss: {:.3f}'.format(avg_loss))\n",
    "        print('Last AUC: {:.3f}, eval {:.3f}'.format(auc, auc_eval))\n",
    "        print('Last accuracy: {:.2f}, eval {:.2f}'.format(\n",
    "            100 * acc, 100 * acc_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_split(data: List[Tuple[int, int]]) \\\n",
    "    -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X, y = zip(*data)\n",
    "    X = np.reshape(X, (-1, 1))\n",
    "    y = np.reshape(y, (-1, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last average loss: 0.703\n",
      "Last AUC: 0.492, eval 0.495\n",
      "Last accuracy: 49.34, eval 48.68\n",
      "CPU times: user 2.1 s, sys: 192 ms, total: 2.29 s\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "collection_size = len(document_to_id)\n",
    "embedding_size = 25\n",
    "batch_size = 16\n",
    "\n",
    "valid_data_ = input_split(valid_data)\n",
    "\n",
    "model_fn = lambda: model_sentiment(collection_size,\n",
    "                                   embedding_size)\n",
    "input_fn = lambda: input_sentiment(train_data,\n",
    "                                   batch_size)\n",
    "\n",
    "train_sentiment_pv(model_fn,\n",
    "                   input_fn,\n",
    "                   opt_ftrl,\n",
    "                   [embeddings_dm, embeddings_dbow],\n",
    "                   valid_data_,\n",
    "                   num_epochs=1,\n",
    "                   model_dir=SENT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.696\n",
      "AUC: 0.506\n",
      "Accuracy: 50.54\n"
     ]
    }
   ],
   "source": [
    "collection_size = len(document_to_id)\n",
    "embedding_size = 25\n",
    "batch_size = 16\n",
    "\n",
    "eval_data = input_split(test_data)\n",
    "\n",
    "embeddings = [embeddings_dm, embeddings_dbow]\n",
    "\n",
    "with tf.Graph().as_default() as graph, \\\n",
    "    tf.Session(graph=graph) as session:\n",
    "    \n",
    "    init, inputs, predictions, loss_op = \\\n",
    "        model_sentiment(collection_size,\n",
    "                        embedding_size)\n",
    "\n",
    "    _, y = inputs\n",
    "    y_prob, y_hat = predictions\n",
    "\n",
    "    EPOCH_SUMMARIES = 'epoch_summaries'\n",
    "    avg_tensor, avg_op, avg_reset = \\\n",
    "        metrics_average_loss(loss_op, EPOCH_SUMMARIES)\n",
    "    auc_eval_tensor, auc_eval_op, auc_eval_reset = \\\n",
    "        metrics_auc('eval', y, y_prob, EPOCH_SUMMARIES)\n",
    "    acc_eval_tensor, acc_eval_op, acc_eval_reset = \\\n",
    "        metrics_accuracy('eval', y, y_hat, EPOCH_SUMMARIES)\n",
    "\n",
    "    eval_feed = dict(zip(inputs, eval_data))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, tf.train.latest_checkpoint(SENT_DIR))\n",
    "\n",
    "    session.run(tf.local_variables_initializer())\n",
    "\n",
    "    init_feed = dict(zip(init[0], embeddings))\n",
    "    session.run(init[1], init_feed)\n",
    "\n",
    "    session.run([avg_op, auc_eval_op, acc_eval_op], eval_feed)\n",
    "    \n",
    "    avg_loss = session.run(avg_tensor)\n",
    "    auc_eval = session.run(auc_eval_tensor)\n",
    "    acc_eval = session.run(acc_eval_tensor)\n",
    "\n",
    "print('Average loss: {:.3f}'.format(avg_loss))\n",
    "print('AUC: {:.3f}'.format(auc_eval))\n",
    "print('Accuracy: {:.2f}'.format(100 * acc_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(file: str, embeddings: np.ndarray):\n",
    "    with open(file, 'w') as f:\n",
    "        num_vectors = embeddings.shape[0]\n",
    "        for i in range(num_vectors):\n",
    "            embedding = embeddings[i]\n",
    "            embedding_string = ('{:.5f}'.format(k) for k in embedding)\n",
    "            embedding_string = ' '.join(embedding_string)\n",
    "            f.write(embedding_string)\n",
    "            f.write('\\n')\n",
    "\n",
    "def load_embeddings(file: str) -> np.ndarray:\n",
    "    with open(file, 'r') as f:\n",
    "        vectors = list(list(map(float, line.split())) for line in f)\n",
    "        return np.asarray(vectors, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings file size: 50,836,170 bytes\n"
     ]
    }
   ],
   "source": [
    "save_embeddings(DM_FILE, embeddings_dm)\n",
    "print('Embeddings file size: {:,d} bytes'.format(os.stat(DM_FILE).st_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings file size: 4,083,149 bytes\n"
     ]
    }
   ],
   "source": [
    "save_embeddings(DM_WORDS_FILE, embeddings_dm_words)\n",
    "print('Embeddings file size: {:,d} bytes'.format(os.stat(DM_WORDS_FILE).st_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings file size: 50,836,650 bytes\n"
     ]
    }
   ],
   "source": [
    "save_embeddings(DBOW_FILE, embeddings_dbow)\n",
    "print('Embeddings file size: {:,d} bytes'.format(os.stat(DBOW_FILE).st_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71857"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del embeddings_dm, embeddings_dm_words, embeddings_dbow\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DM embeddings...\n",
      "CPU times: user 3.06 s, sys: 79.6 ms, total: 3.14 s\n",
      "Wall time: 3.14 s\n",
      "Loading DBOW embeddings...\n",
      "CPU times: user 2.97 s, sys: 89.6 ms, total: 3.05 s\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    embeddings_dm\n",
    "except NameError:\n",
    "    print('Loading DM embeddings...')\n",
    "    %time embeddings_dm = load_embeddings(DM_FILE)\n",
    "try:\n",
    "    embeddings_dbow\n",
    "except NameError:\n",
    "    print('Loading DBOW embeddings...')\n",
    "    %time embeddings_dbow = load_embeddings(DBOW_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last average loss: 0.696\n",
      "Last AUC: 0.510, eval 0.491\n",
      "Last accuracy: 50.98, eval 49.14\n",
      "CPU times: user 2.15 s, sys: 159 ms, total: 2.31 s\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "collection_size = len(document_to_id)\n",
    "embedding_size = 25\n",
    "batch_size = 16\n",
    "\n",
    "valid_data_ = input_split(valid_data)\n",
    "\n",
    "model_fn = lambda: model_sentiment(collection_size,\n",
    "                                   embedding_size)\n",
    "input_fn = lambda: input_sentiment(train_data,\n",
    "                                   batch_size)\n",
    "\n",
    "train_sentiment_pv(model_fn,\n",
    "                   input_fn,\n",
    "                   opt_ftrl,\n",
    "                   [embeddings_dm, embeddings_dbow],\n",
    "                   valid_data_,\n",
    "                   num_epochs=1,\n",
    "                   model_dir=SENT_DIR,\n",
    "                   remove_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40011"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del embeddings_dm, embeddings_dbow\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir(EXP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dm_fn(data: List[Tuple[int, int]],\n",
    "                collection_size: int,\n",
    "                vocabulary_size: int,\n",
    "                embedding_size: int,\n",
    "                window_size: int,\n",
    "                num_sampled: int,\n",
    "                linear_input: str,\n",
    "                batch_size: int,\n",
    "                num_epochs=1,\n",
    "                model_dir=DM_DIR) \\\n",
    "    -> Callable[[], Tuple[np.ndarray, np.array]]:\n",
    "\n",
    "    model_fn = functools.partial(model_dm,\n",
    "                                 collection_size,\n",
    "                                 vocabulary_size,\n",
    "                                 embedding_size,\n",
    "                                 window_size,\n",
    "                                 num_sampled,\n",
    "                                 linear_input)\n",
    "    input_fn = functools.partial(input_dm,\n",
    "                                 data,\n",
    "                                 batch_size,\n",
    "                                 window_size)\n",
    "\n",
    "    return functools.partial(train_embeddings,\n",
    "                             model_fn,\n",
    "                             input_fn,\n",
    "                             opt_adagrad,\n",
    "                             num_epochs=num_epochs,\n",
    "                             model_dir=model_dir,\n",
    "                             remove_model=False)\n",
    "\n",
    "def train_dbow_fn(data: List[Tuple[int, int]],\n",
    "                  collection_size: int,\n",
    "                  vocabulary_size: int,\n",
    "                  embedding_size: int,\n",
    "                  window_size: int,\n",
    "                  num_sampled: int,\n",
    "                  batch_size: int,\n",
    "                  num_epochs=1,\n",
    "                  model_dir=DBOW_DIR) \\\n",
    "    -> Callable[[], np.ndarray]:\n",
    "\n",
    "    model_fn = functools.partial(model_dbow,\n",
    "                                 collection_size,\n",
    "                                 vocabulary_size,\n",
    "                                 embedding_size,\n",
    "                                 window_size,\n",
    "                                 num_sampled)\n",
    "    input_fn = functools.partial(input_dbow,\n",
    "                                 data,\n",
    "                                 batch_size,\n",
    "                                 window_size)\n",
    "\n",
    "    return functools.partial(train_embeddings,\n",
    "                             model_fn,\n",
    "                             input_fn,\n",
    "                             opt_adagrad,\n",
    "                             num_epochs=num_epochs,\n",
    "                             model_dir=model_dir,\n",
    "                             remove_model=False)\n",
    "\n",
    "def train_sentiment_fn(train_data: List[Tuple[int, int]],\n",
    "                       eval_data: List[Tuple[int, int]],\n",
    "                       collection_size: int,\n",
    "                       embedding_size: int,\n",
    "                       batch_size: int,\n",
    "                       num_epochs=2,\n",
    "                       model_dir=SENT_DIR) \\\n",
    "    -> Callable[[List[np.ndarray]], None]:\n",
    "\n",
    "    eval_data_ = input_split(eval_data)\n",
    "    \n",
    "    model_fn = functools.partial(model_sentiment,\n",
    "                                 collection_size,\n",
    "                                 embedding_size)\n",
    "    input_fn = functools.partial(input_sentiment,\n",
    "                                 train_data,\n",
    "                                 batch_size)\n",
    "\n",
    "    return functools.partial(train_sentiment_pv,\n",
    "                             model_fn,\n",
    "                             input_fn,\n",
    "                             opt_ftrl,\n",
    "                             eval_data=eval_data_,\n",
    "                             num_epochs=num_epochs,\n",
    "                             model_dir=model_dir,\n",
    "                             remove_model=False)\n",
    "\n",
    "def run_experiment(name: str,\n",
    "                   num_iters: int,\n",
    "                   log_steps: int,\n",
    "                   data: List[Tuple[int, int]],\n",
    "                   train_data: List[Tuple[int, int]],\n",
    "                   eval_data: List[Tuple[int, int]],\n",
    "                   collection_size: int,\n",
    "                   vocabulary_size: int,\n",
    "                   embedding_size: int,\n",
    "                   window_size: int,\n",
    "                   num_sampled: int,\n",
    "                   dm_linear: str,\n",
    "                   batch_size: int,\n",
    "                   remove_home=False):\n",
    "\n",
    "    exp_dir = os.path.join(HOME_DIR, name) \n",
    "    if remove_home:\n",
    "        remove_dir(exp_dir)\n",
    "\n",
    "    dm_dir = os.path.join(exp_dir, 'pv_dm')\n",
    "    dbow_dir = os.path.join(exp_dir, 'pv_dbow')\n",
    "    sent_dm_dir = os.path.join(exp_dir, 'sent_dm')\n",
    "    sent_dbow_dir = os.path.join(exp_dir, 'sent_dbow')\n",
    "    sent_dir = os.path.join(exp_dir, 'sent')\n",
    "\n",
    "    dm_file = os.path.join(exp_dir, 'pv_dm.txt')\n",
    "    dm_words_file = os.path.join(exp_dir, 'pv_dm_words.txt')\n",
    "    dbow_file = os.path.join(exp_dir, 'pv_dbow.txt')\n",
    "\n",
    "    train_dm = train_dm_fn(\n",
    "        data,\n",
    "        collection_size,\n",
    "        vocabulary_size,\n",
    "        embedding_size,\n",
    "        window_size,\n",
    "        num_sampled,\n",
    "        dm_linear,\n",
    "        batch_size,\n",
    "        model_dir=dm_dir)\n",
    "\n",
    "    train_dbow = train_dbow_fn(\n",
    "        data,\n",
    "        collection_size,\n",
    "        vocabulary_size,\n",
    "        embedding_size,\n",
    "        window_size,\n",
    "        num_sampled,\n",
    "        batch_size,\n",
    "        model_dir=dbow_dir)\n",
    "\n",
    "    train_sentiment = train_sentiment_fn(\n",
    "        train_data,\n",
    "        eval_data,\n",
    "        collection_size,\n",
    "        embedding_size,\n",
    "        batch_size=16)\n",
    "\n",
    "    no_embeddings = np.zeros((collection_size, embedding_size),\n",
    "                             dtype=np.float32)\n",
    "    \n",
    "    for k in range(1, num_iters+1):\n",
    "        print_step = k == 1 or k == num_iters or k % log_steps == 0\n",
    "        if print_step: print('[ {} ]\\n'.format(k))\n",
    "        if print_step: print('DM...\\n')\n",
    "\n",
    "        embeddings_dm, embeddings_dm_words = \\\n",
    "            train_dm(last_print=print_step)\n",
    "        \n",
    "        if print_step: print('\\nDBOW...\\n')\n",
    "        \n",
    "        embeddings_dbow = train_dbow(last_print=print_step)\n",
    "        \n",
    "        embeddings_dm = embeddings_dm \\\n",
    "            / np.linalg.norm(embeddings_dm, axis=1, keepdims=True)\n",
    "        embeddings_dbow = embeddings_dbow \\\n",
    "            / np.linalg.norm(embeddings_dbow, axis=1, keepdims=True)\n",
    "        \n",
    "        if print_step: print('\\nSentiment...\\n')\n",
    "\n",
    "        train_sentiment([embeddings_dm / 2, embeddings_dbow / 2],\n",
    "                        model_dir=sent_dir,\n",
    "                        last_print=print_step)\n",
    "        \n",
    "        if print_step: print('\\nSentiment DM-only...\\n')\n",
    "        \n",
    "        train_sentiment([embeddings_dm, no_embeddings],\n",
    "                        model_dir=sent_dm_dir,\n",
    "                        last_print=print_step)\n",
    "        if print_step: print('\\nSentiment DBOW-only...\\n')\n",
    "        \n",
    "        train_sentiment([embeddings_dbow, no_embeddings],\n",
    "                        model_dir=sent_dbow_dir,\n",
    "                        last_print=print_step)\n",
    "        \n",
    "        if print_step: print()\n",
    "    \n",
    "    save_embeddings(dm_file, embeddings_dm)\n",
    "    print('DM Embeddings file size: {:,d} bytes'.format(os.stat(dm_file).st_size))\n",
    "    save_embeddings(dm_words_file, embeddings_dm_words)\n",
    "    print('DM Word Embeddings file size: {:,d} bytes'.format(os.stat(dm_words_file).st_size))\n",
    "    save_embeddings(dbow_file, embeddings_dbow)\n",
    "    print('DBOW Embeddings file size: {:,d} bytes'.format(os.stat(dbow_file).st_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_params = dict(num_iters=25,\n",
    "                     log_steps=5,\n",
    "                     data=data,\n",
    "                     train_data=train_data,\n",
    "                     eval_data=valid_data,\n",
    "                     collection_size=len(document_to_id),\n",
    "                     vocabulary_size=len(token_to_id),\n",
    "                     num_sampled=100,\n",
    "                     batch_size=64,\n",
    "                     remove_home=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 3.6848\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 4.5622\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.693\n",
      "Last AUC: 0.520, eval 0.506\n",
      "Last accuracy: 51.23, eval 50.41\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.693\n",
      "Last AUC: 0.515, eval 0.499\n",
      "Last accuracy: 50.64, eval 51.32\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.693\n",
      "Last AUC: 0.513, eval 0.505\n",
      "Last accuracy: 50.49, eval 50.59\n",
      "\n",
      "[ 5 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 2.3938\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 4.1841\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.689\n",
      "Last AUC: 0.555, eval 0.526\n",
      "Last accuracy: 53.73, eval 51.95\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.690\n",
      "Last AUC: 0.544, eval 0.521\n",
      "Last accuracy: 53.11, eval 51.86\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.692\n",
      "Last AUC: 0.532, eval 0.516\n",
      "Last accuracy: 51.99, eval 50.95\n",
      "\n",
      "[ 10 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.8530\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 3.5868\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.676\n",
      "Last AUC: 0.611, eval 0.600\n",
      "Last accuracy: 58.12, eval 58.67\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.683\n",
      "Last AUC: 0.582, eval 0.575\n",
      "Last accuracy: 56.06, eval 56.04\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.681\n",
      "Last AUC: 0.589, eval 0.589\n",
      "Last accuracy: 56.59, eval 56.77\n",
      "\n",
      "[ 15 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.4657\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 3.0562\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.657\n",
      "Last AUC: 0.656, eval 0.663\n",
      "Last accuracy: 60.83, eval 61.85\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.676\n",
      "Last AUC: 0.606, eval 0.614\n",
      "Last accuracy: 58.01, eval 58.40\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.662\n",
      "Last AUC: 0.642, eval 0.654\n",
      "Last accuracy: 60.16, eval 60.40\n",
      "\n",
      "[ 20 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.1894\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 2.7173\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.643\n",
      "Last AUC: 0.680, eval 0.697\n",
      "Last accuracy: 62.73, eval 64.40\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.670\n",
      "Last AUC: 0.621, eval 0.637\n",
      "Last accuracy: 58.58, eval 60.13\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.650\n",
      "Last AUC: 0.665, eval 0.682\n",
      "Last accuracy: 61.48, eval 62.58\n",
      "\n",
      "[ 25 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.0174\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 2.5132\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.635\n",
      "Last AUC: 0.692, eval 0.713\n",
      "Last accuracy: 63.73, eval 65.67\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.667\n",
      "Last AUC: 0.630, eval 0.653\n",
      "Last accuracy: 59.46, eval 60.58\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.644\n",
      "Last AUC: 0.676, eval 0.694\n",
      "Last accuracy: 62.39, eval 64.21\n",
      "\n",
      "DM Embeddings file size: 50,837,983 bytes\n",
      "DM Word Embeddings file size: 4,089,892 bytes\n",
      "DBOW Embeddings file size: 50,838,098 bytes\n"
     ]
    }
   ],
   "source": [
    "run_experiment(name='25_2_avg',\n",
    "               embedding_size=25,\n",
    "               window_size=2,\n",
    "               dm_linear='average',\n",
    "               **common_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 3.8960\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 4.5404\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.692\n",
      "Last AUC: 0.527, eval 0.489\n",
      "Last accuracy: 51.97, eval 47.23\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.693\n",
      "Last AUC: 0.520, eval 0.509\n",
      "Last accuracy: 51.92, eval 50.86\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.693\n",
      "Last AUC: 0.515, eval 0.487\n",
      "Last accuracy: 50.42, eval 47.87\n",
      "\n",
      "[ 5 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 2.5777\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 4.1952\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.690\n",
      "Last AUC: 0.546, eval 0.497\n",
      "Last accuracy: 53.20, eval 48.14\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.691\n",
      "Last AUC: 0.534, eval 0.513\n",
      "Last accuracy: 52.36, eval 50.86\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.692\n",
      "Last AUC: 0.527, eval 0.486\n",
      "Last accuracy: 51.92, eval 47.68\n",
      "\n",
      "[ 10 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 2.0458\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 3.7894\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.685\n",
      "Last AUC: 0.572, eval 0.552\n",
      "Last accuracy: 55.08, eval 54.86\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.689\n",
      "Last AUC: 0.551, eval 0.535\n",
      "Last accuracy: 53.84, eval 52.41\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.688\n",
      "Last AUC: 0.557, eval 0.557\n",
      "Last accuracy: 53.93, eval 54.31\n",
      "\n",
      "[ 15 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.7022\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 3.4289\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.675\n",
      "Last AUC: 0.610, eval 0.609\n",
      "Last accuracy: 57.28, eval 58.13\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.687\n",
      "Last AUC: 0.566, eval 0.552\n",
      "Last accuracy: 54.51, eval 53.50\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.677\n",
      "Last AUC: 0.604, eval 0.622\n",
      "Last accuracy: 57.44, eval 58.86\n",
      "\n",
      "[ 20 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.4442\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 3.1653\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.665\n",
      "Last AUC: 0.635, eval 0.639\n",
      "Last accuracy: 59.42, eval 60.13\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.684\n",
      "Last AUC: 0.577, eval 0.569\n",
      "Last accuracy: 55.22, eval 56.13\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.669\n",
      "Last AUC: 0.628, eval 0.649\n",
      "Last accuracy: 59.75, eval 60.76\n",
      "\n",
      "[ 25 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.2405\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 2.9784\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.659\n",
      "Last AUC: 0.649, eval 0.653\n",
      "Last accuracy: 60.69, eval 61.94\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.682\n",
      "Last AUC: 0.584, eval 0.581\n",
      "Last accuracy: 56.09, eval 56.86\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.664\n",
      "Last AUC: 0.640, eval 0.660\n",
      "Last accuracy: 60.11, eval 61.76\n",
      "\n",
      "DM Embeddings file size: 50,836,767 bytes\n",
      "DM Word Embeddings file size: 4,075,278 bytes\n",
      "DBOW Embeddings file size: 50,835,566 bytes\n"
     ]
    }
   ],
   "source": [
    "run_experiment(name='25_4_avg',\n",
    "               embedding_size=25,\n",
    "               window_size=4,\n",
    "               dm_linear='average',\n",
    "               **common_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 3.3434\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 4.5614\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.692\n",
      "Last AUC: 0.530, eval 0.513\n",
      "Last accuracy: 51.59, eval 51.50\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.693\n",
      "Last AUC: 0.519, eval 0.489\n",
      "Last accuracy: 51.36, eval 49.77\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.692\n",
      "Last AUC: 0.524, eval 0.521\n",
      "Last accuracy: 51.69, eval 51.86\n",
      "\n",
      "[ 5 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 2.0796\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 4.1830\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.689\n",
      "Last AUC: 0.548, eval 0.524\n",
      "Last accuracy: 53.07, eval 52.41\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.692\n",
      "Last AUC: 0.530, eval 0.492\n",
      "Last accuracy: 51.47, eval 49.95\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.691\n",
      "Last AUC: 0.535, eval 0.531\n",
      "Last accuracy: 52.65, eval 51.86\n",
      "\n",
      "[ 10 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.7241\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 3.5776\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.683\n",
      "Last AUC: 0.581, eval 0.582\n",
      "Last accuracy: 55.56, eval 56.04\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.690\n",
      "Last AUC: 0.540, eval 0.525\n",
      "Last accuracy: 52.46, eval 51.32\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.684\n",
      "Last AUC: 0.574, eval 0.588\n",
      "Last accuracy: 55.34, eval 56.58\n",
      "\n",
      "[ 15 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.3689\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 3.0423\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.668\n",
      "Last AUC: 0.630, eval 0.646\n",
      "Last accuracy: 59.40, eval 60.13\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.687\n",
      "Last AUC: 0.561, eval 0.569\n",
      "Last accuracy: 53.90, eval 53.77\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.670\n",
      "Last AUC: 0.624, eval 0.645\n",
      "Last accuracy: 58.71, eval 61.31\n",
      "\n",
      "[ 20 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.0902\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 2.7041\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.656\n",
      "Last AUC: 0.655, eval 0.673\n",
      "Last accuracy: 61.19, eval 62.67\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.683\n",
      "Last AUC: 0.581, eval 0.601\n",
      "Last accuracy: 55.30, eval 55.59\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.660\n",
      "Last AUC: 0.645, eval 0.666\n",
      "Last accuracy: 60.32, eval 63.22\n",
      "\n",
      "[ 25 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 0.9139\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 2.5016\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.649\n",
      "Last AUC: 0.668, eval 0.684\n",
      "Last accuracy: 61.82, eval 62.31\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.679\n",
      "Last AUC: 0.595, eval 0.616\n",
      "Last accuracy: 56.38, eval 58.04\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.656\n",
      "Last AUC: 0.655, eval 0.674\n",
      "Last accuracy: 60.85, eval 62.49\n",
      "\n",
      "DM Embeddings file size: 50,837,169 bytes\n",
      "DM Word Embeddings file size: 4,084,441 bytes\n",
      "DBOW Embeddings file size: 50,838,467 bytes\n"
     ]
    }
   ],
   "source": [
    "run_experiment(name='25_2_concat',\n",
    "               embedding_size=25,\n",
    "               window_size=2,\n",
    "               dm_linear='concatenate',\n",
    "               **common_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 2.9098\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 4.5406\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.692\n",
      "Last AUC: 0.526, eval 0.502\n",
      "Last accuracy: 51.76, eval 49.59\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.692\n",
      "Last AUC: 0.523, eval 0.498\n",
      "Last accuracy: 51.67, eval 51.04\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.693\n",
      "Last AUC: 0.515, eval 0.510\n",
      "Last accuracy: 50.76, eval 49.77\n",
      "\n",
      "[ 5 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.3410\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 4.1954\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.690\n",
      "Last AUC: 0.543, eval 0.499\n",
      "Last accuracy: 52.61, eval 49.77\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.691\n",
      "Last AUC: 0.534, eval 0.498\n",
      "Last accuracy: 52.19, eval 49.59\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.692\n",
      "Last AUC: 0.527, eval 0.507\n",
      "Last accuracy: 51.97, eval 51.41\n",
      "\n",
      "[ 10 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 1.0657\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 3.7917\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.687\n",
      "Last AUC: 0.561, eval 0.520\n",
      "Last accuracy: 54.27, eval 50.68\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.690\n",
      "Last AUC: 0.540, eval 0.512\n",
      "Last accuracy: 52.29, eval 51.50\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.690\n",
      "Last AUC: 0.546, eval 0.536\n",
      "Last accuracy: 53.27, eval 52.77\n",
      "\n",
      "[ 15 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 0.8936\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 3.4329\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.678\n",
      "Last AUC: 0.601, eval 0.587\n",
      "Last accuracy: 57.01, eval 56.77\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.689\n",
      "Last AUC: 0.550, eval 0.527\n",
      "Last accuracy: 52.60, eval 52.23\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.681\n",
      "Last AUC: 0.590, eval 0.607\n",
      "Last accuracy: 56.32, eval 57.77\n",
      "\n",
      "[ 20 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 0.7163\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 3.1688\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.669\n",
      "Last AUC: 0.629, eval 0.627\n",
      "Last accuracy: 59.36, eval 58.76\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.686\n",
      "Last AUC: 0.564, eval 0.546\n",
      "Last accuracy: 54.32, eval 53.86\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.672\n",
      "Last AUC: 0.616, eval 0.637\n",
      "Last accuracy: 58.54, eval 61.04\n",
      "\n",
      "[ 25 ]\n",
      "\n",
      "DM...\n",
      "\n",
      "Last average loss: 0.5480\n",
      "\n",
      "DBOW...\n",
      "\n",
      "Last average loss: 2.9794\n",
      "\n",
      "Sentiment...\n",
      "\n",
      "Last average loss: 0.661\n",
      "Last AUC: 0.645, eval 0.644\n",
      "Last accuracy: 60.57, eval 60.04\n",
      "\n",
      "Sentiment DM-only...\n",
      "\n",
      "Last average loss: 0.684\n",
      "Last AUC: 0.575, eval 0.564\n",
      "Last accuracy: 55.75, eval 55.04\n",
      "\n",
      "Sentiment DBOW-only...\n",
      "\n",
      "Last average loss: 0.667\n",
      "Last AUC: 0.630, eval 0.645\n",
      "Last accuracy: 59.08, eval 60.13\n",
      "\n",
      "DM Embeddings file size: 50,836,688 bytes\n",
      "DM Word Embeddings file size: 4,083,913 bytes\n",
      "DBOW Embeddings file size: 50,835,797 bytes\n"
     ]
    }
   ],
   "source": [
    "run_experiment(name='25_4_concat',\n",
    "               embedding_size=25,\n",
    "               window_size=4,\n",
    "               dm_linear='concatenate',\n",
    "               **common_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-cpu)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
