{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['udc.tar.gz',\n",
       " 'train.csv',\n",
       " 'valid.csv',\n",
       " 'test.csv',\n",
       " 'vocabulary.bin',\n",
       " 'train.tfrecords',\n",
       " 'valid.tfrecords',\n",
       " 'test.tfrecords']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = 'ubuntu'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "VOCAB_BIN = os.path.join(DATA_DIR, 'vocabulary.bin')\n",
    "TRAIN_TFR = os.path.join(DATA_DIR, 'train.tfrecords')\n",
    "VALID_TFR = os.path.join(DATA_DIR, 'valid.tfrecords')\n",
    "TEST_TFR = os.path.join(DATA_DIR, 'test.tfrecords')\n",
    "\n",
    "if not os.path.isfile(VOCAB_BIN):\n",
    "    raise Exception('File not found: {}'.format(VOCAB_BIN))\n",
    "\n",
    "if not os.path.isfile(TRAIN_TFR):\n",
    "    raise Exception('File not found: {}'.format(TRAIN_TFR))\n",
    "\n",
    "if not os.path.isfile(VALID_TFR):\n",
    "    raise Exception('File not found: {}'.format(VALID_TFR))\n",
    "\n",
    "if not os.path.isfile(TEST_TFR):\n",
    "    raise Exception('File not found: {}'.format(TEST_TFR))\n",
    "\n",
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 91,619\n",
      "Vector length: 220\n"
     ]
    }
   ],
   "source": [
    "# `tokenizer` function must be defined before restoring the vocabulary object\n",
    "# (pickle does not serialize functions)\n",
    "def tokenizer(sentences):\n",
    "    return (sentence.split() for sentence in sentences)\n",
    "\n",
    "class VocabularyAdapter:\n",
    "    \n",
    "    def __init__(self, vocabulary_bin):\n",
    "        self._vocab = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(vocabulary_bin)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._vocab.vocabulary_)\n",
    "    \n",
    "    @property\n",
    "    def vector_length(self):\n",
    "        return self._vocab.max_document_length\n",
    "\n",
    "vocab = VocabularyAdapter(VOCAB_BIN)\n",
    "\n",
    "print('Vocabulary size: {:,d}'.format(vocab.size))\n",
    "print('Vector length: {:,d}'.format(vocab.vector_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple TFRecord + Example reader**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/programmers_guide/reading_data\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/parse_single_example\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/parse_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Example 0 ]\n",
      "\n",
      "context\n",
      "\n",
      "[   3   61   29  309   63   69   98    4   66   12  866   10    1    2   93\n",
      "    5    9  153   60   12  183 1023   32   47    5   59    1  196  581  197\n",
      "   45    4   66  262  866   46    5   31  171    6   45    4   66  262   56\n",
      "    8 2422   46    1    2    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "context_len\n",
      "\n",
      "50\n",
      "\n",
      "utterance\n",
      "\n",
      "[170   1   3  73   9   6  34 667  10   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "10\n",
      "\n",
      "label\n",
      "\n",
      "0\n",
      "\n",
      "[ Example 1 ]\n",
      "\n",
      "context\n",
      "\n",
      "[  706     1  1736    41    32   265     6   608     5   332    64     9\n",
      "     6  2394     1     3    73  5984    22     4  1689   148    19    50\n",
      "   208    10     3    16    11  2451    13     9    22     4  2256   148\n",
      "     1  3311   994    11   286    25   215    35    22   118   184    17\n",
      "    27     1    12     6    22  1096    20    11   278    25   561     1\n",
      "   110    27     1     2   146    60  1480   197   316   110    27     1\n",
      "   262    16    11   391    25   816   367   394    19   456 22712    43\n",
      "    13   816   656    27     1     2  3488     6   190   136  1112     1\n",
      "     2  7715     1  3388    67     6    18     1  2196    34     7     1\n",
      "     2   130    47     8   212   119     1   309  8385    58    11   134\n",
      "   424     8   212     1     2   262  1570   144    11   318   185    17\n",
      "    27     1    12   212   740    42  8385     7     1   262   183   880\n",
      "  1553     9     1  2238     1  2196    34     7     1  2123    57     1\n",
      "     2     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "\n",
      "context_len\n",
      "\n",
      "157\n",
      "\n",
      "utterance\n",
      "\n",
      "[15  4 66  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "4\n",
      "\n",
      "label\n",
      "\n",
      "1\n",
      "\n",
      "[ Example 2 ]\n",
      "\n",
      "context\n",
      "\n",
      "[ 2325    78     6    40    13    22   118   184     5    79     1    24\n",
      "  1318    18   458   126    11   348  2036    51    21   444     1  1334\n",
      "     7   377  8633   489     3   122    24     6 17930     1     2    19\n",
      "    47     5 12233     6   240    31     4  2120  2232     1     2   224\n",
      "     5    12   112    63    25    49     6    39  4197     7     1     2\n",
      "     4  4197   522    13    63   675   379   819    80     8    41     6\n",
      "     4   187   325  1324   193     3    23    72     1     2   237     4\n",
      "   598   453   269   499   346   133    11   514   118    11   134   406\n",
      "    19    47    17    43     1     2    40     6    15    17   265     1\n",
      "     2   706     5   196     5  3670    55   203  2120     1     2 12513\n",
      "    17    27     1     2   224     5    49     6     4    45   262   474\n",
      "    22   317     4   142    97    25    88    20   377   104    57    46\n",
      "   127     1     3   290   112     8  1764    75    13   346    20  9456\n",
      "    13  5199    33  1092   597   113 88836    18     4   458    25 13298\n",
      "    17    27     1     2     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "\n",
      "context_len\n",
      "\n",
      "172\n",
      "\n",
      "utterance\n",
      "\n",
      "[1712  101    1 9343  176    0    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "7\n",
      "\n",
      "label\n",
      "\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    filename_queue = tf.train.string_input_producer([TRAIN_TFR])\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    key, value = reader.read(filename_queue)\n",
    "\n",
    "    example_features = {\n",
    "        'context': tf.FixedLenFeature(vocab.vector_length, dtype=tf.int64),\n",
    "        'context_len': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "        'utterance': tf.FixedLenFeature(vocab.vector_length, dtype=tf.int64),\n",
    "        'utterance_len': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "        'label': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "    }\n",
    "\n",
    "    example = tf.parse_single_example(value, example_features)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for i in range(3):\n",
    "        example_ = session.run(example)\n",
    "        context = example_['context']\n",
    "        context_len = example_['context_len']\n",
    "        utterance = example_['utterance']\n",
    "        utterance_len = example_['utterance_len']\n",
    "        label = example_['label']\n",
    "        print('[ Example {} ]\\n'.format(i))\n",
    "        print('context\\n\\n{}\\n'.format(context))\n",
    "        print('context_len\\n\\n{}\\n'.format(context_len))\n",
    "        print('utterance\\n\\n{}\\n'.format(utterance))\n",
    "        print('utterance_len\\n\\n{}\\n'.format(utterance_len))\n",
    "        print('label\\n\\n{}\\n'.format(label))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input function for Estimators**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/get_started/input_fn\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/learn/read_batch_record_features\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/feature_column\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/feature_column/make_parse_example_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_NumericColumn(key='context', shape=(220,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='context_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='utterance', shape=(220,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='utterance_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='label', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "def input_features(vector_length):\n",
    "    return [\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='label', shape=1, dtype=tf.int64),\n",
    "    ]\n",
    "\n",
    "\n",
    "features = input_features(vocab.vector_length)\n",
    "\n",
    "for x in features:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': FixedLenFeature(shape=(220,), dtype=tf.int64, default_value=None),\n",
       " 'context_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'label': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'utterance': FixedLenFeature(shape=(220,), dtype=tf.int64, default_value=None),\n",
       " 'utterance_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.feature_column.make_parse_example_spec(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:0' shape=(3, 220) dtype=int64>, 'context_len': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:1' shape=(3, 1) dtype=int64>, 'label': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:2' shape=(3, 1) dtype=int64>, 'utterance': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:3' shape=(3, 220) dtype=int64>, 'utterance_len': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:4' shape=(3, 1) dtype=int64>} \n",
      "\n",
      "[ Example 0 ]\n",
      "\n",
      "context\n",
      "\n",
      "[ 578    1  113    0 3396  625  477  261   19  429 2215   10    1  113  230\n",
      " 3396  538    1 1765    1  658    1  936    1 1468    7    4  338  379  450\n",
      "  130   47    3  165  272  274    7    1    6    9 7209    7    1 8915   91\n",
      "  104 7066   91  338    1   87   24    4  338  379    7    1    2    6   12\n",
      "  214   18   50  274    7    1  646    5    9   33   11 1091 1635    1   12\n",
      "   23   24 1576    8  306   54    1    2   23  221  562   47  294    9    1\n",
      "    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "context_len\n",
      "\n",
      "[91]\n",
      "\n",
      "utterance\n",
      "\n",
      "[ 6377    10    15  1938    62 86006   101     1     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "[8]\n",
      "\n",
      "label\n",
      "\n",
      "[0]\n",
      "\n",
      "[ Example 1 ]\n",
      "\n",
      "context\n",
      "\n",
      "[  37    3  138    4  107   45 1126    0   46   53   11  107  182    5  126\n",
      "   67    4  174   54    6  214    7   18    4  366  228    7    1    2   79\n",
      "    1    2    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "context_len\n",
      "\n",
      "[32]\n",
      "\n",
      "utterance\n",
      "\n",
      "[  422    50   926    13     4   297    25    17    80   128   147   217\n",
      "   217   699  1447 40088     1    19    47     8    71    12     5    12\n",
      "    16     8    14    26     3    82     1     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "[31]\n",
      "\n",
      "label\n",
      "\n",
      "[0]\n",
      "\n",
      "[ Example 2 ]\n",
      "\n",
      "context\n",
      "\n",
      "[   3  161    8   16  138   75   10    6   40   11  103   25  219   11 1812\n",
      "  477   74   63   18  105    7    1    2  109   69    9   33   11  163   25\n",
      "  477 1420    1   12   23   36   80  766 4347   43    3   73    9  150   12\n",
      "   86   50  477   27    1    2    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "context_len\n",
      "\n",
      "[51]\n",
      "\n",
      "utterance\n",
      "\n",
      "[ 69  70   3  98 861  50 529 154   3 530 493  10  79   9   6 751   1   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "[17]\n",
      "\n",
      "label\n",
      "\n",
      "[1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "    \n",
    "    batch_example = tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=[TRAIN_TFR],\n",
    "        batch_size=3,\n",
    "        features=example_features\n",
    "    )\n",
    "    \n",
    "    print(batch_example, '\\n')\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    examples = session.run(batch_example)\n",
    "    \n",
    "    for i in range(3):\n",
    "        context = examples['context'][i]\n",
    "        context_len = examples['context_len'][i]\n",
    "        utterance = examples['utterance'][i]\n",
    "        utterance_len = examples['utterance_len'][i]\n",
    "        label = examples['label'][i]\n",
    "        print('[ Example {} ]\\n'.format(i))\n",
    "        print('context\\n\\n{}\\n'.format(context))\n",
    "        print('context_len\\n\\n{}\\n'.format(context_len))\n",
    "        print('utterance\\n\\n{}\\n'.format(utterance))\n",
    "        print('utterance_len\\n\\n{}\\n'.format(utterance_len))\n",
    "        print('label\\n\\n{}\\n'.format(label))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Training ]\n",
      "\n",
      "... 128,000 examples\n",
      "... 256,000 examples\n",
      "... 384,000 examples\n",
      "... 512,000 examples\n",
      "... 640,000 examples\n",
      "... 768,000 examples\n",
      "... 896,000 examples\n",
      "... 938,593 examples\n",
      "Epoch limit reached\n",
      "\n",
      "[ Validation ]\n",
      "\n",
      "... 16,000 examples\n",
      "... 32,000 examples\n",
      "... 48,000 examples\n",
      "... 64,000 examples\n",
      "... 80,000 examples\n",
      "... 96,000 examples\n",
      "... 112,000 examples\n",
      "... 128,000 examples\n",
      "... 144,000 examples\n",
      "... 160,000 examples\n",
      "... 176,000 examples\n",
      "... 183,245 examples\n",
      "Epoch limit reached\n",
      "\n",
      "[ Test ]\n",
      "\n",
      "... 16,000 examples\n",
      "... 32,000 examples\n",
      "... 48,000 examples\n",
      "... 64,000 examples\n",
      "... 80,000 examples\n",
      "... 96,000 examples\n",
      "... 112,000 examples\n",
      "... 128,000 examples\n",
      "... 144,000 examples\n",
      "... 160,000 examples\n",
      "... 176,000 examples\n",
      "... 176,256 examples\n",
      "Epoch limit reached\n"
     ]
    }
   ],
   "source": [
    "def input_fn(name, filenames, features, batch_size, num_epochs=None):\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "\n",
    "    batch_example = tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=filenames,\n",
    "        features=example_features,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        name='read_batch_record_features_' + name\n",
    "    )\n",
    "\n",
    "    batch_target = batch_example.pop('label')\n",
    "\n",
    "    return batch_example, batch_target\n",
    "\n",
    "input_fn_train = lambda: input_fn('train', [TRAIN_TFR], features, 128, 1)\n",
    "input_fn_valid = lambda: input_fn('valid', [VALID_TFR], features, 16, 1)\n",
    "input_fn_test = lambda: input_fn('test', [TEST_TFR], features, 16, 1)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    train_data = input_fn_train()\n",
    "    valid_data = input_fn_valid()\n",
    "    test_data = input_fn_test()\n",
    "    \n",
    "    tf.local_variables_initializer().run()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    print('[ Training ]\\n')\n",
    "    \n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(train_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    print()\n",
    "    print('[ Validation ]\\n')\n",
    "\n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(valid_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    print()\n",
    "    print('[ Test ]\\n')\n",
    "\n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(test_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-cpu)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
