{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['udc.tar.gz',\n",
       " 'train.csv',\n",
       " 'valid.csv',\n",
       " 'test.csv',\n",
       " 'vocabulary.bin',\n",
       " 'train.tfrecords',\n",
       " 'valid.tfrecords',\n",
       " 'test.tfrecords']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = 'ubuntu'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "VOCAB_BIN = os.path.join(DATA_DIR, 'vocabulary.bin')\n",
    "TRAIN_TFR = os.path.join(DATA_DIR, 'train.tfrecords')\n",
    "VALID_TFR = os.path.join(DATA_DIR, 'valid.tfrecords')\n",
    "TEST_TFR = os.path.join(DATA_DIR, 'test.tfrecords')\n",
    "\n",
    "def has_file(file):\n",
    "    if not os.path.isfile(file):\n",
    "        raise Exception('File not found: {}'.format(file))\n",
    "\n",
    "has_file(VOCAB_BIN)\n",
    "has_file(TRAIN_TFR)\n",
    "has_file(VALID_TFR)\n",
    "has_file(TEST_TFR)\n",
    "\n",
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 91,619\n",
      "Vector length: 160\n"
     ]
    }
   ],
   "source": [
    "# `tokenizer` function must be defined before restoring the vocabulary object\n",
    "# (pickle does not serialize functions)\n",
    "def tokenizer(sentences):\n",
    "    return (sentence.split() for sentence in sentences)\n",
    "\n",
    "class VocabularyAdapter:\n",
    "    \n",
    "    def __init__(self, vocabulary_bin):\n",
    "        self._vocab = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(vocabulary_bin)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._vocab.vocabulary_)\n",
    "    \n",
    "    @property\n",
    "    def vector_length(self):\n",
    "        return self._vocab.max_document_length\n",
    "\n",
    "vocab = VocabularyAdapter(VOCAB_BIN)\n",
    "\n",
    "print('Vocabulary size: {:,d}'.format(vocab.size))\n",
    "print('Vector length: {:,d}'.format(vocab.vector_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple TFRecord + Example reader**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/programmers_guide/reading_data\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/parse_single_example\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/parse_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Example 0 ]\n",
      "\n",
      "context\n",
      "\n",
      "[    3    73   262   108   756     4   301   837   341  1271     5    28\n",
      "    53    40   262    56     8    90   341   920    10     3    73     9\n",
      "     6   660   197  1057     4  1236    20   576   348    13   197   756\n",
      "   259   119    13    40     1     2     9    81     6   218   419     8\n",
      "   290    11  2429  2628    25     0     1   153   134     1     2    93\n",
      "     1   534   262    23  1598    62  4389     0     1     2   144     7\n",
      "     1     2    70     1     2    29   340     1     9     6  1935   118\n",
      "    50 10075     7     1     2    79     1    28     9    33   156    29\n",
      "     4   111   129    17   265     1    32    11   116  2071  7281    18\n",
      "   409   808     1     2    12    67     6   400   158    50  2071   983\n",
      "     7     1   529    11   312   731   106   613    26     8    14    37\n",
      "     4  6645    51    29    14    26    12   819     1     2    38  3721\n",
      "     6   164 65630     7     1     2    29   948  3721     5    28    11\n",
      "  1447  5455     1     2]\n",
      "\n",
      "context_len\n",
      "\n",
      "160\n",
      "\n",
      "utterance\n",
      "\n",
      "[ 506  576 2970 1294   67   29  709  139    8  178 4258   25  633   19  234\n",
      "    1   44  115    3   14   18   31 2249  129   10    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "26\n",
      "\n",
      "label\n",
      "\n",
      "1\n",
      "\n",
      "[ Example 1 ]\n",
      "\n",
      "context\n",
      "\n",
      "[   3   61   29  309   63   69   98    4   66   12  866   10    1    2   93\n",
      "    5    9  153   60   12  183 1023   32   47    5   59    1  196  581  197\n",
      "   45    4   66  262  866   46    5   31  171    6   45    4   66  262   56\n",
      "    8 2422   46    1    2    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "context_len\n",
      "\n",
      "50\n",
      "\n",
      "utterance\n",
      "\n",
      "[170   1   3  73   9   6  34 667  10   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "10\n",
      "\n",
      "label\n",
      "\n",
      "0\n",
      "\n",
      "[ Example 2 ]\n",
      "\n",
      "context\n",
      "\n",
      "[ 3458    63     1    29   776   667     8   751     5    28    37  1736\n",
      "   207   628   600     8    22     5     6    49    11  1530    15     3\n",
      "    78    39  3286     4    22    17    27     1     2   119     1     2\n",
      "    12   191    65     8    52    15     0    18   751     6  1621  1103\n",
      "     8    15    18  1757     1     2    13   901   157     6 11391   832\n",
      "   815    43    95    25     4     0    77    27     5  1130   617   348\n",
      "    17  1159     1     3    14    21    35    50   163     5   126    14\n",
      "    12    65     8   335     7     1     2    23     3    54     4   469\n",
      "    29   251     8  4213     7    17    27     1     2     6    12    24\n",
      "   959     7    42     4    76   330     7     1   418    19     4 13066\n",
      "     5  2036    67     6   440     1     2     3    39   291   204    13\n",
      "    84   459   300    21   176     4   177    17    43     1  1923     6\n",
      "    21   133    17    43     1     2    14    12    73   262    16    68\n",
      "   706     8    16  1923]\n",
      "\n",
      "context_len\n",
      "\n",
      "160\n",
      "\n",
      "utterance\n",
      "\n",
      "[578  10   1 224   5 359  10   3 445  26 258   8  12   1  26 449  14  12\n",
      "  56   7   1  79   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "23\n",
      "\n",
      "label\n",
      "\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    filename_queue = tf.train.string_input_producer([TRAIN_TFR])\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    key, value = reader.read(filename_queue)\n",
    "\n",
    "    example_features = {\n",
    "        'context': tf.FixedLenFeature(vocab.vector_length, dtype=tf.int64),\n",
    "        'context_len': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "        'utterance': tf.FixedLenFeature(vocab.vector_length, dtype=tf.int64),\n",
    "        'utterance_len': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "        'label': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "    }\n",
    "\n",
    "    example = tf.parse_single_example(value, example_features)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for i in range(3):\n",
    "        example_ = session.run(example)\n",
    "        context = example_['context']\n",
    "        context_len = example_['context_len']\n",
    "        utterance = example_['utterance']\n",
    "        utterance_len = example_['utterance_len']\n",
    "        label = example_['label']\n",
    "        print('[ Example {} ]\\n'.format(i))\n",
    "        print('context\\n\\n{}\\n'.format(context))\n",
    "        print('context_len\\n\\n{}\\n'.format(context_len))\n",
    "        print('utterance\\n\\n{}\\n'.format(utterance))\n",
    "        print('utterance_len\\n\\n{}\\n'.format(utterance_len))\n",
    "        print('label\\n\\n{}\\n'.format(label))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input function for Estimators**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/get_started/input_fn\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/learn/read_batch_record_features\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/feature_column\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/feature_column/make_parse_example_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_NumericColumn(key='context', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='context_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='utterance', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='utterance_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='label', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "def features_train(vector_length):\n",
    "    return [\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='label', shape=1, dtype=tf.int64),\n",
    "    ]\n",
    "\n",
    "train_features = features_train(vocab.vector_length)\n",
    "\n",
    "for x in train_features:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'context_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'label': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'utterance': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'utterance_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.feature_column.make_parse_example_spec(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_NumericColumn(key='context', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='context_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='utterance', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='utterance_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_0', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_0_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_1', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_1_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_2', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_2_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_3', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_3_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_4', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_4_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_5', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_5_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_6', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_6_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_7', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_7_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_8', shape=(160,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='distractor_8_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "def features_eval(vector_length):\n",
    "    features = []\n",
    "    keys = ['context', 'utterance']\n",
    "    keys += ['distractor_{}'.format(i) for i in range(9)]\n",
    "    for key in keys:\n",
    "        features += [\n",
    "            tf.feature_column.numeric_column(\n",
    "                key=key, shape=vector_length, dtype=tf.int64),\n",
    "            tf.feature_column.numeric_column(\n",
    "                key=key + '_len', shape=1, dtype=tf.int64),\n",
    "        ]\n",
    "    return features\n",
    "\n",
    "eval_features = features_eval(vocab.vector_length)\n",
    "\n",
    "for x in eval_features:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'context_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_0': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_0_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_1': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_1_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_2': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_2_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_3': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_3_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_4': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_4_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_5': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_5_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_6': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_6_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_7': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_7_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_8': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'distractor_8_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'utterance': FixedLenFeature(shape=(160,), dtype=tf.int64, default_value=None),\n",
       " 'utterance_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.feature_column.make_parse_example_spec(eval_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:0' shape=(3, 160) dtype=int64>, 'context_len': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:1' shape=(3, 1) dtype=int64>, 'label': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:2' shape=(3, 1) dtype=int64>, 'utterance': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:3' shape=(3, 160) dtype=int64>, 'utterance_len': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:4' shape=(3, 1) dtype=int64>} \n",
      "\n",
      "[ Example 0 ]\n",
      "\n",
      "context\n",
      "\n",
      "[  137    57     3    56    89    71    30     3   199     8   358     0\n",
      "    19  1267  1351    10     0    82   280     6    93    43  2118     5\n",
      "  3143     5  1127     5   684    27    28   141   123    21   315     8\n",
      "     4   104    30     9   161    40    33    11    77    32   315   638\n",
      "     5    28     3    14    21    52   126     8    92    10 38327   161\n",
      "    93     5   142    58    63     4     0   219    54    30    68  1464\n",
      "   870     7     7     1     2   180   706   242    86     4  1682     7\n",
      "     1    17  1159     1    12    16    50  1168    55    32    11  1511\n",
      "  1403     7     1     2     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "\n",
      "context_len\n",
      "\n",
      "[100]\n",
      "\n",
      "utterance\n",
      "\n",
      "[ 106 1168    7 7283    6   41   93    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "[8]\n",
      "\n",
      "label\n",
      "\n",
      "[1]\n",
      "\n",
      "[ Example 1 ]\n",
      "\n",
      "context\n",
      "\n",
      "[    4  1923     5   238    13   362  1814     6  1053  2088     1     4\n",
      "  2109  3612   161     8     6    11   574     0  1814     1  7725     1\n",
      "     3    61    18   325   726    58     8   739    98  1427    43     3\n",
      "   122   285  1427    13   596   739    98    83   829    27     1     2\n",
      "   160     5    28    14    21    12   837    50     7     1     2    38\n",
      "   317    14    12 14876    11   369  2820  2068    25  2939     7     1\n",
      "     2    32  1764     8  1764   305     4   837    17    27     1     2\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "\n",
      "context_len\n",
      "\n",
      "[84]\n",
      "\n",
      "utterance\n",
      "\n",
      "[17 27  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "[3]\n",
      "\n",
      "label\n",
      "\n",
      "[1]\n",
      "\n",
      "[ Example 2 ]\n",
      "\n",
      "context\n",
      "\n",
      "[ 287    1 1586 2211  387    1   70    1    2 1456 8840    1    2    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "context_len\n",
      "\n",
      "[13]\n",
      "\n",
      "utterance\n",
      "\n",
      "[1456   12  112    7    1    3  996 2231    1   70    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "[11]\n",
      "\n",
      "label\n",
      "\n",
      "[1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    example_features = tf.feature_column.make_parse_example_spec(train_features)\n",
    "    \n",
    "    batch_example = tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=[TRAIN_TFR],\n",
    "        batch_size=3,\n",
    "        features=example_features\n",
    "    )\n",
    "    \n",
    "    print(batch_example, '\\n')\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    examples = session.run(batch_example)\n",
    "    \n",
    "    for i in range(3):\n",
    "        context = examples['context'][i]\n",
    "        context_len = examples['context_len'][i]\n",
    "        utterance = examples['utterance'][i]\n",
    "        utterance_len = examples['utterance_len'][i]\n",
    "        label = examples['label'][i]\n",
    "        print('[ Example {} ]\\n'.format(i))\n",
    "        print('context\\n\\n{}\\n'.format(context))\n",
    "        print('context_len\\n\\n{}\\n'.format(context_len))\n",
    "        print('utterance\\n\\n{}\\n'.format(utterance))\n",
    "        print('utterance_len\\n\\n{}\\n'.format(utterance_len))\n",
    "        print('label\\n\\n{}\\n'.format(label))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Training ]\n",
      "\n",
      "... 128,000 examples\n",
      "... 256,000 examples\n",
      "... 384,000 examples\n",
      "... 512,000 examples\n",
      "... 640,000 examples\n",
      "... 768,000 examples\n",
      "... 896,000 examples\n",
      "... 1,000,000 examples\n",
      "Epoch limit reached\n",
      "\n",
      "[ Validation ]\n",
      "\n",
      "... 16,000 examples\n",
      "... 19,560 examples\n",
      "Epoch limit reached\n",
      "\n",
      "[ Test ]\n",
      "\n",
      "... 16,000 examples\n",
      "... 18,920 examples\n",
      "Epoch limit reached\n"
     ]
    }
   ],
   "source": [
    "def _input_reader(name, filenames, features, batch_size, num_epochs):\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "    return tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=filenames,\n",
    "        features=example_features,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        randomize_input=True,\n",
    "        queue_capacity=200000 + batch_size * 10,\n",
    "        name='read_batch_record_features_' + name\n",
    "    )\n",
    "\n",
    "\n",
    "def input_train(name, filenames, features, batch_size, num_epochs=None):\n",
    "    batch_example = _input_reader(name, filenames, features, batch_size, num_epochs)\n",
    "    batch_target = batch_example.pop('label')\n",
    "    return batch_example, batch_target\n",
    "\n",
    "def input_eval(name, filenames, features, batch_size, num_epochs=None):\n",
    "    batch_example = _input_reader(name, filenames, features, batch_size, num_epochs)\n",
    "    batch_target = tf.zeros_like(batch_example['context_len'])\n",
    "    return batch_example, batch_target\n",
    "\n",
    "input_fn_train = lambda: input_train('train', [TRAIN_TFR], train_features, 128, 1)\n",
    "input_fn_valid = lambda: input_eval('valid', [VALID_TFR], eval_features, 16, 1)\n",
    "input_fn_test = lambda: input_eval('test', [TEST_TFR], eval_features, 16, 1)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    train_data = input_fn_train()\n",
    "    valid_data = input_fn_valid()\n",
    "    test_data = input_fn_test()\n",
    "    \n",
    "    tf.local_variables_initializer().run()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    print('[ Training ]\\n')\n",
    "    \n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(train_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    print()\n",
    "    print('[ Validation ]\\n')\n",
    "\n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(valid_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    print()\n",
    "    print('[ Test ]\\n')\n",
    "\n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(test_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-cpu)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
