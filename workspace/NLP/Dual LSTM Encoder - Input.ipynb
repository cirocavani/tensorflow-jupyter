{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['udc.tar.gz',\n",
       " 'train.csv',\n",
       " 'valid.csv',\n",
       " 'test.csv',\n",
       " 'train.tfrecords',\n",
       " 'valid.tfrecords',\n",
       " 'test.tfrecords',\n",
       " 'vocabulary.bin',\n",
       " 'valid_positive.tfrecords',\n",
       " 'valid_negative.tfrecords',\n",
       " 'test_positive.tfrecords',\n",
       " 'test_negative.tfrecords']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = 'ubuntu'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "VOCAB_BIN = os.path.join(DATA_DIR, 'vocabulary.bin')\n",
    "TRAIN_TFR = os.path.join(DATA_DIR, 'train.tfrecords')\n",
    "VALID_POSITIVE_TFR = os.path.join(DATA_DIR, 'valid_positive.tfrecords')\n",
    "VALID_NEGATIVE_TFR = os.path.join(DATA_DIR, 'valid_negative.tfrecords')\n",
    "TEST_POSITIVE_TFR = os.path.join(DATA_DIR, 'test_positive.tfrecords')\n",
    "TEST_NEGATIVE_TFR = os.path.join(DATA_DIR, 'test_negative.tfrecords')\n",
    "\n",
    "def has_file(file):\n",
    "    if not os.path.isfile(file):\n",
    "        raise Exception('File not found: {}'.format(file))\n",
    "\n",
    "has_file(VOCAB_BIN)\n",
    "has_file(TRAIN_TFR)\n",
    "has_file(VALID_POSITIVE_TFR)\n",
    "has_file(VALID_NEGATIVE_TFR)\n",
    "has_file(TEST_POSITIVE_TFR)\n",
    "has_file(TEST_NEGATIVE_TFR)\n",
    "\n",
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 91,619\n",
      "Vector length: 220\n"
     ]
    }
   ],
   "source": [
    "# `tokenizer` function must be defined before restoring the vocabulary object\n",
    "# (pickle does not serialize functions)\n",
    "def tokenizer(sentences):\n",
    "    return (sentence.split() for sentence in sentences)\n",
    "\n",
    "class VocabularyAdapter:\n",
    "    \n",
    "    def __init__(self, vocabulary_bin):\n",
    "        self._vocab = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(vocabulary_bin)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._vocab.vocabulary_)\n",
    "    \n",
    "    @property\n",
    "    def vector_length(self):\n",
    "        return self._vocab.max_document_length\n",
    "\n",
    "vocab = VocabularyAdapter(VOCAB_BIN)\n",
    "\n",
    "print('Vocabulary size: {:,d}'.format(vocab.size))\n",
    "print('Vector length: {:,d}'.format(vocab.vector_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple TFRecord + Example reader**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/programmers_guide/reading_data\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/parse_single_example\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/parse_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Example 0 ]\n",
      "\n",
      "context\n",
      "\n",
      "[   3   61   29  309   63   69   98    4   66   12  866   10    1    2   93\n",
      "    5    9  153   60   12  183 1023   32   47    5   59    1  196  581  197\n",
      "   45    4   66  262  866   46    5   31  171    6   45    4   66  262   56\n",
      "    8 2422   46    1    2    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "context_len\n",
      "\n",
      "50\n",
      "\n",
      "utterance\n",
      "\n",
      "[170   1   3  73   9   6  34 667  10   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "10\n",
      "\n",
      "label\n",
      "\n",
      "0\n",
      "\n",
      "[ Example 1 ]\n",
      "\n",
      "context\n",
      "\n",
      "[  706     1  1736    41    32   265     6   608     5   332    64     9\n",
      "     6  2394     1     3    73  5984    22     4  1689   148    19    50\n",
      "   208    10     3    16    11  2451    13     9    22     4  2256   148\n",
      "     1  3311   994    11   286    25   215    35    22   118   184    17\n",
      "    27     1    12     6    22  1096    20    11   278    25   561     1\n",
      "   110    27     1     2   146    60  1480   197   316   110    27     1\n",
      "   262    16    11   391    25   816   367   394    19   456 22712    43\n",
      "    13   816   656    27     1     2  3488     6   190   136  1112     1\n",
      "     2  7715     1  3388    67     6    18     1  2196    34     7     1\n",
      "     2   130    47     8   212   119     1   309  8385    58    11   134\n",
      "   424     8   212     1     2   262  1570   144    11   318   185    17\n",
      "    27     1    12   212   740    42  8385     7     1   262   183   880\n",
      "  1553     9     1  2238     1  2196    34     7     1  2123    57     1\n",
      "     2     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "\n",
      "context_len\n",
      "\n",
      "157\n",
      "\n",
      "utterance\n",
      "\n",
      "[15  4 66  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "4\n",
      "\n",
      "label\n",
      "\n",
      "1\n",
      "\n",
      "[ Example 2 ]\n",
      "\n",
      "context\n",
      "\n",
      "[ 2325    78     6    40    13    22   118   184     5    79     1    24\n",
      "  1318    18   458   126    11   348  2036    51    21   444     1  1334\n",
      "     7   377  8633   489     3   122    24     6 17930     1     2    19\n",
      "    47     5 12233     6   240    31     4  2120  2232     1     2   224\n",
      "     5    12   112    63    25    49     6    39  4197     7     1     2\n",
      "     4  4197   522    13    63   675   379   819    80     8    41     6\n",
      "     4   187   325  1324   193     3    23    72     1     2   237     4\n",
      "   598   453   269   499   346   133    11   514   118    11   134   406\n",
      "    19    47    17    43     1     2    40     6    15    17   265     1\n",
      "     2   706     5   196     5  3670    55   203  2120     1     2 12513\n",
      "    17    27     1     2   224     5    49     6     4    45   262   474\n",
      "    22   317     4   142    97    25    88    20   377   104    57    46\n",
      "   127     1     3   290   112     8  1764    75    13   346    20  9456\n",
      "    13  5199    33  1092   597   113 88836    18     4   458    25 13298\n",
      "    17    27     1     2     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "\n",
      "context_len\n",
      "\n",
      "172\n",
      "\n",
      "utterance\n",
      "\n",
      "[1712  101    1 9343  176    0    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "7\n",
      "\n",
      "label\n",
      "\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    filename_queue = tf.train.string_input_producer([TRAIN_TFR])\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    key, value = reader.read(filename_queue)\n",
    "\n",
    "    example_features = {\n",
    "        'context': tf.FixedLenFeature(vocab.vector_length, dtype=tf.int64),\n",
    "        'context_len': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "        'utterance': tf.FixedLenFeature(vocab.vector_length, dtype=tf.int64),\n",
    "        'utterance_len': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "        'label': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "    }\n",
    "\n",
    "    example = tf.parse_single_example(value, example_features)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for i in range(3):\n",
    "        example_ = session.run(example)\n",
    "        context = example_['context']\n",
    "        context_len = example_['context_len']\n",
    "        utterance = example_['utterance']\n",
    "        utterance_len = example_['utterance_len']\n",
    "        label = example_['label']\n",
    "        print('[ Example {} ]\\n'.format(i))\n",
    "        print('context\\n\\n{}\\n'.format(context))\n",
    "        print('context_len\\n\\n{}\\n'.format(context_len))\n",
    "        print('utterance\\n\\n{}\\n'.format(utterance))\n",
    "        print('utterance_len\\n\\n{}\\n'.format(utterance_len))\n",
    "        print('label\\n\\n{}\\n'.format(label))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input function for Estimators**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/get_started/input_fn\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/learn/read_batch_record_features\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/feature_column\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/feature_column/make_parse_example_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_NumericColumn(key='context', shape=(220,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='context_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='utterance', shape=(220,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='utterance_len', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n",
      "_NumericColumn(key='label', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "def input_features(vector_length):\n",
    "    return [\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='label', shape=1, dtype=tf.int64),\n",
    "    ]\n",
    "\n",
    "\n",
    "features = input_features(vocab.vector_length)\n",
    "\n",
    "for x in features:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': FixedLenFeature(shape=(220,), dtype=tf.int64, default_value=None),\n",
       " 'context_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'label': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None),\n",
       " 'utterance': FixedLenFeature(shape=(220,), dtype=tf.int64, default_value=None),\n",
       " 'utterance_len': FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.feature_column.make_parse_example_spec(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:0' shape=(3, 220) dtype=int64>, 'context_len': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:1' shape=(3, 1) dtype=int64>, 'label': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:2' shape=(3, 1) dtype=int64>, 'utterance': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:3' shape=(3, 220) dtype=int64>, 'utterance_len': <tf.Tensor 'dequeue_record_examples/fifo_queue_Dequeue:4' shape=(3, 1) dtype=int64>} \n",
      "\n",
      "[ Example 0 ]\n",
      "\n",
      "context\n",
      "\n",
      "[  14  439   36    8  198    0    8  226    5    3  123   21    1    2   54\n",
      "   11  348    1    2   98   37    3   14   21 2166   31  208    5   48   37\n",
      "  870  302  108   36    5    3   23   54   11  348   37 1265    1    2    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "context_len\n",
      "\n",
      "[44]\n",
      "\n",
      "utterance\n",
      "\n",
      "[  9  51  21  41  19  47 353  30   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "[9]\n",
      "\n",
      "label\n",
      "\n",
      "[1]\n",
      "\n",
      "[ Example 1 ]\n",
      "\n",
      "context\n",
      "\n",
      "[ 137    1   87  617   77   32   97   75  195  697   22    7    1    2   79\n",
      "    5  540   86   29  231  378   32  120 1214    1    2   19   47    9 1570\n",
      "   74 1735  357   13    3   16    8  492 1736    8 1188    1    2    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "context_len\n",
      "\n",
      "[43]\n",
      "\n",
      "utterance\n",
      "\n",
      "[  14   12  124 2763    7    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "[6]\n",
      "\n",
      "label\n",
      "\n",
      "[1]\n",
      "\n",
      "[ Example 2 ]\n",
      "\n",
      "context\n",
      "\n",
      "[ 225  247    5    3   16  253   77   10  187  268    5  195  300   21   96\n",
      "  158   31   76  114   10    3   16    4  142   77   32  998    5   28   29\n",
      "   32  773   10  406    5  704  446  207 1771   18   34    5   28   29   76\n",
      "    5  586    5   42  773   10    1    3  239   16   24   15 1876    5   29\n",
      "  109    1  578   10   13   18 3098    5   64    9    6  143    8 1564   10\n",
      "  506  280   10    1    2  534 1743    7    1 1157   10    9   33   36    8\n",
      "   24 1743  187    5   59   64    9  129   95    0    8 3660   10    1    2\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "context_len\n",
      "\n",
      "[105]\n",
      "\n",
      "utterance\n",
      "\n",
      "[  26   86 1743    7    3   14   21   56    9    5   48   78    3  543    9\n",
      "   10    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "utterance_len\n",
      "\n",
      "[17]\n",
      "\n",
      "label\n",
      "\n",
      "[1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "    \n",
    "    batch_example = tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=[TRAIN_TFR],\n",
    "        batch_size=3,\n",
    "        features=example_features\n",
    "    )\n",
    "    \n",
    "    print(batch_example, '\\n')\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    examples = session.run(batch_example)\n",
    "    \n",
    "    for i in range(3):\n",
    "        context = examples['context'][i]\n",
    "        context_len = examples['context_len'][i]\n",
    "        utterance = examples['utterance'][i]\n",
    "        utterance_len = examples['utterance_len'][i]\n",
    "        label = examples['label'][i]\n",
    "        print('[ Example {} ]\\n'.format(i))\n",
    "        print('context\\n\\n{}\\n'.format(context))\n",
    "        print('context_len\\n\\n{}\\n'.format(context_len))\n",
    "        print('utterance\\n\\n{}\\n'.format(utterance))\n",
    "        print('utterance_len\\n\\n{}\\n'.format(utterance_len))\n",
    "        print('label\\n\\n{}\\n'.format(label))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Training ]\n",
      "\n",
      "... 128,000 examples\n",
      "... 256,000 examples\n",
      "... 384,000 examples\n",
      "... 512,000 examples\n",
      "... 640,000 examples\n",
      "... 768,000 examples\n",
      "... 896,000 examples\n",
      "... 938,593 examples\n",
      "Epoch limit reached\n",
      "\n",
      "[ Validation ]\n",
      "\n",
      "... 16,000 examples\n",
      "... 32,000 examples\n",
      "... 48,000 examples\n",
      "... 64,000 examples\n",
      "... 80,000 examples\n",
      "... 96,000 examples\n",
      "... 112,000 examples\n",
      "... 128,000 examples\n",
      "... 144,000 examples\n",
      "... 160,000 examples\n",
      "... 176,000 examples\n",
      "... 183,281 examples\n",
      "Epoch limit reached\n",
      "\n",
      "[ Test ]\n",
      "\n",
      "... 16,000 examples\n",
      "... 32,000 examples\n",
      "... 48,000 examples\n",
      "... 64,000 examples\n",
      "... 80,000 examples\n",
      "... 96,000 examples\n",
      "... 112,000 examples\n",
      "... 128,000 examples\n",
      "... 144,000 examples\n",
      "... 160,000 examples\n",
      "... 176,000 examples\n",
      "... 176,301 examples\n",
      "Epoch limit reached\n"
     ]
    }
   ],
   "source": [
    "def input_fn(name, filenames, features, batch_size, num_epochs=None):\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "\n",
    "    batch_example = tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=filenames,\n",
    "        features=example_features,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        randomize_input=True,\n",
    "        queue_capacity=200000 + batch_size * 10,\n",
    "        name='read_batch_record_features_' + name\n",
    "    )\n",
    "\n",
    "    batch_target = batch_example.pop('label')\n",
    "\n",
    "    return batch_example, batch_target\n",
    "\n",
    "input_fn_train = lambda: input_fn('train', [TRAIN_TFR], features, 128, 1)\n",
    "input_fn_valid = lambda: input_fn('valid', [VALID_POSITIVE_TFR, VALID_NEGATIVE_TFR], features, 16, 1)\n",
    "input_fn_test = lambda: input_fn('test', [TEST_POSITIVE_TFR, TEST_NEGATIVE_TFR], features, 16, 1)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    train_data = input_fn_train()\n",
    "    valid_data = input_fn_valid()\n",
    "    test_data = input_fn_test()\n",
    "    \n",
    "    tf.local_variables_initializer().run()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    print('[ Training ]\\n')\n",
    "    \n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(train_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    print()\n",
    "    print('[ Validation ]\\n')\n",
    "\n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(valid_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    print()\n",
    "    print('[ Test ]\\n')\n",
    "\n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(test_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-cpu)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
