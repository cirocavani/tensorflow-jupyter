{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = 'ubuntu'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "VOCAB_BIN = os.path.join(DATA_DIR, 'vocabulary.bin')\n",
    "TRAIN_TFR = os.path.join(DATA_DIR, 'train.tfrecords')\n",
    "VALID_TFR = os.path.join(DATA_DIR, 'valid.tfrecords')\n",
    "TEST_TFR = os.path.join(DATA_DIR, 'test.tfrecords')\n",
    "\n",
    "def has_file(file):\n",
    "    if not os.path.isfile(file):\n",
    "        raise Exception('File not found: {}'.format(file))\n",
    "\n",
    "has_file(VOCAB_BIN)\n",
    "has_file(TRAIN_TFR)\n",
    "has_file(VALID_TFR)\n",
    "has_file(TEST_TFR)\n",
    "\n",
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `tokenizer` function must be defined before restoring the vocabulary object\n",
    "# (pickle does not serialize functions)\n",
    "def tokenizer(sentences):\n",
    "    return (sentence.split() for sentence in sentences)\n",
    "\n",
    "class VocabularyAdapter:\n",
    "    \n",
    "    def __init__(self, vocabulary_bin):\n",
    "        self._vocab = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(vocabulary_bin)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._vocab.vocabulary_)\n",
    "    \n",
    "    @property\n",
    "    def vector_length(self):\n",
    "        return self._vocab.max_document_length\n",
    "\n",
    "vocab = VocabularyAdapter(VOCAB_BIN)\n",
    "\n",
    "print('Vocabulary size: {:,d}'.format(vocab.size))\n",
    "print('Vector length: {:,d}'.format(vocab.vector_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple TFRecord + Example reader**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/programmers_guide/reading_data\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/parse_single_example\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/parse_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    filename_queue = tf.train.string_input_producer([TRAIN_TFR])\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    key, value = reader.read(filename_queue)\n",
    "\n",
    "    example_features = {\n",
    "        'context': tf.FixedLenFeature(vocab.vector_length, dtype=tf.int64),\n",
    "        'context_len': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "        'utterance': tf.FixedLenFeature(vocab.vector_length, dtype=tf.int64),\n",
    "        'utterance_len': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "        'label': tf.FixedLenFeature((), dtype=tf.int64),\n",
    "    }\n",
    "\n",
    "    example = tf.parse_single_example(value, example_features)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for i in range(3):\n",
    "        example_ = session.run(example)\n",
    "        context = example_['context']\n",
    "        context_len = example_['context_len']\n",
    "        utterance = example_['utterance']\n",
    "        utterance_len = example_['utterance_len']\n",
    "        label = example_['label']\n",
    "        print('[ Example {} ]\\n'.format(i))\n",
    "        print('context\\n\\n{}\\n'.format(context))\n",
    "        print('context_len\\n\\n{}\\n'.format(context_len))\n",
    "        print('utterance\\n\\n{}\\n'.format(utterance))\n",
    "        print('utterance_len\\n\\n{}\\n'.format(utterance_len))\n",
    "        print('label\\n\\n{}\\n'.format(label))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input function for Estimators**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/get_started/input_fn\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/learn/read_batch_record_features\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/feature_column\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/feature_column/make_parse_example_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_train(vector_length):\n",
    "    return [\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='label', shape=1, dtype=tf.int64),\n",
    "    ]\n",
    "\n",
    "train_features = features_train(vocab.vector_length)\n",
    "\n",
    "for x in train_features:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.feature_column.make_parse_example_spec(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_eval(vector_length):\n",
    "    features = []\n",
    "    keys = ['context', 'utterance']\n",
    "    keys += ['distractor_{}'.format(i) for i in range(9)]\n",
    "    for key in keys:\n",
    "        features += [\n",
    "            tf.feature_column.numeric_column(\n",
    "                key=key, shape=vector_length, dtype=tf.int64),\n",
    "            tf.feature_column.numeric_column(\n",
    "                key=key + '_len', shape=1, dtype=tf.int64),\n",
    "        ]\n",
    "    return features\n",
    "\n",
    "eval_features = features_eval(vocab.vector_length)\n",
    "\n",
    "for x in eval_features:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.feature_column.make_parse_example_spec(eval_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    example_features = tf.feature_column.make_parse_example_spec(train_features)\n",
    "    \n",
    "    batch_example = tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=[TRAIN_TFR],\n",
    "        batch_size=3,\n",
    "        features=example_features\n",
    "    )\n",
    "    \n",
    "    print(batch_example, '\\n')\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    examples = session.run(batch_example)\n",
    "    \n",
    "    for i in range(3):\n",
    "        context = examples['context'][i]\n",
    "        context_len = examples['context_len'][i]\n",
    "        utterance = examples['utterance'][i]\n",
    "        utterance_len = examples['utterance_len'][i]\n",
    "        label = examples['label'][i]\n",
    "        print('[ Example {} ]\\n'.format(i))\n",
    "        print('context\\n\\n{}\\n'.format(context))\n",
    "        print('context_len\\n\\n{}\\n'.format(context_len))\n",
    "        print('utterance\\n\\n{}\\n'.format(utterance))\n",
    "        print('utterance_len\\n\\n{}\\n'.format(utterance_len))\n",
    "        print('label\\n\\n{}\\n'.format(label))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def _input_reader(name, filenames, features, batch_size, num_epochs):\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "    return tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=filenames,\n",
    "        features=example_features,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        randomize_input=True,\n",
    "        queue_capacity=200000 + batch_size * 10,\n",
    "        name='read_batch_record_features_' + name\n",
    "    )\n",
    "\n",
    "\n",
    "def input_train(name, filenames, features, batch_size, num_epochs=None):\n",
    "    batch_example = _input_reader(name, filenames, features, batch_size, num_epochs)\n",
    "    batch_target = batch_example.pop('label')\n",
    "    return batch_example, batch_target\n",
    "\n",
    "def input_eval(name, filenames, features, batch_size, num_epochs=None):\n",
    "    batch_example = _input_reader(name, filenames, features, batch_size, num_epochs)\n",
    "    batch_target = tf.zeros_like(batch_example['context_len'])\n",
    "    return batch_example, batch_target\n",
    "\n",
    "input_fn_train = lambda: input_train('train', [TRAIN_TFR], train_features, 128, 1)\n",
    "input_fn_valid = lambda: input_eval('valid', [VALID_TFR], eval_features, 16, 1)\n",
    "input_fn_test = lambda: input_eval('test', [TEST_TFR], eval_features, 16, 1)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    train_data = input_fn_train()\n",
    "    valid_data = input_fn_valid()\n",
    "    test_data = input_fn_test()\n",
    "    \n",
    "    tf.local_variables_initializer().run()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    print('[ Training ]\\n')\n",
    "    \n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(train_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    print()\n",
    "    print('[ Validation ]\\n')\n",
    "\n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(valid_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    print()\n",
    "    print('[ Test ]\\n')\n",
    "\n",
    "    batch_count = 0\n",
    "    examples_count = 0\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            data = session.run(test_data)\n",
    "            examples_count += len(data[0]['context'])\n",
    "            batch_count += 1\n",
    "            if batch_count % 1000 == 0:\n",
    "                print('... {:,d} examples'.format(examples_count))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('... {:,d} examples'.format(examples_count))\n",
    "        print('Epoch limit reached')\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-cpu)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
