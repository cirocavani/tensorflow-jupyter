{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics**\n",
    "\n",
    "Multi-class classification problem:\n",
    "\n",
    "* given:<br>\n",
    "    1 context and n utterances\n",
    "* return:<br>\n",
    "    which utterance is the correct response\n",
    "\n",
    "Metric:\n",
    "\n",
    "recall in k\n",
    "\n",
    "From n utterances, if the correct one is in the top k, counts as true positive (tp), otherwise, counts as false negative (fn).\n",
    "\n",
    "`recall = tp / (tp + fn)`\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/metrics/recall_at_k\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 in 2 recall @ 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 3  # number of examples from evaluation (validation / test)\n",
    "num_labels = 1  # the only label is the class of the correct utterance (the position from 0 to n-1)\n",
    "num_classes = 2 # number of utterance (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by construction, the first utterance (class = 0) is the correct utterance\n",
    "labels = tf.constant(0, shape=(batch_size, num_labels), dtype=tf.int64)\n",
    "\n",
    "print(labels)\n",
    "print(labels.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits for the first and second utterance\n",
    "predictions = tf.constant([0.8, 0.09, 0.6, 0.1, 0.5, 0.3], shape=(batch_size, num_classes), dtype=tf.float64)\n",
    "\n",
    "print(predictions)\n",
    "print(predictions.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, u = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=1)\n",
    "\n",
    "print(r)\n",
    "print(u)\n",
    "\n",
    "tf.local_variables_initializer().run()\n",
    "\n",
    "print(u.eval())\n",
    "print(r.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fn = tf.local_variables()\n",
    "\n",
    "print(tp)\n",
    "print(fn)\n",
    "\n",
    "print(tp.eval(), fn.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 in 10 recall @ 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_labels = 1\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by construction, the first utterance (class = 0) is the correct utterance\n",
    "labels = tf.constant(0, shape=(batch_size, num_labels), dtype=tf.int64)\n",
    "\n",
    "print(labels)\n",
    "print(labels.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits for a good result (true positive)\n",
    "example_class0 = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.1]\n",
    "example_class1 = [0.8, 0.9, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.1]\n",
    "# logits for a bad result (false negative)\n",
    "example_class5 = [0.4, 0.9, 0.8, 0.7, 0.6, 0.5, 0.3, 0.2, 0.1, 0.1]\n",
    "example_class9 = [0.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "logits = example_class0 + example_class1 + example_class5 + example_class9\n",
    "\n",
    "predictions = tf.constant(logits,shape=(batch_size, num_classes), dtype=tf.float64)\n",
    "\n",
    "print(predictions)\n",
    "print(predictions.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, u = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=5)\n",
    "\n",
    "print(r)\n",
    "print(u)\n",
    "\n",
    "tf.local_variables_initializer().run()\n",
    "\n",
    "print(u.eval())\n",
    "print(r.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*_, tp, fn = tf.local_variables()\n",
    "\n",
    "print(tp)\n",
    "print(fn)\n",
    "\n",
    "print(tp.eval(), fn.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "vector_len = 4\n",
    "\n",
    "features = {\n",
    "    'context': tf.constant(1.0, shape=(batch_size, vector_len)),\n",
    "    'context_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'utterance': tf.constant(2.0, shape=(batch_size, vector_len)),\n",
    "    'utterance_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_0': tf.constant(3.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_0_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_1': tf.constant(4.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_1_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_2': tf.constant(5.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_2_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_3': tf.constant(6.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_3_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_4': tf.constant(7.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_4_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_5': tf.constant(8.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_5_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_6': tf.constant(9.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_6_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_7': tf.constant(10.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_7_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_8': tf.constant(11.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_8_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "}\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.constant(0, shape=(batch_size, 1))\n",
    "\n",
    "print(labels)\n",
    "print(labels.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = features['context']\n",
    "context_len = features['context_len']\n",
    "\n",
    "print(context)\n",
    "print(context.eval())\n",
    "print()\n",
    "print(context_len)\n",
    "print(context_len.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance = features['utterance']\n",
    "utterance_len = features['utterance_len']\n",
    "\n",
    "print(utterance)\n",
    "print(utterance.eval())\n",
    "print()\n",
    "print(utterance_len)\n",
    "print(utterance_len.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_context = []\n",
    "input_context_len = []\n",
    "input_utterance = []\n",
    "input_utterance_len = []\n",
    "labels_ = []\n",
    "\n",
    "input_context.append(context)\n",
    "input_context_len.append(context_len)\n",
    "input_utterance.append(utterance)\n",
    "input_utterance_len.append(utterance_len)\n",
    "labels_.append(tf.ones(shape=(batch_size, 1)))\n",
    "\n",
    "print(input_context)\n",
    "print(input_context_len)\n",
    "print(input_utterance)\n",
    "print(input_utterance_len)\n",
    "print(labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    input_context.append(context)\n",
    "    input_context_len.append(context_len)\n",
    "    input_utterance.append(features['distractor_{}'.format(i)])\n",
    "    input_utterance_len.append(features['distractor_{}_len'.format(i)])\n",
    "    labels_.append(tf.zeros(shape=(batch_size, 1)))\n",
    "\n",
    "print('input_context\\n\\n', input_context, '\\n')\n",
    "print('input_context_len\\n\\n', input_context_len, '\\n')\n",
    "print('input_utterance\\n\\n', input_utterance, '\\n')\n",
    "print('input_utterance_len\\n\\n', input_utterance_len, '\\n')\n",
    "print('labels_\\n\\n', labels_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_context = tf.concat(input_context, axis=0)\n",
    "input_context_len = tf.concat(input_context_len, axis=0)\n",
    "input_utterance = tf.concat(input_utterance, axis=0)\n",
    "input_utterance_len = tf.concat(input_utterance_len, axis=0)\n",
    "labels_ = tf.concat(labels_, axis=0)\n",
    "\n",
    "print('input_context\\n\\n', input_context, '\\n')\n",
    "print('input_context_len\\n\\n', input_context_len, '\\n')\n",
    "print('input_utterance\\n\\n', input_utterance, '\\n')\n",
    "print('input_utterance_len\\n\\n', input_utterance_len, '\\n')\n",
    "print('labels_\\n\\n', labels_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = tf.constant(list(range(batch_size * 10)), shape=(batch_size * 10, 1))\n",
    "\n",
    "print(probs)\n",
    "print(probs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_probs = tf.split(probs, num_or_size_splits=10, axis=0)\n",
    "predictions = tf.concat(split_probs, axis=1)\n",
    "\n",
    "print(predictions)\n",
    "print(predictions.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = predictions[:, :2]\n",
    "\n",
    "print(predictions_2)\n",
    "print(predictions_2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_fn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dual_encoder(vocab_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 input_context,\n",
    "                 input_context_len,\n",
    "                 input_utterance,\n",
    "                 input_utterance_len,\n",
    "                 targets):\n",
    "\n",
    "    input_data = tf.concat([input_context, input_utterance], axis=0)\n",
    "    input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "    input_length = tf.reshape(input_length, [-1])\n",
    "    \n",
    "    embeddings = tf.get_variable(\n",
    "        'embeddings',\n",
    "        shape=(vocab_size, embed_size),\n",
    "        initializer=tf.random_uniform_initializer(-0.25, 0.25))\n",
    "\n",
    "    input_embed = tf.nn.embedding_lookup(\n",
    "        embeddings, input_data, name='input_embed')\n",
    "        \n",
    "    with tf.variable_scope('rnn'):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(\n",
    "            hidden_size,\n",
    "            forget_bias=2.0,\n",
    "            use_peepholes=True,\n",
    "            state_is_tuple=True)\n",
    "\n",
    "        outputs, states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            input_embed,\n",
    "            sequence_length=input_length,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        context_encoding, utterance_encoding = tf.split(\n",
    "            states.h, num_or_size_splits=2, axis=0)\n",
    "\n",
    "    with tf.variable_scope('prediction'):\n",
    "        ct = context_encoding\n",
    "        rt = utterance_encoding\n",
    "        M = tf.get_variable(\n",
    "            'M',\n",
    "            shape=(hidden_size, hidden_size),\n",
    "            initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        ct_M = tf.matmul(ct, M)\n",
    "        batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "        batch_rt = tf.expand_dims(rt, axis=2)\n",
    "        batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "        ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "        b = tf.get_variable(\n",
    "           'b', shape=(), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        logits = ct_M_r + b\n",
    "        \n",
    "        probs = tf.sigmoid(logits)\n",
    "\n",
    "    if targets is None:\n",
    "        return probs, None\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(\n",
    "        multi_class_labels=targets, logits=logits, reduction=tf.losses.Reduction.MEAN)\n",
    "    \n",
    "    return probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn_eval(features, labels, vocab_size, embed_size, hidden_size):\n",
    "    input_context = []\n",
    "    input_context_len = []\n",
    "    input_utterance = []\n",
    "    input_utterance_len = []\n",
    "    labels_ = []\n",
    "    \n",
    "    context = features['context']\n",
    "    context_len = features['context_len']\n",
    "\n",
    "    input_context.append(context)\n",
    "    input_context_len.append(context_len)\n",
    "    input_utterance.append(features['utterance'])\n",
    "    input_utterance_len.append(features['utterance_len'])\n",
    "    labels_.append(tf.ones_like(context_len))\n",
    "    \n",
    "    for i in range(9):\n",
    "        input_context.append(context)\n",
    "        input_context_len.append(context_len)\n",
    "        input_utterance.append(features['distractor_{}'.format(i)])\n",
    "        input_utterance_len.append(features['distractor_{}_len'.format(i)])\n",
    "        labels_.append(tf.zeros_like(context_len))\n",
    "\n",
    "    input_context = tf.concat(input_context, axis=0)\n",
    "    input_context_len = tf.concat(input_context_len, axis=0)\n",
    "    input_utterance = tf.concat(input_utterance, axis=0)\n",
    "    input_utterance_len = tf.concat(input_utterance_len, axis=0)\n",
    "    labels_ = tf.concat(labels_, axis=0)\n",
    "\n",
    "    probs, loss = dual_encoder(\n",
    "        vocab_size,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        input_context,\n",
    "        input_context_len,\n",
    "        input_utterance,\n",
    "        input_utterance_len,\n",
    "        labels_)\n",
    "    \n",
    "    split_probs = tf.split(probs, num_or_size_splits=10, axis=0)\n",
    "    predictions = tf.concat(split_probs, axis=1)\n",
    "    predictions_2 = predictions[:, :2]\n",
    "    \n",
    "    recall_at_1_2 = tf.metrics.recall_at_k(labels=labels, predictions=predictions_2, k=1)\n",
    "    recall_at_1_10 = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=1)\n",
    "    recall_at_2_10 = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=2)\n",
    "    recall_at_5_10 = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=5)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        'recall_at_1_2': recall_at_1_2,\n",
    "        'recall_at_1_10': recall_at_1_10,\n",
    "        'recall_at_2_10': recall_at_2_10,\n",
    "        'recall_at_5_10': recall_at_5_10,\n",
    "    }\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        predictions=probs,\n",
    "        loss=loss,\n",
    "        train_op=None,\n",
    "        eval_metric_ops=eval_metric_ops\n",
    "    )\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    vocab_size = params['vocab_size']\n",
    "    embed_size = params['embed_size']\n",
    "    hidden_size = params['hidden_size']\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return model_fn_eval(features, labels, vocab_size, embed_size, hidden_size)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `tokenizer` function must be defined before restoring the vocabulary object\n",
    "# (pickle does not serialize functions)\n",
    "def tokenizer(sentences):\n",
    "    return (sentence.split() for sentence in sentences)\n",
    "\n",
    "class VocabularyAdapter:\n",
    "    \n",
    "    def __init__(self, vocabulary_bin):\n",
    "        self._vocab = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(vocabulary_bin)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._vocab.vocabulary_)\n",
    "    \n",
    "    @property\n",
    "    def vector_length(self):\n",
    "        return self._vocab.max_document_length\n",
    "\n",
    "\n",
    "def features_eval(vector_length):\n",
    "    features = []\n",
    "    keys = ['context', 'utterance']\n",
    "    keys += ['distractor_{}'.format(i) for i in range(9)]\n",
    "    for key in keys:\n",
    "        features += [\n",
    "            tf.feature_column.numeric_column(\n",
    "                key=key, shape=vector_length, dtype=tf.int64),\n",
    "            tf.feature_column.numeric_column(\n",
    "                key=key + '_len', shape=1, dtype=tf.int64),\n",
    "        ]\n",
    "    return features\n",
    "\n",
    "\n",
    "def input_fn_eval(name, filenames, features, batch_size, num_epochs=None):\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "\n",
    "    batch_example = tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=filenames,\n",
    "        features=example_features,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        randomize_input=True,\n",
    "        queue_capacity=200000 + batch_size * 10,\n",
    "        name='read_batch_record_features_' + name\n",
    "    )\n",
    "\n",
    "    batch_target = tf.zeros_like(batch_example['context_len'])\n",
    "\n",
    "    return batch_example, batch_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = 'ubuntu'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "VOCAB_BIN = os.path.join(DATA_DIR, 'vocabulary.bin')\n",
    "VALID_TFR = os.path.join(DATA_DIR, 'valid.tfrecords')\n",
    "TEST_TFR = os.path.join(DATA_DIR, 'test.tfrecords')\n",
    "\n",
    "def has_file(file):\n",
    "    if not os.path.isfile(file):\n",
    "        raise Exception('File not found: {}'.format(file))\n",
    "\n",
    "has_file(VOCAB_BIN)\n",
    "has_file(VALID_TFR)\n",
    "has_file(TEST_TFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(HOME_DIR, 'model')\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    raise Exception('Folder not found: {}'.format(MODEL_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = VocabularyAdapter(VOCAB_BIN)\n",
    "features = features_eval(vocab.vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'vocab_size': vocab.size,\n",
    "    'embed_size': 100,\n",
    "    'hidden_size': 256,\n",
    "}\n",
    "\n",
    "input_fn_valid = lambda: input_fn_eval('valid', [VALID_TFR], features, 16, 1)\n",
    "input_fn_test = lambda: input_fn_eval('test', [TEST_TFR], features, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir=MODEL_DIR,\n",
    "    params=params)\n",
    "\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print('Validation...\\n')\n",
    "estimator.evaluate(input_fn_valid, steps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-gpu-1.2)",
   "language": "python",
   "name": "tensorflow-gpu-1.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
