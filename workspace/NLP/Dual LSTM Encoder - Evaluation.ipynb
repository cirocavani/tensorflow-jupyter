{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics**\n",
    "\n",
    "Multi-class classification problem:\n",
    "\n",
    "* given:<br>\n",
    "    1 context and n utterances\n",
    "* return:<br>\n",
    "    which utterance is the correct response\n",
    "\n",
    "Metric:\n",
    "\n",
    "recall in k\n",
    "\n",
    "From n utterances, if the correct one is in the top k, counts as true positive (tp), otherwise, counts as false negative (fn).\n",
    "\n",
    "`recall = tp / (tp + fn)`\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/metrics/recall_at_k\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f0af53ef320>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 in 2 recall @ 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 3  # number of examples from evaluation (validation / test)\n",
    "num_labels = 1  # the only label is the class of the correct utterance (the position from 0 to n-1)\n",
    "num_classes = 2 # number of utterance (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(3, 1), dtype=int64)\n",
      "[[0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# by construction, the first utterance (class = 0) is the correct utterance\n",
    "labels = tf.constant(0, shape=(batch_size, num_labels), dtype=tf.int64)\n",
    "\n",
    "print(labels)\n",
    "print(labels.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(3, 2), dtype=float64)\n",
      "[[ 0.8   0.09]\n",
      " [ 0.6   0.1 ]\n",
      " [ 0.5   0.3 ]]\n"
     ]
    }
   ],
   "source": [
    "# logits for the first and second utterance\n",
    "predictions = tf.constant([0.8, 0.09, 0.6, 0.1, 0.5, 0.3], shape=(batch_size, num_classes), dtype=tf.float64)\n",
    "\n",
    "print(predictions)\n",
    "print(predictions.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"recall_at_1:0\", shape=(), dtype=float64)\n",
      "Tensor(\"recall_at_1/update:0\", shape=(), dtype=float64)\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "r, u = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=1)\n",
    "\n",
    "print(r)\n",
    "print(u)\n",
    "\n",
    "tf.local_variables_initializer().run()\n",
    "\n",
    "print(u.eval())\n",
    "print(r.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'recall_at_1/true_positive_at_1:0' shape=() dtype=float64_ref>\n",
      "<tf.Variable 'recall_at_1/false_negative_at_1:0' shape=() dtype=float64_ref>\n",
      "3.0 0.0\n"
     ]
    }
   ],
   "source": [
    "tp, fn = tf.local_variables()\n",
    "\n",
    "print(tp)\n",
    "print(fn)\n",
    "\n",
    "print(tp.eval(), fn.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 in 10 recall @ 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_labels = 1\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(4, 1), dtype=int64)\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# by construction, the first utterance (class = 0) is the correct utterance\n",
    "labels = tf.constant(0, shape=(batch_size, num_labels), dtype=tf.int64)\n",
    "\n",
    "print(labels)\n",
    "print(labels.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_3:0\", shape=(4, 10), dtype=float64)\n",
      "[[ 0.9  0.8  0.7  0.6  0.5  0.4  0.3  0.2  0.1  0.1]\n",
      " [ 0.8  0.9  0.7  0.6  0.5  0.4  0.3  0.2  0.1  0.1]\n",
      " [ 0.4  0.9  0.8  0.7  0.6  0.5  0.3  0.2  0.1  0.1]\n",
      " [ 0.   0.9  0.8  0.7  0.6  0.5  0.4  0.3  0.2  0.1]]\n"
     ]
    }
   ],
   "source": [
    "# logits for a good result (true positive)\n",
    "example_class0 = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.1]\n",
    "example_class1 = [0.8, 0.9, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.1]\n",
    "# logits for a bad result (false negative)\n",
    "example_class5 = [0.4, 0.9, 0.8, 0.7, 0.6, 0.5, 0.3, 0.2, 0.1, 0.1]\n",
    "example_class9 = [0.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "logits = example_class0 + example_class1 + example_class5 + example_class9\n",
    "\n",
    "predictions = tf.constant(logits,shape=(batch_size, num_classes), dtype=tf.float64)\n",
    "\n",
    "print(predictions)\n",
    "print(predictions.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"recall_at_5:0\", shape=(), dtype=float64)\n",
      "Tensor(\"recall_at_5/update:0\", shape=(), dtype=float64)\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "r, u = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=5)\n",
    "\n",
    "print(r)\n",
    "print(u)\n",
    "\n",
    "tf.local_variables_initializer().run()\n",
    "\n",
    "print(u.eval())\n",
    "print(r.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'recall_at_5/true_positive_at_5:0' shape=() dtype=float64_ref>\n",
      "<tf.Variable 'recall_at_5/false_negative_at_5:0' shape=() dtype=float64_ref>\n",
      "2.0 2.0\n"
     ]
    }
   ],
   "source": [
    "*_, tp, fn = tf.local_variables()\n",
    "\n",
    "print(tp)\n",
    "print(fn)\n",
    "\n",
    "print(tp.eval(), fn.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f0af53f17f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': <tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>, 'context_len': <tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>, 'utterance': <tf.Tensor 'Const_2:0' shape=(3, 4) dtype=float32>, 'utterance_len': <tf.Tensor 'Const_3:0' shape=(3, 1) dtype=int32>, 'distractor_0': <tf.Tensor 'Const_4:0' shape=(3, 4) dtype=float32>, 'distractor_0_len': <tf.Tensor 'Const_5:0' shape=(3, 1) dtype=int32>, 'distractor_1': <tf.Tensor 'Const_6:0' shape=(3, 4) dtype=float32>, 'distractor_1_len': <tf.Tensor 'Const_7:0' shape=(3, 1) dtype=int32>, 'distractor_2': <tf.Tensor 'Const_8:0' shape=(3, 4) dtype=float32>, 'distractor_2_len': <tf.Tensor 'Const_9:0' shape=(3, 1) dtype=int32>, 'distractor_3': <tf.Tensor 'Const_10:0' shape=(3, 4) dtype=float32>, 'distractor_3_len': <tf.Tensor 'Const_11:0' shape=(3, 1) dtype=int32>, 'distractor_4': <tf.Tensor 'Const_12:0' shape=(3, 4) dtype=float32>, 'distractor_4_len': <tf.Tensor 'Const_13:0' shape=(3, 1) dtype=int32>, 'distractor_5': <tf.Tensor 'Const_14:0' shape=(3, 4) dtype=float32>, 'distractor_5_len': <tf.Tensor 'Const_15:0' shape=(3, 1) dtype=int32>, 'distractor_6': <tf.Tensor 'Const_16:0' shape=(3, 4) dtype=float32>, 'distractor_6_len': <tf.Tensor 'Const_17:0' shape=(3, 1) dtype=int32>, 'distractor_7': <tf.Tensor 'Const_18:0' shape=(3, 4) dtype=float32>, 'distractor_7_len': <tf.Tensor 'Const_19:0' shape=(3, 1) dtype=int32>, 'distractor_8': <tf.Tensor 'Const_20:0' shape=(3, 4) dtype=float32>, 'distractor_8_len': <tf.Tensor 'Const_21:0' shape=(3, 1) dtype=int32>}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "vector_len = 4\n",
    "\n",
    "features = {\n",
    "    'context': tf.constant(1.0, shape=(batch_size, vector_len)),\n",
    "    'context_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'utterance': tf.constant(2.0, shape=(batch_size, vector_len)),\n",
    "    'utterance_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_0': tf.constant(3.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_0_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_1': tf.constant(4.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_1_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_2': tf.constant(5.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_2_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_3': tf.constant(6.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_3_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_4': tf.constant(7.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_4_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_5': tf.constant(8.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_5_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_6': tf.constant(9.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_6_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_7': tf.constant(10.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_7_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "    'distractor_8': tf.constant(11.0, shape=(batch_size, vector_len)),\n",
    "    'distractor_8_len': tf.constant(vector_len, shape=(batch_size, 1)),\n",
    "}\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_22:0\", shape=(3, 1), dtype=int32)\n",
      "[[0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "labels = tf.constant(0, shape=(batch_size, 1))\n",
    "\n",
    "print(labels)\n",
    "print(labels.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(3, 4), dtype=float32)\n",
      "[[ 1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.]]\n",
      "\n",
      "Tensor(\"Const_1:0\", shape=(3, 1), dtype=int32)\n",
      "[[4]\n",
      " [4]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "context = features['context']\n",
    "context_len = features['context_len']\n",
    "\n",
    "print(context)\n",
    "print(context.eval())\n",
    "print()\n",
    "print(context_len)\n",
    "print(context_len.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(3, 4), dtype=float32)\n",
      "[[ 2.  2.  2.  2.]\n",
      " [ 2.  2.  2.  2.]\n",
      " [ 2.  2.  2.  2.]]\n",
      "\n",
      "Tensor(\"Const_3:0\", shape=(3, 1), dtype=int32)\n",
      "[[4]\n",
      " [4]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "utterance = features['utterance']\n",
    "utterance_len = features['utterance_len']\n",
    "\n",
    "print(utterance)\n",
    "print(utterance.eval())\n",
    "print()\n",
    "print(utterance_len)\n",
    "print(utterance_len.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>]\n",
      "[<tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>]\n",
      "[<tf.Tensor 'Const_2:0' shape=(3, 4) dtype=float32>]\n",
      "[<tf.Tensor 'Const_3:0' shape=(3, 1) dtype=int32>]\n",
      "[<tf.Tensor 'ones:0' shape=(3, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "input_context = []\n",
    "input_context_len = []\n",
    "input_utterance = []\n",
    "input_utterance_len = []\n",
    "labels_ = []\n",
    "\n",
    "input_context.append(context)\n",
    "input_context_len.append(context_len)\n",
    "input_utterance.append(utterance)\n",
    "input_utterance_len.append(utterance_len)\n",
    "labels_.append(tf.ones(shape=(batch_size, 1)))\n",
    "\n",
    "print(input_context)\n",
    "print(input_context_len)\n",
    "print(input_utterance)\n",
    "print(input_utterance_len)\n",
    "print(labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_context\n",
      "\n",
      " [<tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const:0' shape=(3, 4) dtype=float32>] \n",
      "\n",
      "input_context_len\n",
      "\n",
      " [<tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_1:0' shape=(3, 1) dtype=int32>] \n",
      "\n",
      "input_utterance\n",
      "\n",
      " [<tf.Tensor 'Const_2:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const_4:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const_6:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const_8:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const_10:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const_12:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const_14:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const_16:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const_18:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'Const_20:0' shape=(3, 4) dtype=float32>] \n",
      "\n",
      "input_utterance_len\n",
      "\n",
      " [<tf.Tensor 'Const_3:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_5:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_7:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_9:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_11:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_13:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_15:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_17:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_19:0' shape=(3, 1) dtype=int32>, <tf.Tensor 'Const_21:0' shape=(3, 1) dtype=int32>] \n",
      "\n",
      "labels_\n",
      "\n",
      " [<tf.Tensor 'ones:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'zeros:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'zeros_1:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'zeros_2:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'zeros_3:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'zeros_4:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'zeros_5:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'zeros_6:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'zeros_7:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'zeros_8:0' shape=(3, 1) dtype=float32>] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    input_context.append(context)\n",
    "    input_context_len.append(context_len)\n",
    "    input_utterance.append(features['distractor_{}'.format(i)])\n",
    "    input_utterance_len.append(features['distractor_{}_len'.format(i)])\n",
    "    labels_.append(tf.zeros(shape=(batch_size, 1)))\n",
    "\n",
    "print('input_context\\n\\n', input_context, '\\n')\n",
    "print('input_context_len\\n\\n', input_context_len, '\\n')\n",
    "print('input_utterance\\n\\n', input_utterance, '\\n')\n",
    "print('input_utterance_len\\n\\n', input_utterance_len, '\\n')\n",
    "print('labels_\\n\\n', labels_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_context\n",
      "\n",
      " Tensor(\"concat:0\", shape=(30, 4), dtype=float32) \n",
      "\n",
      "input_context_len\n",
      "\n",
      " Tensor(\"concat_1:0\", shape=(30, 1), dtype=int32) \n",
      "\n",
      "input_utterance\n",
      "\n",
      " Tensor(\"concat_2:0\", shape=(30, 4), dtype=float32) \n",
      "\n",
      "input_utterance_len\n",
      "\n",
      " Tensor(\"concat_3:0\", shape=(30, 1), dtype=int32) \n",
      "\n",
      "labels_\n",
      "\n",
      " Tensor(\"concat_4:0\", shape=(30, 1), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_context = tf.concat(input_context, axis=0)\n",
    "input_context_len = tf.concat(input_context_len, axis=0)\n",
    "input_utterance = tf.concat(input_utterance, axis=0)\n",
    "input_utterance_len = tf.concat(input_utterance_len, axis=0)\n",
    "labels_ = tf.concat(labels_, axis=0)\n",
    "\n",
    "print('input_context\\n\\n', input_context, '\\n')\n",
    "print('input_context_len\\n\\n', input_context_len, '\\n')\n",
    "print('input_utterance\\n\\n', input_utterance, '\\n')\n",
    "print('input_utterance_len\\n\\n', input_utterance_len, '\\n')\n",
    "print('labels_\\n\\n', labels_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_23:0\", shape=(30, 1), dtype=int32)\n",
      "[[ 0]\n",
      " [ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [13]\n",
      " [14]\n",
      " [15]\n",
      " [16]\n",
      " [17]\n",
      " [18]\n",
      " [19]\n",
      " [20]\n",
      " [21]\n",
      " [22]\n",
      " [23]\n",
      " [24]\n",
      " [25]\n",
      " [26]\n",
      " [27]\n",
      " [28]\n",
      " [29]]\n"
     ]
    }
   ],
   "source": [
    "probs = tf.constant(list(range(batch_size * 10)), shape=(batch_size * 10, 1))\n",
    "\n",
    "print(probs)\n",
    "print(probs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_5:0\", shape=(3, 10), dtype=int32)\n",
      "[[ 0  3  6  9 12 15 18 21 24 27]\n",
      " [ 1  4  7 10 13 16 19 22 25 28]\n",
      " [ 2  5  8 11 14 17 20 23 26 29]]\n"
     ]
    }
   ],
   "source": [
    "split_probs = tf.split(probs, num_or_size_splits=10, axis=0)\n",
    "predictions = tf.concat(split_probs, axis=1)\n",
    "\n",
    "print(predictions)\n",
    "print(predictions.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(3, 2), dtype=int32)\n",
      "[[0 3]\n",
      " [1 4]\n",
      " [2 5]]\n"
     ]
    }
   ],
   "source": [
    "predictions_2 = predictions[:, :2]\n",
    "\n",
    "print(predictions_2)\n",
    "print(predictions_2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_fn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dual_encoder(vocab_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 input_context,\n",
    "                 input_context_len,\n",
    "                 input_utterance,\n",
    "                 input_utterance_len,\n",
    "                 targets):\n",
    "\n",
    "    input_data = tf.concat([input_context, input_utterance], axis=0)\n",
    "    input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "    input_length = tf.reshape(input_length, [-1])\n",
    "    \n",
    "    embeddings = tf.get_variable(\n",
    "        'embeddings',\n",
    "        shape=(vocab_size, embed_size),\n",
    "        initializer=tf.random_uniform_initializer(-0.25, 0.25))\n",
    "\n",
    "    input_embed = tf.nn.embedding_lookup(\n",
    "        embeddings, input_data, name='input_embed')\n",
    "        \n",
    "    with tf.variable_scope('rnn'):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(\n",
    "            hidden_size,\n",
    "            forget_bias=2.0,\n",
    "            use_peepholes=True,\n",
    "            state_is_tuple=True)\n",
    "\n",
    "        outputs, states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            input_embed,\n",
    "            sequence_length=input_length,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        context_encoding, utterance_encoding = tf.split(\n",
    "            states.h, num_or_size_splits=2, axis=0)\n",
    "\n",
    "    with tf.variable_scope('prediction'):\n",
    "        ct = context_encoding\n",
    "        rt = utterance_encoding\n",
    "        M = tf.get_variable(\n",
    "            'M',\n",
    "            shape=(hidden_size, hidden_size),\n",
    "            initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        ct_M = tf.matmul(ct, M)\n",
    "        batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "        batch_rt = tf.expand_dims(rt, axis=2)\n",
    "        batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "        ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "        b = tf.get_variable(\n",
    "           'b', shape=(), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        logits = ct_M_r + b\n",
    "        \n",
    "        probs = tf.sigmoid(logits)\n",
    "\n",
    "    if targets is None:\n",
    "        return probs, None\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(\n",
    "        multi_class_labels=targets, logits=logits, reduction=tf.losses.Reduction.MEAN)\n",
    "    \n",
    "    return probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn_eval(features, labels, vocab_size, embed_size, hidden_size):\n",
    "    input_context = []\n",
    "    input_context_len = []\n",
    "    input_utterance = []\n",
    "    input_utterance_len = []\n",
    "    labels_ = []\n",
    "    \n",
    "    context = features['context']\n",
    "    context_len = features['context_len']\n",
    "\n",
    "    input_context.append(context)\n",
    "    input_context_len.append(context_len)\n",
    "    input_utterance.append(features['utterance'])\n",
    "    input_utterance_len.append(features['utterance_len'])\n",
    "    labels_.append(tf.ones_like(context_len))\n",
    "    \n",
    "    for i in range(9):\n",
    "        input_context.append(context)\n",
    "        input_context_len.append(context_len)\n",
    "        input_utterance.append(features['distractor_{}'.format(i)])\n",
    "        input_utterance_len.append(features['distractor_{}_len'.format(i)])\n",
    "        labels_.append(tf.zeros_like(context_len))\n",
    "\n",
    "    input_context = tf.concat(input_context, axis=0)\n",
    "    input_context_len = tf.concat(input_context_len, axis=0)\n",
    "    input_utterance = tf.concat(input_utterance, axis=0)\n",
    "    input_utterance_len = tf.concat(input_utterance_len, axis=0)\n",
    "    labels_ = tf.concat(labels_, axis=0)\n",
    "\n",
    "    probs, loss = dual_encoder(\n",
    "        vocab_size,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        input_context,\n",
    "        input_context_len,\n",
    "        input_utterance,\n",
    "        input_utterance_len,\n",
    "        labels_)\n",
    "    \n",
    "    split_probs = tf.split(probs, num_or_size_splits=10, axis=0)\n",
    "    predictions = tf.concat(split_probs, axis=1)\n",
    "    predictions_2 = predictions[:, :2]\n",
    "    \n",
    "    recall_at_1_2 = tf.metrics.recall_at_k(labels=labels, predictions=predictions_2, k=1)\n",
    "    recall_at_1_10 = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=1)\n",
    "    recall_at_2_10 = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=2)\n",
    "    recall_at_5_10 = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=5)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        'recall_at_1_2': recall_at_1_2,\n",
    "        'recall_at_1_10': recall_at_1_10,\n",
    "        'recall_at_2_10': recall_at_2_10,\n",
    "        'recall_at_5_10': recall_at_5_10,\n",
    "    }\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        predictions=probs,\n",
    "        loss=loss,\n",
    "        train_op=None,\n",
    "        eval_metric_ops=eval_metric_ops\n",
    "    )\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    vocab_size = params['vocab_size']\n",
    "    embed_size = params['embed_size']\n",
    "    hidden_size = params['hidden_size']\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return model_fn_eval(features, labels, vocab_size, embed_size, hidden_size)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `tokenizer` function must be defined before restoring the vocabulary object\n",
    "# (pickle does not serialize functions)\n",
    "def tokenizer(sentences):\n",
    "    return (sentence.split() for sentence in sentences)\n",
    "\n",
    "class VocabularyAdapter:\n",
    "    \n",
    "    def __init__(self, vocabulary_bin):\n",
    "        self._vocab = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(vocabulary_bin)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._vocab.vocabulary_)\n",
    "    \n",
    "    @property\n",
    "    def vector_length(self):\n",
    "        return self._vocab.max_document_length\n",
    "\n",
    "\n",
    "def features_eval(vector_length):\n",
    "    features = []\n",
    "    keys = ['context', 'utterance']\n",
    "    keys += ['distractor_{}'.format(i) for i in range(9)]\n",
    "    for key in keys:\n",
    "        features += [\n",
    "            tf.feature_column.numeric_column(\n",
    "                key=key, shape=vector_length, dtype=tf.int64),\n",
    "            tf.feature_column.numeric_column(\n",
    "                key=key + '_len', shape=1, dtype=tf.int64),\n",
    "        ]\n",
    "    return features\n",
    "\n",
    "\n",
    "def input_fn_eval(name, filenames, features, batch_size, num_epochs=None):\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "\n",
    "    batch_example = tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=filenames,\n",
    "        features=example_features,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        randomize_input=True,\n",
    "        queue_capacity=200000 + batch_size * 10,\n",
    "        name='read_batch_record_features_' + name\n",
    "    )\n",
    "\n",
    "    batch_target = tf.zeros_like(batch_example['context_len'])\n",
    "\n",
    "    return batch_example, batch_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = 'ubuntu'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "VOCAB_BIN = os.path.join(DATA_DIR, 'vocabulary.bin')\n",
    "VALID_TFR = os.path.join(DATA_DIR, 'valid.tfrecords')\n",
    "TEST_TFR = os.path.join(DATA_DIR, 'test.tfrecords')\n",
    "\n",
    "def has_file(file):\n",
    "    if not os.path.isfile(file):\n",
    "        raise Exception('File not found: {}'.format(file))\n",
    "\n",
    "has_file(VOCAB_BIN)\n",
    "has_file(VALID_TFR)\n",
    "has_file(TEST_TFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(HOME_DIR, 'model')\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    raise Exception('Folder not found: {}'.format(MODEL_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = VocabularyAdapter(VOCAB_BIN)\n",
    "features = features_eval(vocab.vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'vocab_size': vocab.size,\n",
    "    'embed_size': 100,\n",
    "    'hidden_size': 200,\n",
    "}\n",
    "\n",
    "input_fn_valid = lambda: input_fn_eval('valid', [VALID_TFR], features, 16, 1)\n",
    "input_fn_test = lambda: input_fn_eval('test', [TEST_TFR], features, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'ubuntu/model', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f0a5ecd69b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir=MODEL_DIR,\n",
    "    params=params)\n",
    "\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n",
      "\n",
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-30-15:59:00\n",
      "INFO:tensorflow:Restoring parameters from ubuntu/model/model.ckpt-39070\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-30-16:05:22\n",
      "INFO:tensorflow:Saving dict for global step 39070: global_step = 39070, loss = 1.83156, recall_at_1_10 = 0.39018404908, recall_at_1_2 = 0.780419222904, recall_at_2_10 = 0.572188139059, recall_at_5_10 = 0.847085889571\n",
      "CPU times: user 5min 55s, sys: 29.5 s, total: 6min 24s\n",
      "Wall time: 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Validation...\\n')\n",
    "estimator.evaluate(input_fn_valid, name='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test...\n",
      "\n",
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-30-16:05:23\n",
      "INFO:tensorflow:Restoring parameters from ubuntu/model/model.ckpt-39070\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-30-16:11:31\n",
      "INFO:tensorflow:Saving dict for global step 39070: global_step = 39070, loss = 1.8324, recall_at_1_10 = 0.385359408034, recall_at_1_2 = 0.778594080338, recall_at_2_10 = 0.565380549683, recall_at_5_10 = 0.842441860465\n",
      "CPU times: user 5min 48s, sys: 28.7 s, total: 6min 17s\n",
      "Wall time: 6min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Test...\\n')\n",
    "estimator.evaluate(input_fn_test, name='test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-gpu-1.2)",
   "language": "python",
   "name": "tensorflow-gpu-1.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
