{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7feef2eec6a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings:\n",
      "\n",
      "Tensor(\"stack:0\", shape=(4, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 4\n",
    "embed_size = 2\n",
    "\n",
    "word_0 = [0, 0]\n",
    "word_1 = [1, 0]\n",
    "word_2 = [0, 1]\n",
    "word_3 = [1, 1]\n",
    "\n",
    "embeddings = tf.stack([word_0, word_1, word_2, word_3])\n",
    "\n",
    "print('Embeddings:\\n')\n",
    "print(embeddings)\n",
    "embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      "\n",
      "Tensor(\"stack_1:0\", shape=(2, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 2],\n",
       "       [3, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "sentence_length = 3\n",
    "\n",
    "sentence_0 = [0, 3, 2]\n",
    "sentence_1 = [3, 1, 0]\n",
    "\n",
    "input_data = tf.stack([sentence_0, sentence_1])\n",
    "\n",
    "print('Sentences:\\n')\n",
    "print(input_data)\n",
    "input_data.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "\n",
      "Tensor(\"embedding_lookup:0\", shape=(2, 3, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0]]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embed = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "\n",
    "print('Input:\\n')\n",
    "print(input_embed)\n",
    "input_embed.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pairing\n",
    "\n",
    "Similarity between **`c`** and **`c'`**, where **`c' = Mr`**.\n",
    "\n",
    "**`c`** -> encoded context vector\n",
    "\n",
    "**`r`** -> encoded response vector\n",
    "\n",
    "**`M`** -> translate responce to context, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7feef2eec860>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [3 4]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "M = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "print('M', M.shape, '\\n')\n",
    "print(M.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c (2, 1) \n",
      "\n",
      "[[1]\n",
      " [2]] \n",
      "\n",
      "r (2, 1) \n",
      "\n",
      "[[3]\n",
      " [4]] \n",
      "\n",
      "ct * M (1, 2) \n",
      "\n",
      "[[ 7 10]] \n",
      "\n",
      "ct * M * r (1, 1) \n",
      "\n",
      "[[61]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[1], [2]])\n",
    "r = tf.constant([[3], [4]])\n",
    "\n",
    "ct_M = tf.matmul(c, M, transpose_a=True)\n",
    "ct_M_r = tf.matmul(ct_M, r)\n",
    "\n",
    "print('c', c.shape, '\\n')\n",
    "print(c.eval(), '\\n')\n",
    "print('r', r.shape, '\\n')\n",
    "print(r.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [0 0]] \n",
      "\n",
      "rt (2, 2) \n",
      "\n",
      "[[3 4]\n",
      " [0 0]] \n",
      "\n",
      "ct * M (2, 2) \n",
      "\n",
      "[[ 7 10]\n",
      " [ 0  0]] \n",
      "\n",
      "ct * M * r (2, 2) \n",
      "\n",
      "[[61  0]\n",
      " [ 0  0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct = tf.constant([[1, 2], [0, 0]])\n",
    "rt = tf.constant([[3, 4], [0, 0]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "ct_M_r = tf.matmul(ct_M, rt, transpose_b=True)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c (2, 1) \n",
      "\n",
      "[[5]\n",
      " [6]] \n",
      "\n",
      "r (2, 1) \n",
      "\n",
      "[[7]\n",
      " [8]] \n",
      "\n",
      "ct * M (1, 2) \n",
      "\n",
      "[[23 34]] \n",
      "\n",
      "ct * M * r (1, 1) \n",
      "\n",
      "[[433]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[5], [6]])\n",
    "r = tf.constant([[7], [8]])\n",
    "\n",
    "ct_M = tf.matmul(c, M, transpose_a=True)\n",
    "ct_M_r = tf.matmul(ct_M, r)\n",
    "\n",
    "print('c', c.shape, '\\n')\n",
    "print(c.eval(), '\\n')\n",
    "print('r', r.shape, '\\n')\n",
    "print(r.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [5 6]] \n",
      "\n",
      "rt (2, 2) \n",
      "\n",
      "[[3 4]\n",
      " [7 8]] \n",
      "\n",
      "ct * M (2, 2) \n",
      "\n",
      "[[ 7 10]\n",
      " [23 34]] \n",
      "\n",
      "ct * M * r (2, 2) \n",
      "\n",
      "[[ 61 129]\n",
      " [205 433]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct = tf.constant([[1, 2], [5, 6]])\n",
    "rt = tf.constant([[3, 4], [7, 8]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "ct_M_r = tf.matmul(ct_M, rt, transpose_b=True)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [5 6]] \n",
      "\n",
      "rt (2, 2) \n",
      "\n",
      "[[3 4]\n",
      " [7 8]] \n",
      "\n",
      "ct * M (2, 2) \n",
      "\n",
      "[[ 7 10]\n",
      " [23 34]] \n",
      "\n",
      "ct * M (batch) (2, 2, 1) \n",
      "\n",
      "[[[ 7]\n",
      "  [10]]\n",
      "\n",
      " [[23]\n",
      "  [34]]] \n",
      "\n",
      "rt (batch) (2, 2, 1) \n",
      "\n",
      "[[[3]\n",
      "  [4]]\n",
      "\n",
      " [[7]\n",
      "  [8]]] \n",
      "\n",
      "ct * M * r (batch) (2, 1, 1) \n",
      "\n",
      "[[[ 61]]\n",
      "\n",
      " [[433]]] \n",
      "\n",
      "ct * M * r (2, 1) \n",
      "\n",
      "[[ 61]\n",
      " [433]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct = tf.constant([[1, 2], [5, 6]])\n",
    "rt = tf.constant([[3, 4], [7, 8]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "\n",
    "batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "batch_rt = tf.expand_dims(rt, axis=2)\n",
    "\n",
    "batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "\n",
    "ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M (batch)', batch_ct_M.shape, '\\n')\n",
    "print(batch_ct_M.eval(), '\\n')\n",
    "print('rt (batch)', batch_rt.shape, '\\n')\n",
    "print(batch_rt.eval(), '\\n')\n",
    "print('ct * M * r (batch)', batch_ct_M_r.shape, '\\n')\n",
    "print(batch_ct_M_r.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dual LSTM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7feef0eaf5f8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 25\n",
    "sentence_size = 4\n",
    "batch_size = 2\n",
    "embed_size = 5\n",
    "hidden_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Sentence -> Word Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform:0\", shape=(2, 4), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[20,  3, 18,  0],\n",
       "       [19, 10, 16, 11]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = tf.random_uniform(\n",
    "    shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "\n",
    "print(input_context)\n",
    "input_context.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_1:0\", shape=(2, 4), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8, 16,  6, 22],\n",
       "       [16, 18, 11, 14]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_utterance = tf.random_uniform(\n",
    "    shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "\n",
    "print(input_utterance)\n",
    "input_utterance.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(2, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "\n",
    "print(input_context_len)\n",
    "input_context_len.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(2, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_utterance_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "\n",
    "print(input_utterance_len)\n",
    "input_utterance_len.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(25, 5) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.14988273, -0.19110286, -0.24203259,  0.09176153,  0.13214087],\n",
       "       [ 0.1510129 ,  0.0303269 , -0.15055364, -0.14482069,  0.02167702],\n",
       "       [-0.1299116 ,  0.16214228, -0.03491116,  0.09344488, -0.09528035],\n",
       "       [-0.24947137,  0.19961739, -0.01646852, -0.0918501 ,  0.1530059 ],\n",
       "       [ 0.11675918, -0.01111042, -0.0985992 ,  0.09767246, -0.16816711],\n",
       "       [ 0.03683805, -0.18322444, -0.13840151,  0.08290368,  0.13598228],\n",
       "       [-0.04843336, -0.0033769 ,  0.0212689 ,  0.01030666,  0.02789927],\n",
       "       [ 0.08915007,  0.07976782,  0.24043638, -0.17069489, -0.02816147],\n",
       "       [-0.1653192 ,  0.03305852,  0.11798108, -0.20664763,  0.13696319],\n",
       "       [-0.06338978,  0.04527843,  0.01564932, -0.02352995,  0.07507151],\n",
       "       [ 0.03615546,  0.19331169,  0.14691347, -0.02281886,  0.1041016 ],\n",
       "       [ 0.1577577 , -0.02061677,  0.1709919 , -0.22921723, -0.04294664],\n",
       "       [ 0.20407331, -0.22857004, -0.24630672,  0.24416858, -0.20645511],\n",
       "       [ 0.12103355,  0.07726097, -0.01252657,  0.13673735,  0.07996988],\n",
       "       [ 0.05597407,  0.11223638,  0.20009196,  0.20111275, -0.10194093],\n",
       "       [ 0.13453859, -0.11819875, -0.17189431,  0.14056057,  0.08515871],\n",
       "       [-0.06486589, -0.24939632,  0.2331118 ,  0.09323716, -0.01013249],\n",
       "       [-0.13184053,  0.14212346,  0.22124308, -0.11775833,  0.03535438],\n",
       "       [-0.16949397,  0.17018604, -0.05815071, -0.07912713, -0.1572476 ],\n",
       "       [-0.24115968,  0.24950135,  0.01116753, -0.23983431,  0.14387524],\n",
       "       [-0.14629865, -0.01260984,  0.11717206,  0.0479545 , -0.23843712],\n",
       "       [-0.22518218, -0.13222927,  0.09375882,  0.01615936,  0.04991448],\n",
       "       [ 0.22622663, -0.19167888,  0.17659527,  0.1906907 , -0.08598322],\n",
       "       [-0.0886941 , -0.14801973, -0.12819946, -0.20842588, -0.09348184],\n",
       "       [-0.11714709,  0.23732382, -0.24154603, -0.04631478,  0.11294776]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = tf.Variable(\n",
    "    tf.random_uniform(shape=(vocab_size, embed_size), minval=-0.25, maxval=0.25))\n",
    "\n",
    "embeddings.initializer.run()\n",
    "\n",
    "print(embeddings)\n",
    "embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(2, 4, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.03615546,  0.19331169,  0.14691347, -0.02281886,  0.1041016 ],\n",
       "        [ 0.20407331, -0.22857004, -0.24630672,  0.24416858, -0.20645511],\n",
       "        [ 0.22622663, -0.19167888,  0.17659527,  0.1906907 , -0.08598322],\n",
       "        [-0.24947137,  0.19961739, -0.01646852, -0.0918501 ,  0.1530059 ]],\n",
       "\n",
       "       [[-0.1299116 ,  0.16214228, -0.03491116,  0.09344488, -0.09528035],\n",
       "        [-0.04843336, -0.0033769 ,  0.0212689 ,  0.01030666,  0.02789927],\n",
       "        [ 0.22622663, -0.19167888,  0.17659527,  0.1906907 , -0.08598322],\n",
       "        [ 0.1510129 ,  0.0303269 , -0.15055364, -0.14482069,  0.02167702]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embed = tf.nn.embedding_lookup(embeddings, input_context)\n",
    "\n",
    "print(context_embed)\n",
    "context_embed.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup_1:0\", shape=(2, 4, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.05597407,  0.11223638,  0.20009196,  0.20111275, -0.10194093],\n",
       "        [-0.24947137,  0.19961739, -0.01646852, -0.0918501 ,  0.1530059 ],\n",
       "        [ 0.13453859, -0.11819875, -0.17189431,  0.14056057,  0.08515871],\n",
       "        [-0.11714709,  0.23732382, -0.24154603, -0.04631478,  0.11294776]],\n",
       "\n",
       "       [[ 0.03683805, -0.18322444, -0.13840151,  0.08290368,  0.13598228],\n",
       "        [ 0.1577577 , -0.02061677,  0.1709919 , -0.22921723, -0.04294664],\n",
       "        [ 0.03683805, -0.18322444, -0.13840151,  0.08290368,  0.13598228],\n",
       "        [-0.1299116 ,  0.16214228, -0.03491116,  0.09344488, -0.09528035]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_embed = tf.nn.embedding_lookup(embeddings, input_utterance)\n",
    "\n",
    "print(utterance_embed)\n",
    "utterance_embed.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual Encode - Input**\n",
    "\n",
    "Concatenated tensor to encode both sentences in a single pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", shape=(4, 4, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.1577577 , -0.02061677,  0.1709919 , -0.22921723, -0.04294664],\n",
       "        [-0.13184053,  0.14212346,  0.22124308, -0.11775833,  0.03535438],\n",
       "        [ 0.03615546,  0.19331169,  0.14691347, -0.02281886,  0.1041016 ],\n",
       "        [ 0.1577577 , -0.02061677,  0.1709919 , -0.22921723, -0.04294664]],\n",
       "\n",
       "       [[ 0.11675918, -0.01111042, -0.0985992 ,  0.09767246, -0.16816711],\n",
       "        [ 0.08915007,  0.07976782,  0.24043638, -0.17069489, -0.02816147],\n",
       "        [-0.06338978,  0.04527843,  0.01564932, -0.02352995,  0.07507151],\n",
       "        [-0.06486589, -0.24939632,  0.2331118 ,  0.09323716, -0.01013249]],\n",
       "\n",
       "       [[ 0.03683805, -0.18322444, -0.13840151,  0.08290368,  0.13598228],\n",
       "        [ 0.1510129 ,  0.0303269 , -0.15055364, -0.14482069,  0.02167702],\n",
       "        [ 0.08915007,  0.07976782,  0.24043638, -0.17069489, -0.02816147],\n",
       "        [ 0.08915007,  0.07976782,  0.24043638, -0.17069489, -0.02816147]],\n",
       "\n",
       "       [[ 0.22622663, -0.19167888,  0.17659527,  0.1906907 , -0.08598322],\n",
       "        [-0.24115968,  0.24950135,  0.01116753, -0.23983431,  0.14387524],\n",
       "        [-0.11714709,  0.23732382, -0.24154603, -0.04631478,  0.11294776],\n",
       "        [-0.1653192 ,  0.03305852,  0.11798108, -0.20664763,  0.13696319]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embed = tf.concat([context_embed, utterance_embed], axis=0)\n",
    "\n",
    "print(input_embed)\n",
    "input_embed.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_1:0\", shape=(4, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "\n",
    "print(input_length)\n",
    "input_length.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length = tf.reshape(input_length, [-1])\n",
    "\n",
    "print(input_length)\n",
    "input_length.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      "\n",
      "Tensor(\"rnn/transpose:0\", shape=(4, 4, 8), dtype=float32)\n",
      "\n",
      "Final states:\n",
      "\n",
      "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 8) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 8) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "cell = tf.nn.rnn_cell.LSTMCell(\n",
    "    hidden_size,\n",
    "    forget_bias=2.0,\n",
    "    use_peepholes=True,\n",
    "    state_is_tuple=True)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(\n",
    "    cell,\n",
    "    input_embed,\n",
    "    sequence_length=input_length,\n",
    "    dtype=tf.float32)\n",
    "\n",
    "for tv in cell.trainable_variables:\n",
    "    tv.initializer.run()\n",
    "\n",
    "print('Outputs:\\n')\n",
    "print(outputs)\n",
    "print()\n",
    "print('Final states:\\n')\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual Encode - Output**\n",
    "\n",
    "Split the encode of each sentece type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_encoding, utterance_encoding = tf.split(states.h, num_or_size_splits=2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"split:0\", shape=(?, 8), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00699558,  0.00977578, -0.00646461, -0.00915181,  0.01707251,\n",
       "        -0.0238877 , -0.00059203,  0.01717633],\n",
       "       [ 0.00099451, -0.0106104 , -0.04555769, -0.01584092,  0.01838387,\n",
       "        -0.04374483, -0.03094321,  0.04608263]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(context_encoding)\n",
    "context_encoding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"split:1\", shape=(?, 8), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03658517, -0.01717115,  0.04685726, -0.0335674 ,  0.00718115,\n",
       "         0.01776352,  0.01542488, -0.01498981],\n",
       "       [ 0.06261449, -0.03825479, -0.06994751,  0.04793863, -0.00912744,\n",
       "        -0.02626521, -0.03092923,  0.02570395]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(utterance_encoding)\n",
    "utterance_encoding.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_1:0' shape=(8, 8) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.02592108, -0.49067274, -0.76623291,  1.49376059, -0.4238739 ,\n",
       "         0.92777282, -0.18552829,  0.39114252],\n",
       "       [ 0.35380542, -0.02336758,  0.47686008,  0.17341617,  0.34636134,\n",
       "        -0.48681974, -0.15234731,  0.87920207],\n",
       "       [-0.7267921 , -1.09397745, -0.19578362,  0.66617787, -0.32199371,\n",
       "         0.27647865,  0.08492222,  1.80460811],\n",
       "       [-1.47765732,  0.58444881,  0.75915891, -0.41247815, -0.95768559,\n",
       "         0.19206792,  0.17678015, -0.38182244],\n",
       "       [ 0.09469015, -0.7331118 , -0.28203532,  0.37355739,  0.00920274,\n",
       "         0.23877402,  0.27701908, -0.02028478],\n",
       "       [-0.28349239,  1.89762306, -0.89023685,  0.36111453, -0.04939051,\n",
       "         1.42928362, -0.04162903, -0.28117257],\n",
       "       [-0.35769558,  1.21531439, -1.20074153, -1.35509169,  0.09909067,\n",
       "         1.06533611,  0.71215773,  1.27959204],\n",
       "       [ 0.40157151, -0.54389036,  1.07706428, -0.5330258 ,  0.06305721,\n",
       "         0.62319988,  0.99265051,  1.48126411]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = context_encoding\n",
    "rt = utterance_encoding\n",
    "\n",
    "M = tf.Variable(tf.truncated_normal(shape=(hidden_size, hidden_size)))\n",
    "\n",
    "M.initializer.run()\n",
    "\n",
    "print(M)\n",
    "M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(?, 8), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.04271219e-05,   2.22710837e-02,  -3.00640408e-02,\n",
       "         -2.74273399e-02,  -3.46280821e-03,   4.22730409e-02,\n",
       "          2.17236895e-02,   2.30774693e-02],\n",
       "       [ -6.47506118e-02,   1.23922862e-01,  -7.01749846e-02,\n",
       "          4.47266251e-02,  -1.98715832e-02,   2.73962002e-02,\n",
       "         -5.91390543e-02,  -4.17987294e-02]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_M = tf.matmul(ct, M)\n",
    "\n",
    "print(ct_M)\n",
    "ct_M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims:0\", shape=(?, 8, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.02123714],\n",
       "        [ 0.10588894],\n",
       "        [-0.10926309],\n",
       "        [-0.02437902],\n",
       "        [ 0.04113741],\n",
       "        [ 0.01197255],\n",
       "        [-0.03193182],\n",
       "        [ 0.06311099]],\n",
       "\n",
       "       [[ 0.02261633],\n",
       "        [-0.02912687],\n",
       "        [-0.02649755],\n",
       "        [-0.05920239],\n",
       "        [ 0.03552807],\n",
       "        [ 0.00198112],\n",
       "        [ 0.03563669],\n",
       "        [ 0.11155382]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "\n",
    "print(batch_ct_M)\n",
    "batch_ct_M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims_1:0\", shape=(?, 8, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.05162073],\n",
       "        [ 0.0358412 ],\n",
       "        [ 0.04149287],\n",
       "        [-0.03796405],\n",
       "        [ 0.02101916],\n",
       "        [-0.00133579],\n",
       "        [ 0.00930932],\n",
       "        [-0.00747717]],\n",
       "\n",
       "       [[-0.00384405],\n",
       "        [ 0.00421883],\n",
       "        [ 0.00807627],\n",
       "        [-0.00077201],\n",
       "        [-0.03191332],\n",
       "        [ 0.02167791],\n",
       "        [ 0.03467385],\n",
       "        [-0.03085664]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_rt = tf.expand_dims(rt, axis=2)\n",
    "\n",
    "print(batch_rt)\n",
    "batch_rt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze:0\", shape=(?, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00065791],\n",
       "       [-0.00417699]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "print(ct_M_r)\n",
    "ct_M_r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_2:0' shape=() dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "b.initializer.run()\n",
    "\n",
    "print(b)\n",
    "b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.49933356],\n",
       "       [ 0.50007993]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = ct_M_r + b\n",
    "probs = tf.sigmoid(logits)\n",
    "\n",
    "print(probs)\n",
    "probs.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_3:0\", shape=(2, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targets:\n",
    "# For each pair (context, utterance)\n",
    "# 1 -> utterance is the correct sentence related to context\n",
    "# 0 -> utterance is a random sentence related to other context\n",
    "targets = tf.constant([1, 0], shape=(2, 1))\n",
    "\n",
    "print(targets)\n",
    "targets.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "Tensor(\"sigmoid_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69348526"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.to_float(targets), logits=logits)\n",
    "\n",
    "print(loss)\n",
    "loss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69289988"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_loss = tf.reduce_mean(loss)\n",
    "\n",
    "print(mean_loss)\n",
    "mean_loss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "Average loss: 3.698\n"
     ]
    }
   ],
   "source": [
    "def dual_encoder(vocab_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 input_context,\n",
    "                 input_context_len,\n",
    "                 input_utterance,\n",
    "                 input_utterance_len,\n",
    "                 targets):\n",
    "\n",
    "    with tf.variable_scope('embedding'):\n",
    "        embeddings = tf.get_variable(\n",
    "            'embeddings',\n",
    "            shape=(vocab_size, embed_size),\n",
    "            initializer=tf.random_uniform_initializer(-0.25, 0.25))\n",
    "\n",
    "        context_embed = tf.nn.embedding_lookup(\n",
    "            embeddings, input_context, name='context_embed')\n",
    "        utterance_embed = tf.nn.embedding_lookup(\n",
    "            embeddings, input_utterance, name='utterance_embed')\n",
    "\n",
    "        input_embed = tf.concat([context_embed, utterance_embed], axis=0)\n",
    "        input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "        input_length = tf.reshape(input_length, [-1])\n",
    "        \n",
    "    with tf.variable_scope('rnn'):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(\n",
    "            hidden_size,\n",
    "            forget_bias=2.0,\n",
    "            use_peepholes=True,\n",
    "            state_is_tuple=True)\n",
    "\n",
    "        outputs, states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            input_embed,\n",
    "            sequence_length=input_length,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        context_encoding, utterance_encoding = tf.split(\n",
    "            states.h, num_or_size_splits=2, axis=0)\n",
    "\n",
    "    with tf.variable_scope('prediction'):\n",
    "        ct = context_encoding\n",
    "        rt = utterance_encoding\n",
    "        M = tf.get_variable(\n",
    "            'M',\n",
    "            shape=(hidden_size, hidden_size),\n",
    "            initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        ct_M = tf.matmul(ct, M)\n",
    "        batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "        batch_rt = tf.expand_dims(rt, axis=2)\n",
    "        batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "        ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "        b = tf.get_variable(\n",
    "            'b', shape=(), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        logits = ct_M_r + b\n",
    "        \n",
    "        probs = tf.sigmoid(logits)\n",
    "\n",
    "    if targets is None:\n",
    "        return probs, None\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.to_float(targets), logits=logits)\n",
    "    loss = tf.reduce_mean(loss, name=\"loss\")\n",
    "    \n",
    "    return probs, loss\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.Session(graph=graph) as session:\n",
    "    vocab_size = 91619\n",
    "    embed_size = 100\n",
    "    hidden_size = 256\n",
    "\n",
    "    batch_size = 128\n",
    "    sentence_size = 220\n",
    "    input_context = tf.random_uniform(\n",
    "        shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "    input_context_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "    input_utterance = tf.random_uniform(\n",
    "        shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "    input_utterance_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "    targets = tf.random_uniform(\n",
    "        shape=(batch_size, 1), minval=0, maxval=1, dtype=tf.int64)    \n",
    "    \n",
    "    _, loss = dual_encoder(vocab_size,\n",
    "                           embed_size,\n",
    "                           hidden_size,\n",
    "                           input_context,\n",
    "                           input_context_len,\n",
    "                           input_utterance,\n",
    "                           input_utterance_len,\n",
    "                           targets)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)\n",
    "    \n",
    "    loss_value = session.run(loss)\n",
    "    \n",
    "    print('Average loss: {:,.3f}'.format(loss_value))\n",
    "\n",
    "del graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-cpu)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
