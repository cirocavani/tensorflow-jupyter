{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f3aa8ded550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings:\n",
      "\n",
      "Tensor(\"stack:0\", shape=(4, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 4\n",
    "embed_size = 2\n",
    "\n",
    "word_0 = [0, 0]\n",
    "word_1 = [1, 0]\n",
    "word_2 = [0, 1]\n",
    "word_3 = [1, 1]\n",
    "\n",
    "embeddings = tf.stack([word_0, word_1, word_2, word_3])\n",
    "\n",
    "print('Embeddings:\\n')\n",
    "print(embeddings)\n",
    "embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      "\n",
      "Tensor(\"stack_1:0\", shape=(2, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 2],\n",
       "       [3, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "sentence_length = 3\n",
    "\n",
    "sentence_0 = [0, 3, 2]\n",
    "sentence_1 = [3, 1, 0]\n",
    "\n",
    "input_data = tf.stack([sentence_0, sentence_1])\n",
    "\n",
    "print('Sentences:\\n')\n",
    "print(input_data)\n",
    "input_data.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "\n",
      "Tensor(\"embedding_lookup:0\", shape=(2, 3, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0]]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embed = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "\n",
    "print('Input:\\n')\n",
    "print(input_embed)\n",
    "input_embed.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pairing\n",
    "\n",
    "Similarity between **`c`** and **`c'`**, where **`c' = Mr`**.\n",
    "\n",
    "**`c`** -> encoded context vector\n",
    "\n",
    "**`r`** -> encoded response vector\n",
    "\n",
    "**`M`** -> translate responce to context, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f3aa8deda20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [3 4]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "M = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "print('M', M.shape, '\\n')\n",
    "print(M.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c (2, 1) \n",
      "\n",
      "[[1]\n",
      " [2]] \n",
      "\n",
      "r (2, 1) \n",
      "\n",
      "[[3]\n",
      " [4]] \n",
      "\n",
      "ct * M (1, 2) \n",
      "\n",
      "[[ 7 10]] \n",
      "\n",
      "ct * M * r (1, 1) \n",
      "\n",
      "[[61]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[1], [2]])\n",
    "r = tf.constant([[3], [4]])\n",
    "\n",
    "ct_M = tf.matmul(c, M, transpose_a=True)\n",
    "ct_M_r = tf.matmul(ct_M, r)\n",
    "\n",
    "print('c', c.shape, '\\n')\n",
    "print(c.eval(), '\\n')\n",
    "print('r', r.shape, '\\n')\n",
    "print(r.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [0 0]] \n",
      "\n",
      "rt (2, 2) \n",
      "\n",
      "[[3 4]\n",
      " [0 0]] \n",
      "\n",
      "ct * M (2, 2) \n",
      "\n",
      "[[ 7 10]\n",
      " [ 0  0]] \n",
      "\n",
      "ct * M * r (2, 2) \n",
      "\n",
      "[[61  0]\n",
      " [ 0  0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct = tf.constant([[1, 2], [0, 0]])\n",
    "rt = tf.constant([[3, 4], [0, 0]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "ct_M_r = tf.matmul(ct_M, rt, transpose_b=True)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c (2, 1) \n",
      "\n",
      "[[5]\n",
      " [6]] \n",
      "\n",
      "r (2, 1) \n",
      "\n",
      "[[7]\n",
      " [8]] \n",
      "\n",
      "ct * M (1, 2) \n",
      "\n",
      "[[23 34]] \n",
      "\n",
      "ct * M * r (1, 1) \n",
      "\n",
      "[[433]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[5], [6]])\n",
    "r = tf.constant([[7], [8]])\n",
    "\n",
    "ct_M = tf.matmul(c, M, transpose_a=True)\n",
    "ct_M_r = tf.matmul(ct_M, r)\n",
    "\n",
    "print('c', c.shape, '\\n')\n",
    "print(c.eval(), '\\n')\n",
    "print('r', r.shape, '\\n')\n",
    "print(r.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [5 6]] \n",
      "\n",
      "rt (2, 2) \n",
      "\n",
      "[[3 4]\n",
      " [7 8]] \n",
      "\n",
      "ct * M (2, 2) \n",
      "\n",
      "[[ 7 10]\n",
      " [23 34]] \n",
      "\n",
      "ct * M * r (2, 2) \n",
      "\n",
      "[[ 61 129]\n",
      " [205 433]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct = tf.constant([[1, 2], [5, 6]])\n",
    "rt = tf.constant([[3, 4], [7, 8]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "ct_M_r = tf.matmul(ct_M, rt, transpose_b=True)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [5 6]] \n",
      "\n",
      "rt (2, 2) \n",
      "\n",
      "[[3 4]\n",
      " [7 8]] \n",
      "\n",
      "ct * M (2, 2) \n",
      "\n",
      "[[ 7 10]\n",
      " [23 34]] \n",
      "\n",
      "ct * M (batch) (2, 2, 1) \n",
      "\n",
      "[[[ 7]\n",
      "  [10]]\n",
      "\n",
      " [[23]\n",
      "  [34]]] \n",
      "\n",
      "rt (batch) (2, 2, 1) \n",
      "\n",
      "[[[3]\n",
      "  [4]]\n",
      "\n",
      " [[7]\n",
      "  [8]]] \n",
      "\n",
      "ct * M * r (batch) (2, 1, 1) \n",
      "\n",
      "[[[ 61]]\n",
      "\n",
      " [[433]]] \n",
      "\n",
      "ct * M * r (2, 1) \n",
      "\n",
      "[[ 61]\n",
      " [433]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct = tf.constant([[1, 2], [5, 6]])\n",
    "rt = tf.constant([[3, 4], [7, 8]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "\n",
    "batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "batch_rt = tf.expand_dims(rt, axis=2)\n",
    "\n",
    "batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "\n",
    "ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M (batch)', batch_ct_M.shape, '\\n')\n",
    "print(batch_ct_M.eval(), '\\n')\n",
    "print('rt (batch)', batch_rt.shape, '\\n')\n",
    "print(batch_rt.eval(), '\\n')\n",
    "print('ct * M * r (batch)', batch_ct_M_r.shape, '\\n')\n",
    "print(batch_ct_M_r.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dual LSTM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f3aa8ded780>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 25\n",
    "sentence_size = 4\n",
    "batch_size = 2\n",
    "embed_size = 5\n",
    "hidden_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Sentence (Dataset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform:0\", shape=(2, 4), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6,  7,  3,  9],\n",
       "       [16,  3,  3, 21]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = tf.random_uniform(\n",
    "    shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "\n",
    "print(input_context)\n",
    "input_context.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_1:0\", shape=(2, 4), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12, 12, 17, 24],\n",
       "       [ 5,  1,  6,  3]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_utterance = tf.random_uniform(\n",
    "    shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "\n",
    "print(input_utterance)\n",
    "input_utterance.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(2, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "\n",
    "print(input_context_len)\n",
    "input_context_len.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(2, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_utterance_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "\n",
    "print(input_utterance_len)\n",
    "input_utterance_len.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual Encoder - Input**\n",
    "\n",
    "Encode Context and Utterance together.\n",
    "\n",
    "Concatenated tensors to encode both sentences in a single pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", shape=(4, 4), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3, 15, 22, 24],\n",
       "       [15, 19, 10, 24],\n",
       "       [18, 13, 22,  2],\n",
       "       [21, 12, 16, 23]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = tf.concat([input_context, input_utterance], axis=0)\n",
    "\n",
    "print(input_data)\n",
    "input_data.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_1:0\", shape=(4, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "\n",
    "print(input_length)\n",
    "input_length.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length = tf.reshape(input_length, [-1])\n",
    "\n",
    "print(input_length)\n",
    "input_length.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(25, 5) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.21907032,  0.12420064,  0.08173907, -0.02944922,  0.13916892],\n",
       "       [-0.19457632, -0.04192621, -0.01358092, -0.09134567, -0.03374678],\n",
       "       [-0.20141655, -0.04927802,  0.04475701,  0.08313692, -0.24986994],\n",
       "       [-0.11313343, -0.15176058,  0.19104403, -0.22445405, -0.09094852],\n",
       "       [ 0.18365574,  0.04884416,  0.2263785 , -0.20114535,  0.06503594],\n",
       "       [-0.06325829,  0.13168997, -0.04494703, -0.24026519, -0.08608866],\n",
       "       [-0.22691852,  0.05871272, -0.05562907,  0.14495915,  0.19582754],\n",
       "       [-0.11647069, -0.02338237,  0.23145068, -0.13811696,  0.12614876],\n",
       "       [ 0.16999269, -0.19063103,  0.1020385 , -0.00697273,  0.20171386],\n",
       "       [-0.16343969, -0.04493779,  0.08613151, -0.19786072,  0.18145597],\n",
       "       [-0.21040785, -0.13465285,  0.16652071, -0.01110697, -0.23971975],\n",
       "       [ 0.00184298, -0.03021336,  0.05623734, -0.10353458,  0.2476756 ],\n",
       "       [-0.00172263,  0.09363931,  0.10709786, -0.08221245, -0.19734287],\n",
       "       [-0.13532072,  0.18851179,  0.23771602,  0.03604376, -0.01679903],\n",
       "       [-0.16841835, -0.13842201,  0.02659667,  0.07141083, -0.19023174],\n",
       "       [-0.17450178, -0.11135095,  0.18272793,  0.15989608,  0.24597967],\n",
       "       [-0.06821299, -0.18856519, -0.08151788,  0.02913076,  0.09885466],\n",
       "       [ 0.10896826, -0.10157019, -0.21753126, -0.17071927, -0.03440285],\n",
       "       [ 0.18335986,  0.06729227, -0.00719678,  0.22223705,  0.01118076],\n",
       "       [ 0.09113204, -0.07571423,  0.24813646,  0.13842708,  0.1614812 ],\n",
       "       [-0.22301817,  0.10484457, -0.19522208,  0.12108177,  0.03933501],\n",
       "       [ 0.11710513,  0.02811396, -0.13201642, -0.10535878,  0.09543604],\n",
       "       [ 0.23115325, -0.07712948, -0.22003978,  0.17074454,  0.03851539],\n",
       "       [-0.11082011, -0.06353736,  0.00127381,  0.15368789,  0.07994926],\n",
       "       [-0.08633822,  0.1351071 , -0.10854161, -0.02885807, -0.21106774]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = tf.Variable(\n",
    "    tf.random_uniform(shape=(vocab_size, embed_size), minval=-0.25, maxval=0.25))\n",
    "\n",
    "embeddings.initializer.run()\n",
    "\n",
    "print(embeddings)\n",
    "embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(4, 4, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.09113204, -0.07571423,  0.24813646,  0.13842708,  0.1614812 ],\n",
       "        [-0.19457632, -0.04192621, -0.01358092, -0.09134567, -0.03374678],\n",
       "        [ 0.11710513,  0.02811396, -0.13201642, -0.10535878,  0.09543604],\n",
       "        [-0.17450178, -0.11135095,  0.18272793,  0.15989608,  0.24597967]],\n",
       "\n",
       "       [[-0.11313343, -0.15176058,  0.19104403, -0.22445405, -0.09094852],\n",
       "        [-0.21907032,  0.12420064,  0.08173907, -0.02944922,  0.13916892],\n",
       "        [-0.16841835, -0.13842201,  0.02659667,  0.07141083, -0.19023174],\n",
       "        [-0.16841835, -0.13842201,  0.02659667,  0.07141083, -0.19023174]],\n",
       "\n",
       "       [[ 0.18335986,  0.06729227, -0.00719678,  0.22223705,  0.01118076],\n",
       "        [-0.13532072,  0.18851179,  0.23771602,  0.03604376, -0.01679903],\n",
       "        [-0.22691852,  0.05871272, -0.05562907,  0.14495915,  0.19582754],\n",
       "        [ 0.16999269, -0.19063103,  0.1020385 , -0.00697273,  0.20171386]],\n",
       "\n",
       "       [[ 0.23115325, -0.07712948, -0.22003978,  0.17074454,  0.03851539],\n",
       "        [-0.20141655, -0.04927802,  0.04475701,  0.08313692, -0.24986994],\n",
       "        [-0.21040785, -0.13465285,  0.16652071, -0.01110697, -0.23971975],\n",
       "        [-0.17450178, -0.11135095,  0.18272793,  0.15989608,  0.24597967]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embed = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "\n",
    "print(input_embed)\n",
    "input_embed.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Encoder**\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/rnn/LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      "\n",
      "Tensor(\"rnn/transpose:0\", shape=(4, 4, 8), dtype=float32)\n",
      "\n",
      "Final states:\n",
      "\n",
      "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 8) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 8) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "cell = tf.nn.rnn_cell.LSTMCell(\n",
    "    hidden_size,\n",
    "    forget_bias=2.0,\n",
    "    use_peepholes=True,\n",
    "    state_is_tuple=True)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(\n",
    "    cell,\n",
    "    input_embed,\n",
    "    sequence_length=input_length,\n",
    "    dtype=tf.float32)\n",
    "\n",
    "for tv in cell.trainable_variables:\n",
    "    tv.initializer.run()\n",
    "\n",
    "print('Outputs:\\n')\n",
    "print(outputs)\n",
    "print()\n",
    "print('Final states:\\n')\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual Encoder - Output**\n",
    "\n",
    "Split the encoded vector of each sentece type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_encoding, utterance_encoding = tf.split(states.h, num_or_size_splits=2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"split:0\", shape=(?, 8), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00200458, -0.07782954, -0.03901846, -0.02058421, -0.01113973,\n",
       "         0.00311457,  0.01272435, -0.00159189],\n",
       "       [ 0.00298107, -0.02075206, -0.01452476, -0.0094074 , -0.03382337,\n",
       "        -0.00774932, -0.02527196, -0.01318577]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(context_encoding)\n",
    "context_encoding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"split:1\", shape=(?, 8), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.03146975, -0.0214084 ,  0.0434907 , -0.0105907 ,  0.04393053,\n",
       "         0.01149318,  0.07102276,  0.03361205],\n",
       "       [ 0.02853673, -0.06037546,  0.0323844 , -0.02367128, -0.01450527,\n",
       "        -0.04186971,  0.02878205, -0.0065584 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(utterance_encoding)\n",
    "utterance_encoding.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_1:0' shape=(8, 8) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.12962437,  1.14114833,  0.06564874,  0.56438684, -1.34626341,\n",
       "         1.28605855,  0.11107973, -0.79747385],\n",
       "       [-0.11315158, -0.35980058,  1.18024707,  1.81900978,  0.05341239,\n",
       "         0.92986083, -0.2714211 ,  0.81756943],\n",
       "       [ 0.60764712, -0.70737588,  0.77942061,  0.29839471,  0.54188615,\n",
       "        -1.31166804, -0.41452876, -1.36700535],\n",
       "       [ 0.76668429, -1.86763895, -0.29187876,  0.04876193, -1.27575839,\n",
       "         0.96734595,  0.81053513,  0.03170199],\n",
       "       [-0.00268976, -0.68755138, -0.1671298 ,  0.99898678, -0.49784848,\n",
       "         1.28975391, -0.90316176,  0.50242645],\n",
       "       [-0.59916943, -0.38789433,  0.85632062,  0.69197869,  0.25876817,\n",
       "         0.60806382,  0.61659104,  1.40782416],\n",
       "       [ 0.40941748, -0.31378675,  0.69913375, -1.82325435, -0.30749947,\n",
       "        -0.30945924, -0.10638782,  0.1487257 ],\n",
       "       [ 1.26011765, -0.1710791 , -0.56199098, -0.06139187,  0.37000132,\n",
       "         0.74245983,  1.51508677, -1.33844411]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = context_encoding\n",
    "rt = utterance_encoding\n",
    "\n",
    "M = tf.Variable(tf.truncated_normal(shape=(hidden_size, hidden_size)))\n",
    "\n",
    "M.initializer.run()\n",
    "\n",
    "print(M)\n",
    "M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(?, 8), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.11149243, -0.07628223,  0.02294171, -0.03739275, -0.11500248,\n",
       "         0.10149613,  0.02004033, -0.10178125],\n",
       "       [ 0.02060858, -0.01722639,  0.11686569,  0.08371522,  0.06707289,\n",
       "         0.01298102, -0.05079825,  0.00637592]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_M = tf.matmul(ct, M)\n",
    "\n",
    "print(ct_M)\n",
    "ct_M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims:0\", shape=(?, 8, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.05122604],\n",
       "        [-0.02991961],\n",
       "        [-0.03042503],\n",
       "        [-0.09613165],\n",
       "        [-0.08290789],\n",
       "        [ 0.02937662],\n",
       "        [ 0.00145915],\n",
       "        [-0.05831744]],\n",
       "\n",
       "       [[ 0.03272467],\n",
       "        [ 0.03863359],\n",
       "        [ 0.08826862],\n",
       "        [-0.10304278],\n",
       "        [ 0.12715741],\n",
       "        [-0.04919792],\n",
       "        [-0.03106936],\n",
       "        [-0.01913336]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "\n",
    "print(batch_ct_M)\n",
    "batch_ct_M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims_1:0\", shape=(?, 8, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.02745816],\n",
       "        [-0.0448821 ],\n",
       "        [-0.00924154],\n",
       "        [-0.07239423],\n",
       "        [-0.02991658],\n",
       "        [ 0.00671526],\n",
       "        [ 0.01641566],\n",
       "        [ 0.00155555]],\n",
       "\n",
       "       [[-0.00696998],\n",
       "        [ 0.02177757],\n",
       "        [-0.00371406],\n",
       "        [-0.01129351],\n",
       "        [ 0.00814003],\n",
       "        [ 0.05789442],\n",
       "        [ 0.00783155],\n",
       "        [ 0.02890128]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_rt = tf.expand_dims(rt, axis=2)\n",
    "\n",
    "print(batch_rt)\n",
    "batch_rt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze:0\", shape=(?, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00300801],\n",
       "       [ 0.00315467]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "print(ct_M_r)\n",
    "ct_M_r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_2:0' shape=() dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "b.initializer.run()\n",
    "\n",
    "print(b)\n",
    "b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.50056845],\n",
       "       [ 0.50094402]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = ct_M_r + b\n",
    "probs = tf.sigmoid(logits)\n",
    "\n",
    "print(probs)\n",
    "probs.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/losses/sigmoid_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_3:0\", shape=(2, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targets:\n",
    "# For each pair (context, utterance)\n",
    "# 1 -> utterance is the correct sentence related to context\n",
    "# 0 -> utterance is a random sentence related to other context\n",
    "targets = tf.constant([1, 0], shape=(2, 1))\n",
    "\n",
    "print(targets)\n",
    "targets.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "Tensor(\"sigmoid_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69300103"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.losses.sigmoid_cross_entropy(\n",
    "    multi_class_labels=targets, logits=logits, reduction=tf.losses.Reduction.MEAN)\n",
    "\n",
    "print(loss)\n",
    "loss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "Average loss: 4.939\n"
     ]
    }
   ],
   "source": [
    "def dual_encoder(vocab_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 input_context,\n",
    "                 input_context_len,\n",
    "                 input_utterance,\n",
    "                 input_utterance_len,\n",
    "                 targets):\n",
    "\n",
    "    input_data = tf.concat([input_context, input_utterance], axis=0)\n",
    "    input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "    input_length = tf.reshape(input_length, [-1])\n",
    "    \n",
    "    embeddings = tf.get_variable(\n",
    "        'embeddings',\n",
    "        shape=(vocab_size, embed_size),\n",
    "        initializer=tf.random_uniform_initializer(-0.25, 0.25))\n",
    "\n",
    "    input_embed = tf.nn.embedding_lookup(\n",
    "        embeddings, input_data, name='input_embed')\n",
    "        \n",
    "    with tf.variable_scope('rnn'):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(\n",
    "            hidden_size,\n",
    "            forget_bias=2.0,\n",
    "            use_peepholes=True,\n",
    "            state_is_tuple=True)\n",
    "\n",
    "        outputs, states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            input_embed,\n",
    "            sequence_length=input_length,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        context_encoding, utterance_encoding = tf.split(\n",
    "            states.h, num_or_size_splits=2, axis=0)\n",
    "\n",
    "    with tf.variable_scope('prediction'):\n",
    "        ct = context_encoding\n",
    "        rt = utterance_encoding\n",
    "        M = tf.get_variable(\n",
    "            'M',\n",
    "            shape=(hidden_size, hidden_size),\n",
    "            initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        ct_M = tf.matmul(ct, M)\n",
    "        batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "        batch_rt = tf.expand_dims(rt, axis=2)\n",
    "        batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "        ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "        b = tf.get_variable(\n",
    "            'b', shape=(), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        logits = ct_M_r + b\n",
    "        \n",
    "        probs = tf.sigmoid(logits)\n",
    "\n",
    "    if targets is None:\n",
    "        return probs, None\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(\n",
    "        multi_class_labels=targets, logits=logits, reduction=tf.losses.Reduction.MEAN)\n",
    "    \n",
    "    return probs, loss\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.Session(graph=graph) as session:\n",
    "    vocab_size = 100000\n",
    "    embed_size = 100\n",
    "    hidden_size = 200\n",
    "\n",
    "    batch_size = 128\n",
    "    sentence_size = 160\n",
    "    input_context = tf.random_uniform(\n",
    "        shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "    input_context_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "    input_utterance = tf.random_uniform(\n",
    "        shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "    input_utterance_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "    targets = tf.random_uniform(\n",
    "        shape=(batch_size, 1), minval=0, maxval=1, dtype=tf.int64)    \n",
    "    \n",
    "    _, loss = dual_encoder(vocab_size,\n",
    "                           embed_size,\n",
    "                           hidden_size,\n",
    "                           input_context,\n",
    "                           input_context_len,\n",
    "                           input_utterance,\n",
    "                           input_utterance_len,\n",
    "                           targets)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)\n",
    "    \n",
    "    loss_value = session.run(loss)\n",
    "    \n",
    "    print('Average loss: {:,.3f}'.format(loss_value))\n",
    "\n",
    "del graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-cpu)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
