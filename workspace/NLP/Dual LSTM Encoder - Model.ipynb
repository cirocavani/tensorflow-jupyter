{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 4\n",
    "embed_size = 2\n",
    "\n",
    "word_0 = [0, 0]\n",
    "word_1 = [1, 0]\n",
    "word_2 = [0, 1]\n",
    "word_3 = [1, 1]\n",
    "\n",
    "embeddings = tf.stack([word_0, word_1, word_2, word_3])\n",
    "\n",
    "print('Embeddings:\\n')\n",
    "print(embeddings)\n",
    "embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "sentence_length = 3\n",
    "\n",
    "sentence_0 = [0, 3, 2]\n",
    "sentence_1 = [3, 1, 0]\n",
    "\n",
    "input_data = tf.stack([sentence_0, sentence_1])\n",
    "\n",
    "print('Sentences:\\n')\n",
    "print(input_data)\n",
    "input_data.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embed = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "\n",
    "print('Input:\\n')\n",
    "print(input_embed)\n",
    "input_embed.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pairing\n",
    "\n",
    "Similarity between **`c`** and **`c'`**, where **`c' = Mr`**.\n",
    "\n",
    "**`c`** -> encoded context vector\n",
    "\n",
    "**`r`** -> encoded response vector\n",
    "\n",
    "**`M`** -> translate responce to context, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "print('M', M.shape, '\\n')\n",
    "print(M.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1], [2]])\n",
    "r = tf.constant([[3], [4]])\n",
    "\n",
    "ct_M = tf.matmul(c, M, transpose_a=True)\n",
    "ct_M_r = tf.matmul(ct_M, r)\n",
    "\n",
    "print('c', c.shape, '\\n')\n",
    "print(c.eval(), '\\n')\n",
    "print('r', r.shape, '\\n')\n",
    "print(r.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = tf.constant([[1, 2], [0, 0]])\n",
    "rt = tf.constant([[3, 4], [0, 0]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "ct_M_r = tf.matmul(ct_M, rt, transpose_b=True)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[5], [6]])\n",
    "r = tf.constant([[7], [8]])\n",
    "\n",
    "ct_M = tf.matmul(c, M, transpose_a=True)\n",
    "ct_M_r = tf.matmul(ct_M, r)\n",
    "\n",
    "print('c', c.shape, '\\n')\n",
    "print(c.eval(), '\\n')\n",
    "print('r', r.shape, '\\n')\n",
    "print(r.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = tf.constant([[1, 2], [5, 6]])\n",
    "rt = tf.constant([[3, 4], [7, 8]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "ct_M_r = tf.matmul(ct_M, rt, transpose_b=True)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = tf.constant([[1, 2], [5, 6]])\n",
    "rt = tf.constant([[3, 4], [7, 8]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "\n",
    "batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "batch_rt = tf.expand_dims(rt, axis=2)\n",
    "\n",
    "batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "\n",
    "ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M (batch)', batch_ct_M.shape, '\\n')\n",
    "print(batch_ct_M.eval(), '\\n')\n",
    "print('rt (batch)', batch_rt.shape, '\\n')\n",
    "print(batch_rt.eval(), '\\n')\n",
    "print('ct * M * r (batch)', batch_ct_M_r.shape, '\\n')\n",
    "print(batch_ct_M_r.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dual LSTM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 25\n",
    "sentence_size = 4\n",
    "batch_size = 2\n",
    "embed_size = 5\n",
    "hidden_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Sentence (Dataset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_context = tf.random_uniform(\n",
    "    shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "\n",
    "print(input_context)\n",
    "input_context.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_utterance = tf.random_uniform(\n",
    "    shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "\n",
    "print(input_utterance)\n",
    "input_utterance.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_context_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "\n",
    "print(input_context_len)\n",
    "input_context_len.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_utterance_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "\n",
    "print(input_utterance_len)\n",
    "input_utterance_len.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual Encoder - Input**\n",
    "\n",
    "Encode Context and Utterance together.\n",
    "\n",
    "Concatenated tensors to encode both sentences in a single pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.concat([input_context, input_utterance], axis=0)\n",
    "\n",
    "print(input_data)\n",
    "input_data.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "\n",
    "print(input_length)\n",
    "input_length.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = tf.reshape(input_length, [-1])\n",
    "\n",
    "print(input_length)\n",
    "input_length.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(\n",
    "    tf.random_uniform(shape=(vocab_size, embed_size), minval=-0.25, maxval=0.25))\n",
    "\n",
    "embeddings.initializer.run()\n",
    "\n",
    "print(embeddings)\n",
    "embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embed = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "\n",
    "print(input_embed)\n",
    "input_embed.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Encoder**\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/rnn/LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.LSTMCell(\n",
    "    hidden_size,\n",
    "    forget_bias=2.0,\n",
    "    use_peepholes=True,\n",
    "    state_is_tuple=True)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(\n",
    "    cell,\n",
    "    input_embed,\n",
    "    sequence_length=input_length,\n",
    "    dtype=tf.float32)\n",
    "\n",
    "for tv in cell.trainable_variables:\n",
    "    tv.initializer.run()\n",
    "\n",
    "print('Outputs:\\n')\n",
    "print(outputs)\n",
    "print()\n",
    "print('Final states:\\n')\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual Encoder - Output**\n",
    "\n",
    "Split the encoded vector of each sentece type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_encoding, utterance_encoding = tf.split(states.h, num_or_size_splits=2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context_encoding)\n",
    "context_encoding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utterance_encoding)\n",
    "utterance_encoding.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = context_encoding\n",
    "rt = utterance_encoding\n",
    "\n",
    "M = tf.Variable(tf.truncated_normal(shape=(hidden_size, hidden_size)))\n",
    "\n",
    "M.initializer.run()\n",
    "\n",
    "print(M)\n",
    "M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_M = tf.matmul(ct, M)\n",
    "\n",
    "print(ct_M)\n",
    "ct_M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "\n",
    "print(batch_ct_M)\n",
    "batch_ct_M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_rt = tf.expand_dims(rt, axis=2)\n",
    "\n",
    "print(batch_rt)\n",
    "batch_rt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "print(ct_M_r)\n",
    "ct_M_r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "b.initializer.run()\n",
    "\n",
    "print(b)\n",
    "b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = ct_M_r + b\n",
    "probs = tf.sigmoid(logits)\n",
    "\n",
    "print(probs)\n",
    "probs.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/losses/sigmoid_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets:\n",
    "# For each pair (context, utterance)\n",
    "# 1 -> utterance is the correct sentence related to context\n",
    "# 0 -> utterance is a random sentence related to other context\n",
    "targets = tf.constant([1, 0], shape=(2, 1))\n",
    "\n",
    "print(targets)\n",
    "targets.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.sigmoid_cross_entropy(\n",
    "    multi_class_labels=targets, logits=logits, reduction=tf.losses.Reduction.MEAN)\n",
    "\n",
    "print(loss)\n",
    "loss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_encoder(vocab_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 input_context,\n",
    "                 input_context_len,\n",
    "                 input_utterance,\n",
    "                 input_utterance_len,\n",
    "                 targets):\n",
    "\n",
    "    input_data = tf.concat([input_context, input_utterance], axis=0)\n",
    "    input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "    input_length = tf.reshape(input_length, [-1])\n",
    "    \n",
    "    embeddings = tf.get_variable(\n",
    "        'embeddings',\n",
    "        shape=(vocab_size, embed_size),\n",
    "        initializer=tf.random_uniform_initializer(-0.25, 0.25))\n",
    "\n",
    "    input_embed = tf.nn.embedding_lookup(\n",
    "        embeddings, input_data, name='input_embed')\n",
    "        \n",
    "    with tf.variable_scope('rnn'):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(\n",
    "            hidden_size,\n",
    "            forget_bias=2.0,\n",
    "            use_peepholes=True,\n",
    "            state_is_tuple=True)\n",
    "\n",
    "        outputs, states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            input_embed,\n",
    "            sequence_length=input_length,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        context_encoding, utterance_encoding = tf.split(\n",
    "            states.h, num_or_size_splits=2, axis=0)\n",
    "\n",
    "    with tf.variable_scope('prediction'):\n",
    "        ct = context_encoding\n",
    "        rt = utterance_encoding\n",
    "        M = tf.get_variable(\n",
    "            'M',\n",
    "            shape=(hidden_size, hidden_size),\n",
    "            initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        ct_M = tf.matmul(ct, M)\n",
    "        batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "        batch_rt = tf.expand_dims(rt, axis=2)\n",
    "        batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "        ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "        b = tf.get_variable(\n",
    "            'b', shape=(), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        logits = ct_M_r + b\n",
    "        \n",
    "        probs = tf.sigmoid(logits)\n",
    "\n",
    "    if targets is None:\n",
    "        return probs, None\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(\n",
    "        multi_class_labels=targets, logits=logits, reduction=tf.losses.Reduction.MEAN)\n",
    "    \n",
    "    return probs, loss\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.Session(graph=graph) as session:\n",
    "    vocab_size = 100000\n",
    "    embed_size = 100\n",
    "    hidden_size = 200\n",
    "\n",
    "    batch_size = 128\n",
    "    sentence_size = 160\n",
    "    input_context = tf.random_uniform(\n",
    "        shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "    input_context_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "    input_utterance = tf.random_uniform(\n",
    "        shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "    input_utterance_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "    targets = tf.random_uniform(\n",
    "        shape=(batch_size, 1), minval=0, maxval=1, dtype=tf.int64)    \n",
    "    \n",
    "    _, loss = dual_encoder(vocab_size,\n",
    "                           embed_size,\n",
    "                           hidden_size,\n",
    "                           input_context,\n",
    "                           input_context_len,\n",
    "                           input_utterance,\n",
    "                           input_utterance_len,\n",
    "                           targets)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)\n",
    "    \n",
    "    loss_value = session.run(loss)\n",
    "    \n",
    "    print('Average loss: {:,.3f}'.format(loss_value))\n",
    "\n",
    "del graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-cpu)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
