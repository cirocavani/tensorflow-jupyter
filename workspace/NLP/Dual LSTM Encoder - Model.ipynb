{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f1d239ec588>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings:\n",
      "\n",
      "Tensor(\"stack:0\", shape=(4, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 4\n",
    "embed_size = 2\n",
    "\n",
    "word_0 = [0, 0]\n",
    "word_1 = [1, 0]\n",
    "word_2 = [0, 1]\n",
    "word_3 = [1, 1]\n",
    "\n",
    "embeddings = tf.stack([word_0, word_1, word_2, word_3])\n",
    "\n",
    "print('Embeddings:\\n')\n",
    "print(embeddings)\n",
    "embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      "\n",
      "Tensor(\"stack_1:0\", shape=(2, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 2],\n",
       "       [3, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "sentence_length = 3\n",
    "\n",
    "sentence_0 = [0, 3, 2]\n",
    "sentence_1 = [3, 1, 0]\n",
    "\n",
    "input_data = tf.stack([sentence_0, sentence_1])\n",
    "\n",
    "print('Sentences:\\n')\n",
    "print(input_data)\n",
    "input_data.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "\n",
      "Tensor(\"embedding_lookup:0\", shape=(2, 3, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0]]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embed = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "\n",
    "print('Input:\\n')\n",
    "print(input_embed)\n",
    "input_embed.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pairing\n",
    "\n",
    "Similarity between **`c`** and **`c'`**, where **`c' = Mr`**.\n",
    "\n",
    "**`c`** -> encoded context vector\n",
    "\n",
    "**`r`** -> encoded response vector\n",
    "\n",
    "**`M`** -> translate responce to context, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f1d239dffd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [3 4]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "M = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "print('M', M.shape, '\\n')\n",
    "print(M.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c (2, 1) \n",
      "\n",
      "[[1]\n",
      " [2]] \n",
      "\n",
      "r (2, 1) \n",
      "\n",
      "[[3]\n",
      " [4]] \n",
      "\n",
      "ct * M (1, 2) \n",
      "\n",
      "[[ 7 10]] \n",
      "\n",
      "ct * M * r (1, 1) \n",
      "\n",
      "[[61]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[1], [2]])\n",
    "r = tf.constant([[3], [4]])\n",
    "\n",
    "ct_M = tf.matmul(c, M, transpose_a=True)\n",
    "ct_M_r = tf.matmul(ct_M, r)\n",
    "\n",
    "print('c', c.shape, '\\n')\n",
    "print(c.eval(), '\\n')\n",
    "print('r', r.shape, '\\n')\n",
    "print(r.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [0 0]] \n",
      "\n",
      "rt (2, 2) \n",
      "\n",
      "[[3 4]\n",
      " [0 0]] \n",
      "\n",
      "ct * M (2, 2) \n",
      "\n",
      "[[ 7 10]\n",
      " [ 0  0]] \n",
      "\n",
      "ct * M * r (2, 2) \n",
      "\n",
      "[[61  0]\n",
      " [ 0  0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct = tf.constant([[1, 2], [0, 0]])\n",
    "rt = tf.constant([[3, 4], [0, 0]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "ct_M_r = tf.matmul(ct_M, rt, transpose_b=True)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c (2, 1) \n",
      "\n",
      "[[5]\n",
      " [6]] \n",
      "\n",
      "r (2, 1) \n",
      "\n",
      "[[7]\n",
      " [8]] \n",
      "\n",
      "ct * M (1, 2) \n",
      "\n",
      "[[23 34]] \n",
      "\n",
      "ct * M * r (1, 1) \n",
      "\n",
      "[[433]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[5], [6]])\n",
    "r = tf.constant([[7], [8]])\n",
    "\n",
    "ct_M = tf.matmul(c, M, transpose_a=True)\n",
    "ct_M_r = tf.matmul(ct_M, r)\n",
    "\n",
    "print('c', c.shape, '\\n')\n",
    "print(c.eval(), '\\n')\n",
    "print('r', r.shape, '\\n')\n",
    "print(r.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [5 6]] \n",
      "\n",
      "rt (2, 2) \n",
      "\n",
      "[[3 4]\n",
      " [7 8]] \n",
      "\n",
      "ct * M (2, 2) \n",
      "\n",
      "[[ 7 10]\n",
      " [23 34]] \n",
      "\n",
      "ct * M * r (2, 2) \n",
      "\n",
      "[[ 61 129]\n",
      " [205 433]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct = tf.constant([[1, 2], [5, 6]])\n",
    "rt = tf.constant([[3, 4], [7, 8]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "ct_M_r = tf.matmul(ct_M, rt, transpose_b=True)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct (2, 2) \n",
      "\n",
      "[[1 2]\n",
      " [5 6]] \n",
      "\n",
      "rt (2, 2) \n",
      "\n",
      "[[3 4]\n",
      " [7 8]] \n",
      "\n",
      "ct * M (2, 2) \n",
      "\n",
      "[[ 7 10]\n",
      " [23 34]] \n",
      "\n",
      "ct * M (batch) (2, 2, 1) \n",
      "\n",
      "[[[ 7]\n",
      "  [10]]\n",
      "\n",
      " [[23]\n",
      "  [34]]] \n",
      "\n",
      "rt (batch) (2, 2, 1) \n",
      "\n",
      "[[[3]\n",
      "  [4]]\n",
      "\n",
      " [[7]\n",
      "  [8]]] \n",
      "\n",
      "ct * M * r (batch) (2, 1, 1) \n",
      "\n",
      "[[[ 61]]\n",
      "\n",
      " [[433]]] \n",
      "\n",
      "ct * M * r (2, 1) \n",
      "\n",
      "[[ 61]\n",
      " [433]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct = tf.constant([[1, 2], [5, 6]])\n",
    "rt = tf.constant([[3, 4], [7, 8]])\n",
    "\n",
    "ct_M = tf.matmul(ct, M)\n",
    "\n",
    "batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "batch_rt = tf.expand_dims(rt, axis=2)\n",
    "\n",
    "batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "\n",
    "ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "print('ct', ct.shape, '\\n')\n",
    "print(ct.eval(), '\\n')\n",
    "print('rt', rt.shape, '\\n')\n",
    "print(rt.eval(), '\\n')\n",
    "print('ct * M', ct_M.shape, '\\n')\n",
    "print(ct_M.eval(), '\\n')\n",
    "print('ct * M (batch)', batch_ct_M.shape, '\\n')\n",
    "print(batch_ct_M.eval(), '\\n')\n",
    "print('rt (batch)', batch_rt.shape, '\\n')\n",
    "print(batch_rt.eval(), '\\n')\n",
    "print('ct * M * r (batch)', batch_ct_M_r.shape, '\\n')\n",
    "print(batch_ct_M_r.eval(), '\\n')\n",
    "print('ct * M * r', ct_M_r.shape, '\\n')\n",
    "print(ct_M_r.eval(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dual LSTM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f1d239ec940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 25\n",
    "sentence_size = 4\n",
    "batch_size = 2\n",
    "embed_size = 5\n",
    "hidden_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Sentence (Dataset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform:0\", shape=(2, 4), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22,  5, 23, 10],\n",
       "       [ 9, 20,  2, 19]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = tf.random_uniform(\n",
    "    shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "\n",
    "print(input_context)\n",
    "input_context.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_1:0\", shape=(2, 4), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11,  6,  5,  5],\n",
       "       [22, 20, 10, 15]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_utterance = tf.random_uniform(\n",
    "    shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "\n",
    "print(input_utterance)\n",
    "input_utterance.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(2, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "\n",
    "print(input_context_len)\n",
    "input_context_len.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(2, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_utterance_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "\n",
    "print(input_utterance_len)\n",
    "input_utterance_len.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual Encoder - Input**\n",
    "\n",
    "Encode Context and Utterance together.\n",
    "\n",
    "Concatenated tensors to encode both sentences in a single pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", shape=(4, 4), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22, 22, 20, 16],\n",
       "       [ 8, 12, 10, 11],\n",
       "       [ 4,  5, 17,  4],\n",
       "       [17,  6, 22, 24]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = tf.concat([input_context, input_utterance], axis=0)\n",
    "\n",
    "print(input_data)\n",
    "input_data.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_1:0\", shape=(4, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "\n",
    "print(input_length)\n",
    "input_length.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length = tf.reshape(input_length, [-1])\n",
    "\n",
    "print(input_length)\n",
    "input_length.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(25, 5) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -2.04107165e-01,   2.37267435e-01,   1.14207685e-01,\n",
       "         -7.48070478e-02,   1.78534091e-01],\n",
       "       [  2.62767673e-02,   1.81471288e-01,   2.12492347e-02,\n",
       "         -1.81813300e-01,   2.45958567e-03],\n",
       "       [  7.27196336e-02,  -1.20882750e-01,  -4.03785706e-03,\n",
       "         -2.19977736e-01,   2.95515060e-02],\n",
       "       [  5.37881851e-02,   1.51563585e-01,   1.71785474e-01,\n",
       "          1.83263302e-01,   4.02801037e-02],\n",
       "       [ -1.40134633e-01,  -7.83115625e-03,   1.60895646e-01,\n",
       "          1.11507297e-01,  -1.14968061e-01],\n",
       "       [  2.09304869e-01,   2.15322495e-01,  -1.68165445e-01,\n",
       "          2.51206756e-02,  -2.48422027e-01],\n",
       "       [  8.58283043e-02,  -1.11105800e-01,  -9.47612524e-03,\n",
       "         -1.63683116e-01,  -1.11841798e-01],\n",
       "       [  2.13393331e-01,   1.17012084e-01,   2.13164806e-01,\n",
       "          1.92613840e-01,  -1.34313226e-01],\n",
       "       [ -2.18812704e-01,  -1.04888201e-01,  -1.05619729e-01,\n",
       "          2.40417659e-01,   2.00243890e-01],\n",
       "       [  1.14995301e-01,  -3.95178795e-05,  -1.51913106e-01,\n",
       "         -9.38912630e-02,   1.71306610e-01],\n",
       "       [ -2.13287592e-01,  -1.50183916e-01,  -1.41156614e-01,\n",
       "          1.37687266e-01,   1.38085842e-01],\n",
       "       [ -2.84796953e-03,  -1.33032858e-01,   1.50661767e-01,\n",
       "          5.56997657e-02,   8.06293488e-02],\n",
       "       [  1.86704695e-01,   9.07140970e-03,   1.20927274e-01,\n",
       "          5.98225594e-02,   1.81010306e-01],\n",
       "       [ -1.67743683e-01,  -9.57769156e-03,   9.28164721e-02,\n",
       "         -1.85515165e-01,  -5.33564091e-02],\n",
       "       [ -1.23757720e-01,  -1.80672586e-01,   3.23320031e-02,\n",
       "          1.12802505e-01,   5.77142835e-02],\n",
       "       [ -1.95683122e-01,   5.75734377e-02,   5.57121634e-02,\n",
       "         -4.19080257e-04,  -5.89640141e-02],\n",
       "       [ -8.40904713e-02,   1.97201133e-01,   2.40800500e-01,\n",
       "          3.64677906e-02,  -1.54588461e-01],\n",
       "       [ -4.76210117e-02,   2.00022161e-01,   1.13062680e-01,\n",
       "          3.11024785e-02,  -2.25781381e-01],\n",
       "       [  5.32045364e-02,  -1.51457489e-01,   8.47424269e-02,\n",
       "          1.03503585e-01,  -9.06147361e-02],\n",
       "       [  1.99438930e-02,   1.61127567e-01,   2.28444219e-01,\n",
       "         -6.52791858e-02,  -7.57640004e-02],\n",
       "       [  1.95124030e-01,  -2.37459362e-01,  -4.60554361e-02,\n",
       "          1.67412162e-02,   7.05325007e-02],\n",
       "       [ -1.97898567e-01,   5.60383201e-02,   2.00122058e-01,\n",
       "         -1.06466174e-01,   1.98333383e-01],\n",
       "       [ -4.74699140e-02,   2.31842339e-01,  -3.53485346e-03,\n",
       "          3.58898640e-02,  -1.06793642e-03],\n",
       "       [  2.38953590e-01,  -1.81596816e-01,  -1.93254769e-01,\n",
       "         -1.12140715e-01,   1.09892786e-01],\n",
       "       [  1.80348873e-01,   8.84351134e-02,   4.61493134e-02,\n",
       "          6.73720837e-02,   2.40657151e-01]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = tf.Variable(\n",
    "    tf.random_uniform(shape=(vocab_size, embed_size), minval=-0.25, maxval=0.25))\n",
    "\n",
    "embeddings.initializer.run()\n",
    "\n",
    "print(embeddings)\n",
    "embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(4, 4, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.19789857,  0.05603832,  0.20012206, -0.10646617,  0.19833338],\n",
       "        [ 0.07271963, -0.12088275, -0.00403786, -0.21997774,  0.02955151],\n",
       "        [ 0.21339333,  0.11701208,  0.21316481,  0.19261384, -0.13431323],\n",
       "        [ 0.05320454, -0.15145749,  0.08474243,  0.10350358, -0.09061474]],\n",
       "\n",
       "       [[-0.19568312,  0.05757344,  0.05571216, -0.00041908, -0.05896401],\n",
       "        [ 0.01994389,  0.16112757,  0.22844422, -0.06527919, -0.075764  ],\n",
       "        [-0.21328759, -0.15018392, -0.14115661,  0.13768727,  0.13808584],\n",
       "        [ 0.02627677,  0.18147129,  0.02124923, -0.1818133 ,  0.00245959]],\n",
       "\n",
       "       [[ 0.20930487,  0.21532249, -0.16816545,  0.02512068, -0.24842203],\n",
       "        [ 0.02627677,  0.18147129,  0.02124923, -0.1818133 ,  0.00245959],\n",
       "        [ 0.18034887,  0.08843511,  0.04614931,  0.06737208,  0.24065715],\n",
       "        [ 0.1867047 ,  0.00907141,  0.12092727,  0.05982256,  0.18101031]],\n",
       "\n",
       "       [[ 0.18034887,  0.08843511,  0.04614931,  0.06737208,  0.24065715],\n",
       "        [ 0.05378819,  0.15156358,  0.17178547,  0.1832633 ,  0.0402801 ],\n",
       "        [ 0.1867047 ,  0.00907141,  0.12092727,  0.05982256,  0.18101031],\n",
       "        [-0.12375772, -0.18067259,  0.032332  ,  0.11280251,  0.05771428]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embed = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "\n",
    "print(input_embed)\n",
    "input_embed.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Encoder**\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/rnn/LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      "\n",
      "Tensor(\"rnn/transpose:0\", shape=(4, 4, 8), dtype=float32)\n",
      "\n",
      "Final states:\n",
      "\n",
      "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 8) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 8) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "cell = tf.nn.rnn_cell.LSTMCell(\n",
    "    hidden_size,\n",
    "    forget_bias=2.0,\n",
    "    use_peepholes=True,\n",
    "    state_is_tuple=True)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(\n",
    "    cell,\n",
    "    input_embed,\n",
    "    sequence_length=input_length,\n",
    "    dtype=tf.float32)\n",
    "\n",
    "for tv in cell.trainable_variables:\n",
    "    tv.initializer.run()\n",
    "\n",
    "print('Outputs:\\n')\n",
    "print(outputs)\n",
    "print()\n",
    "print('Final states:\\n')\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual Encoder - Output**\n",
    "\n",
    "Split the encoded vector of each sentece type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_encoding, utterance_encoding = tf.split(states.h, num_or_size_splits=2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"split:0\", shape=(?, 8), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00434534,  0.0113768 ,  0.03847972, -0.03734675, -0.033556  ,\n",
       "        -0.04215824,  0.01554458, -0.02245954],\n",
       "       [ 0.00745609, -0.04339714,  0.06076946, -0.01559918,  0.00880726,\n",
       "        -0.06102269, -0.03033336, -0.02441947]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(context_encoding)\n",
    "context_encoding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"split:1\", shape=(?, 8), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.02006005,  0.03290617, -0.06813933, -0.00201645, -0.01616752,\n",
       "         0.09591205,  0.02442359,  0.04216364],\n",
       "       [-0.02327644,  0.0127591 , -0.03932941,  0.03534726,  0.00401921,\n",
       "         0.08309978,  0.01232029,  0.05077659]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(utterance_encoding)\n",
    "utterance_encoding.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_1:0' shape=(8, 8) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.36489382, -1.9051007 , -0.63643503,  0.20628606,  0.22457613,\n",
       "         1.23054576, -0.21263087,  0.62139791],\n",
       "       [ 0.842426  ,  0.35761181, -0.32304102, -0.61951959, -1.03329933,\n",
       "         0.52980793,  1.39493489, -0.12824728],\n",
       "       [ 0.01979361, -1.00124192,  1.26791668,  1.47156739, -0.56096286,\n",
       "        -1.37084091,  1.01594818,  1.03041232],\n",
       "       [-0.63078672,  0.72437549,  0.40278333,  0.06710047,  0.18424897,\n",
       "         1.89565718, -1.64592218,  0.66166532],\n",
       "       [ 0.39488083, -0.77108759,  0.35598478, -0.2579954 , -0.52177596,\n",
       "        -1.46128106, -0.55175263, -1.69498014],\n",
       "       [ 1.38248515,  0.4515157 ,  0.30242011, -0.21638362,  0.71063805,\n",
       "        -1.26243246,  1.30880558,  0.45916498],\n",
       "       [-0.81056315, -0.19090298,  1.02799225,  0.06439355, -0.12565689,\n",
       "        -0.28468347, -0.8998273 , -0.81133282],\n",
       "       [ 0.44970828,  0.81073517,  1.17651534, -0.4153094 ,  1.50258088,\n",
       "        -0.14034843, -1.84965444,  0.27871731]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = context_encoding\n",
    "rt = utterance_encoding\n",
    "\n",
    "M = tf.Variable(tf.truncated_normal(shape=(hidden_size, hidden_size)))\n",
    "\n",
    "M.initializer.run()\n",
    "\n",
    "print(M)\n",
    "M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(?, 8), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -4.60841227e-03,   4.57319012e-03,   2.89663672e-02,\n",
       "          1.18324189e-02,   3.23643833e-02,  -5.56884392e-04,\n",
       "         -1.03770860e-01,  -1.39733500e-04],\n",
       "       [  1.18097939e-01,   2.78882056e-01,   4.33437414e-02,\n",
       "         -1.35466948e-01,   1.65135354e-01,  -1.15727605e-02,\n",
       "         -2.04559118e-01,  -4.57612015e-02]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_M = tf.matmul(ct, M)\n",
    "\n",
    "print(ct_M)\n",
    "ct_M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims:0\", shape=(?, 8, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.08164874],\n",
       "        [ 0.10342894],\n",
       "        [ 0.0842026 ],\n",
       "        [-0.01081535],\n",
       "        [ 0.11796083],\n",
       "        [-0.09975211],\n",
       "        [-0.10813951],\n",
       "        [ 0.01602971]],\n",
       "\n",
       "       [[-0.13119766],\n",
       "        [-0.22096619],\n",
       "        [ 0.00090272],\n",
       "        [ 0.15289454],\n",
       "        [-0.1193141 ],\n",
       "        [-0.00155331],\n",
       "        [ 0.0384606 ],\n",
       "        [ 0.03740075]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "\n",
    "print(batch_ct_M)\n",
    "batch_ct_M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims_1:0\", shape=(?, 8, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.01237914],\n",
       "        [-0.03904677],\n",
       "        [-0.00861677],\n",
       "        [ 0.01759103],\n",
       "        [ 0.03048603],\n",
       "        [ 0.00806168],\n",
       "        [-0.02958024],\n",
       "        [ 0.0015794 ]],\n",
       "\n",
       "       [[-0.02060232],\n",
       "        [-0.01270923],\n",
       "        [ 0.0181511 ],\n",
       "        [-0.00363906],\n",
       "        [ 0.00152899],\n",
       "        [-0.00344818],\n",
       "        [-0.02591585],\n",
       "        [ 0.01295206]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_rt = tf.expand_dims(rt, axis=2)\n",
    "\n",
    "print(batch_rt)\n",
    "batch_rt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze:0\", shape=(?, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00335007],\n",
       "       [ 0.01933217]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "print(ct_M_r)\n",
    "ct_M_r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_2:0' shape=() dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "b.initializer.run()\n",
    "\n",
    "print(b)\n",
    "b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.49999952],\n",
       "       [ 0.49983948]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = ct_M_r + b\n",
    "probs = tf.sigmoid(logits)\n",
    "\n",
    "print(probs)\n",
    "probs.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/losses/sigmoid_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_3:0\", shape=(2, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targets:\n",
    "# For each pair (context, utterance)\n",
    "# 1 -> utterance is the correct sentence related to context\n",
    "# 0 -> utterance is a random sentence related to other context\n",
    "targets = tf.constant([1, 0], shape=(2, 1))\n",
    "\n",
    "print(targets)\n",
    "targets.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "Tensor(\"sigmoid_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69175792"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.losses.sigmoid_cross_entropy(\n",
    "    multi_class_labels=targets, logits=logits, reduction=tf.losses.Reduction.MEAN)\n",
    "\n",
    "print(loss)\n",
    "loss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "del graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "Average loss: 3.503\n"
     ]
    }
   ],
   "source": [
    "def dual_encoder(vocab_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 input_context,\n",
    "                 input_context_len,\n",
    "                 input_utterance,\n",
    "                 input_utterance_len,\n",
    "                 targets):\n",
    "\n",
    "    input_data = tf.concat([input_context, input_utterance], axis=0)\n",
    "    input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "    input_length = tf.reshape(input_length, [-1])\n",
    "    \n",
    "    embeddings = tf.get_variable(\n",
    "        'embeddings',\n",
    "        shape=(vocab_size, embed_size),\n",
    "        initializer=tf.random_uniform_initializer(-0.25, 0.25))\n",
    "\n",
    "    input_embed = tf.nn.embedding_lookup(\n",
    "        embeddings, input_data, name='input_embed')\n",
    "        \n",
    "    with tf.variable_scope('rnn'):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(\n",
    "            hidden_size,\n",
    "            forget_bias=2.0,\n",
    "            use_peepholes=True,\n",
    "            state_is_tuple=True)\n",
    "\n",
    "        outputs, states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            input_embed,\n",
    "            sequence_length=input_length,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        context_encoding, utterance_encoding = tf.split(\n",
    "            states.h, num_or_size_splits=2, axis=0)\n",
    "\n",
    "    with tf.variable_scope('prediction'):\n",
    "        ct = context_encoding\n",
    "        rt = utterance_encoding\n",
    "        M = tf.get_variable(\n",
    "            'M',\n",
    "            shape=(hidden_size, hidden_size),\n",
    "            initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        ct_M = tf.matmul(ct, M)\n",
    "        batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "        batch_rt = tf.expand_dims(rt, axis=2)\n",
    "        batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "        ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "        b = tf.get_variable(\n",
    "            'b', shape=(), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        logits = ct_M_r + b\n",
    "        \n",
    "        probs = tf.sigmoid(logits)\n",
    "\n",
    "    if targets is None:\n",
    "        return probs, None\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(\n",
    "        multi_class_labels=targets, logits=logits, reduction=tf.losses.Reduction.MEAN)\n",
    "    \n",
    "    return probs, loss\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.Session(graph=graph) as session:\n",
    "    vocab_size = 91619\n",
    "    embed_size = 100\n",
    "    hidden_size = 256\n",
    "\n",
    "    batch_size = 128\n",
    "    sentence_size = 220\n",
    "    input_context = tf.random_uniform(\n",
    "        shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "    input_context_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "    input_utterance = tf.random_uniform(\n",
    "        shape=(batch_size, sentence_size), minval=0, maxval=vocab_size, dtype=tf.int64)\n",
    "    input_utterance_len = tf.constant(sentence_size, shape=(batch_size, 1))\n",
    "    targets = tf.random_uniform(\n",
    "        shape=(batch_size, 1), minval=0, maxval=1, dtype=tf.int64)    \n",
    "    \n",
    "    _, loss = dual_encoder(vocab_size,\n",
    "                           embed_size,\n",
    "                           hidden_size,\n",
    "                           input_context,\n",
    "                           input_context_len,\n",
    "                           input_utterance,\n",
    "                           input_utterance_len,\n",
    "                           targets)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)\n",
    "    \n",
    "    loss_value = session.run(loss)\n",
    "    \n",
    "    print('Average loss: {:,.3f}'.format(loss_value))\n",
    "\n",
    "del graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-cpu)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
