{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment / Estimator**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/learn/Experiment\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/estimator/Estimator\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_fn**\n",
    "```text\n",
    " |        model_fn: Model function. Follows the signature:\n",
    " |      \n",
    " |          * Args:\n",
    " |      \n",
    " |            * `features`: This is the first item returned from the `input_fn`\n",
    " |                   passed to `train`, 'evaluate`, and `predict`. This should be a\n",
    " |                   single `Tensor` or `dict` of same.\n",
    " |            * `labels`: This is the second item returned from the `input_fn`\n",
    " |                   passed to `train`, 'evaluate`, and `predict`. This should be a\n",
    " |                   single `Tensor` or `dict` of same (for multi-head models). If\n",
    " |                   mode is `ModeKeys.PREDICT`, `labels=None` will be passed. If\n",
    " |                   the `model_fn`'s signature does not accept `mode`, the\n",
    " |                   `model_fn` must still be able to handle `labels=None`.\n",
    " |            * `mode`: Optional. Specifies if this training, evaluation or\n",
    " |                   prediction. See `ModeKeys`.\n",
    " |            * `params`: Optional `dict` of hyperparameters.  Will receive what\n",
    " |                   is passed to Estimator in `params` parameter. This allows\n",
    " |                   to configure Estimators from hyper parameter tuning.\n",
    " |            * `config`: Optional configuration object. Will receive what is passed\n",
    " |                   to Estimator in `config` parameter, or the default `config`.\n",
    " |                   Allows updating things in your model_fn based on configuration\n",
    " |                   such as `num_ps_replicas`, or `model_dir`.\n",
    " |      \n",
    " |          * Returns:\n",
    " |            `EstimatorSpec`\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dual_encoder(vocab_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 input_context,\n",
    "                 input_context_len,\n",
    "                 input_utterance,\n",
    "                 input_utterance_len,\n",
    "                 targets):\n",
    "\n",
    "    with tf.variable_scope('embedding'):\n",
    "        embeddings = tf.get_variable(\n",
    "            'embeddings',\n",
    "            shape=(vocab_size, embed_size),\n",
    "            initializer=tf.random_uniform_initializer(-0.25, 0.25))\n",
    "\n",
    "        context_embed = tf.nn.embedding_lookup(\n",
    "            embeddings, input_context, name='context_embed')\n",
    "        utterance_embed = tf.nn.embedding_lookup(\n",
    "            embeddings, input_utterance, name='utterance_embed')\n",
    "\n",
    "        input_embed = tf.concat([context_embed, utterance_embed], axis=0)\n",
    "        input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "        input_length = tf.reshape(input_length, [-1])\n",
    "\n",
    "    with tf.variable_scope('rnn'):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(\n",
    "            hidden_size,\n",
    "            forget_bias=2.0,\n",
    "            use_peepholes=True,\n",
    "            state_is_tuple=True)\n",
    "\n",
    "        outputs, states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            input_embed,\n",
    "            sequence_length=input_length,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        context_encoding, utterance_encoding = tf.split(\n",
    "            states.h, num_or_size_splits=2, axis=0)\n",
    "\n",
    "    with tf.variable_scope('prediction'):\n",
    "        ct = context_encoding\n",
    "        rt = utterance_encoding\n",
    "        M = tf.get_variable(\n",
    "            'M',\n",
    "            shape=(hidden_size, hidden_size),\n",
    "            initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        ct_M = tf.matmul(ct, M)\n",
    "        batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "        batch_rt = tf.expand_dims(rt, axis=2)\n",
    "        batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "        ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "        b = tf.get_variable(\n",
    "            'b', shape=(), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        logits = ct_M_r + b\n",
    "        \n",
    "        probs = tf.sigmoid(logits)\n",
    "\n",
    "    if targets is None:\n",
    "        return probs, None\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.to_float(targets), logits=logits)\n",
    "    loss = tf.reduce_mean(loss, name=\"loss\")\n",
    "    \n",
    "    return probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    vocab_size = params['vocab_size']\n",
    "    embed_size = params['embed_size']\n",
    "    hidden_size = params['hidden_size']\n",
    "\n",
    "    input_context = features['context']\n",
    "    input_context_len = features['context_len']\n",
    "    input_utterance = features['utterance']\n",
    "    input_utterance_len = features['utterance_len']\n",
    "\n",
    "    probs, loss = dual_encoder(\n",
    "        vocab_size,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        input_context,\n",
    "        input_context_len,\n",
    "        input_utterance,\n",
    "        input_utterance_len,\n",
    "        labels)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        _learning_rate = params['learning_rate']\n",
    "        _optimizer =  params['optimizer']\n",
    "        \n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=_learning_rate,\n",
    "            clip_gradients=10.0,\n",
    "            optimizer=_optimizer)\n",
    "    else:\n",
    "        train_op = None\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=probs,\n",
    "        loss=loss,\n",
    "        train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `tokenizer` function must be defined before restoring the vocabulary object\n",
    "# (pickle does not serialize functions)\n",
    "def tokenizer(sentences):\n",
    "    return (sentence.split() for sentence in sentences)\n",
    "\n",
    "class VocabularyAdapter:\n",
    "    \n",
    "    def __init__(self, vocabulary_bin):\n",
    "        self._vocab = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(vocabulary_bin)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._vocab.vocabulary_)\n",
    "    \n",
    "    @property\n",
    "    def vector_length(self):\n",
    "        return self._vocab.max_document_length\n",
    "\n",
    "\n",
    "def input_features(vector_length):\n",
    "    return [\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='label', shape=1, dtype=tf.int64),\n",
    "    ]\n",
    "\n",
    "\n",
    "def input_fn(name, filenames, features, batch_size, num_epochs=None):\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "\n",
    "    batch_example = tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=filenames,\n",
    "        features=example_features,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        name='read_batch_record_features_' + name\n",
    "    )\n",
    "\n",
    "    batch_target = batch_example.pop('label')\n",
    "\n",
    "    return batch_example, batch_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = 'ubuntu'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "VOCAB_BIN = os.path.join(DATA_DIR, 'vocabulary.bin')\n",
    "TRAIN_TFR = os.path.join(DATA_DIR, 'train.tfrecords')\n",
    "VALID_TFR = os.path.join(DATA_DIR, 'valid.tfrecords')\n",
    "TEST_TFR = os.path.join(DATA_DIR, 'test.tfrecords')\n",
    "\n",
    "if not os.path.isfile(VOCAB_BIN):\n",
    "    raise Exception('File not found: {}'.format(VOCAB_BIN))\n",
    "\n",
    "if not os.path.isfile(TRAIN_TFR):\n",
    "    raise Exception('File not found: {}'.format(TRAIN_TFR))\n",
    "\n",
    "if not os.path.isfile(VALID_TFR):\n",
    "    raise Exception('File not found: {}'.format(VALID_TFR))\n",
    "\n",
    "if not os.path.isfile(TEST_TFR):\n",
    "    raise Exception('File not found: {}'.format(TEST_TFR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = VocabularyAdapter(VOCAB_BIN)\n",
    "features = input_features(vocab.vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'vocab_size': vocab.size,\n",
    "    'embed_size': 100,\n",
    "    'hidden_size': 256,\n",
    "    'learning_rate': 0.001,\n",
    "    'optimizer': 'Adam',\n",
    "    'batch_size': 128,\n",
    "    'num_epochs': 5,\n",
    "}\n",
    "\n",
    "input_fn_train = lambda: input_fn('train', [TRAIN_TFR], features, params['batch_size'], 1)\n",
    "input_fn_valid = lambda: input_fn('valid', [VALID_TFR], features, 16, 1)\n",
    "input_fn_test = lambda: input_fn('test', [TEST_TFR], features, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def remove_dir(path):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "MODEL_DIR = os.path.join(HOME_DIR, 'model')\n",
    "\n",
    "remove_dir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir=MODEL_DIR,\n",
    "    params=params)\n",
    "\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(1, params['num_epochs'] + 1):\n",
    "    print('[ Epoch {} ]\\n'.format(epoch))\n",
    "    print('Training...\\n')\n",
    "    %time estimator.train(input_fn_train, steps=None)\n",
    "    \n",
    "    print('Validation...\\n')\n",
    "    %time eval_result = estimator.evaluate(input_fn_valid, steps=None)\n",
    "    print(eval_result, '\\n')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-gpu-1.2)",
   "language": "python",
   "name": "tensorflow-gpu-1.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
