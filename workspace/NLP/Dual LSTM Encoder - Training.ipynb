{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimator**\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/estimator/Estimator\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_fn**\n",
    "```text\n",
    " |        model_fn: Model function. Follows the signature:\n",
    " |      \n",
    " |          * Args:\n",
    " |      \n",
    " |            * `features`: This is the first item returned from the `input_fn`\n",
    " |                   passed to `train`, 'evaluate`, and `predict`. This should be a\n",
    " |                   single `Tensor` or `dict` of same.\n",
    " |            * `labels`: This is the second item returned from the `input_fn`\n",
    " |                   passed to `train`, 'evaluate`, and `predict`. This should be a\n",
    " |                   single `Tensor` or `dict` of same (for multi-head models). If\n",
    " |                   mode is `ModeKeys.PREDICT`, `labels=None` will be passed. If\n",
    " |                   the `model_fn`'s signature does not accept `mode`, the\n",
    " |                   `model_fn` must still be able to handle `labels=None`.\n",
    " |            * `mode`: Optional. Specifies if this training, evaluation or\n",
    " |                   prediction. See `ModeKeys`.\n",
    " |            * `params`: Optional `dict` of hyperparameters.  Will receive what\n",
    " |                   is passed to Estimator in `params` parameter. This allows\n",
    " |                   to configure Estimators from hyper parameter tuning.\n",
    " |            * `config`: Optional configuration object. Will receive what is passed\n",
    " |                   to Estimator in `config` parameter, or the default `config`.\n",
    " |                   Allows updating things in your model_fn based on configuration\n",
    " |                   such as `num_ps_replicas`, or `model_dir`.\n",
    " |      \n",
    " |          * Returns:\n",
    " |            `EstimatorSpec`\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dual_encoder(vocab_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 input_context,\n",
    "                 input_context_len,\n",
    "                 input_utterance,\n",
    "                 input_utterance_len,\n",
    "                 targets):\n",
    "\n",
    "    input_data = tf.concat([input_context, input_utterance], axis=0)\n",
    "    input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "    input_length = tf.reshape(input_length, [-1])\n",
    "    \n",
    "    embeddings = tf.get_variable(\n",
    "        'embeddings',\n",
    "        shape=(vocab_size, embed_size),\n",
    "        initializer=tf.random_uniform_initializer(-0.25, 0.25))\n",
    "\n",
    "    input_embed = tf.nn.embedding_lookup(\n",
    "        embeddings, input_data, name='input_embed')\n",
    "        \n",
    "    with tf.variable_scope('rnn'):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(\n",
    "            hidden_size,\n",
    "            forget_bias=2.0,\n",
    "            use_peepholes=True,\n",
    "            state_is_tuple=True)\n",
    "\n",
    "        outputs, states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            input_embed,\n",
    "            sequence_length=input_length,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        context_encoding, utterance_encoding = tf.split(\n",
    "            states.h, num_or_size_splits=2, axis=0)\n",
    "\n",
    "    with tf.variable_scope('prediction'):\n",
    "        ct = context_encoding\n",
    "        rt = utterance_encoding\n",
    "        M = tf.get_variable(\n",
    "            'M',\n",
    "            shape=(hidden_size, hidden_size),\n",
    "            initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        ct_M = tf.matmul(ct, M)\n",
    "        batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "        batch_rt = tf.expand_dims(rt, axis=2)\n",
    "        batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "        ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "        b = tf.get_variable(\n",
    "           'b', shape=(), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        logits = ct_M_r + b\n",
    "        \n",
    "        probs = tf.sigmoid(logits)\n",
    "\n",
    "    if targets is None:\n",
    "        return probs, None\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(\n",
    "        multi_class_labels=targets, logits=logits, reduction=tf.losses.Reduction.MEAN)\n",
    "    \n",
    "    return probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn_train(features, labels, vocab_size, embed_size, hidden_size, learning_rate, optimizer):\n",
    "    input_context = features['context']\n",
    "    input_context_len = features['context_len']\n",
    "    input_utterance = features['utterance']\n",
    "    input_utterance_len = features['utterance_len']\n",
    "\n",
    "    probs, loss = dual_encoder(\n",
    "        vocab_size,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        input_context,\n",
    "        input_context_len,\n",
    "        input_utterance,\n",
    "        input_utterance_len,\n",
    "        labels)\n",
    "    \n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=learning_rate,\n",
    "        clip_gradients=10.0,\n",
    "        optimizer=optimizer)\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.TRAIN,\n",
    "        predictions=probs,\n",
    "        loss=loss,\n",
    "        train_op=train_op)\n",
    "\n",
    "def model_fn_eval(features, labels, vocab_size, embed_size, hidden_size):\n",
    "    input_context = []\n",
    "    input_context_len = []\n",
    "    input_utterance = []\n",
    "    input_utterance_len = []\n",
    "    labels_ = []\n",
    "    \n",
    "    context = features['context']\n",
    "    context_len = features['context_len']\n",
    "\n",
    "    input_context.append(context)\n",
    "    input_context_len.append(context_len)\n",
    "    input_utterance.append(features['utterance'])\n",
    "    input_utterance_len.append(features['utterance_len'])\n",
    "    labels_.append(tf.ones_like(context_len))\n",
    "    \n",
    "    for i in range(9):\n",
    "        input_context.append(context)\n",
    "        input_context_len.append(context_len)\n",
    "        input_utterance.append(features['distractor_{}'.format(i)])\n",
    "        input_utterance_len.append(features['distractor_{}_len'.format(i)])\n",
    "        labels_.append(tf.zeros_like(context_len))\n",
    "\n",
    "    input_context = tf.concat(input_context, axis=0)\n",
    "    input_context_len = tf.concat(input_context_len, axis=0)\n",
    "    input_utterance = tf.concat(input_utterance, axis=0)\n",
    "    input_utterance_len = tf.concat(input_utterance_len, axis=0)\n",
    "    labels_ = tf.concat(labels_, axis=0)\n",
    "\n",
    "    probs, loss = dual_encoder(\n",
    "        vocab_size,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        input_context,\n",
    "        input_context_len,\n",
    "        input_utterance,\n",
    "        input_utterance_len,\n",
    "        labels_)\n",
    "    \n",
    "    split_probs = tf.split(probs, num_or_size_splits=10, axis=0)\n",
    "    predictions = tf.concat(split_probs, axis=1)\n",
    "    predictions_2 = predictions[:, :2]\n",
    "    \n",
    "    recall_at_1_2 = tf.metrics.recall_at_k(labels=labels, predictions=predictions_2, k=1)\n",
    "    recall_at_1_10 = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=1)\n",
    "    recall_at_2_10 = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=2)\n",
    "    recall_at_5_10 = tf.metrics.recall_at_k(labels=labels, predictions=predictions, k=5)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        'recall_at_1_2': recall_at_1_2,\n",
    "        'recall_at_1_10': recall_at_1_10,\n",
    "        'recall_at_2_10': recall_at_2_10,\n",
    "        'recall_at_5_10': recall_at_5_10,\n",
    "    }\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        predictions=probs,\n",
    "        loss=loss,\n",
    "        train_op=None,\n",
    "        eval_metric_ops=eval_metric_ops\n",
    "    )\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    vocab_size = params['vocab_size']\n",
    "    embed_size = params['embed_size']\n",
    "    hidden_size = params['hidden_size']\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        learning_rate = params['learning_rate']\n",
    "        optimizer =  params['optimizer']\n",
    "        return model_fn_train(\n",
    "            features, labels, vocab_size, embed_size, hidden_size, learning_rate, optimizer)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return model_fn_eval(features, labels, vocab_size, embed_size, hidden_size)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `tokenizer` function must be defined before restoring the vocabulary object\n",
    "# (pickle does not serialize functions)\n",
    "def tokenizer(sentences):\n",
    "    return (sentence.split() for sentence in sentences)\n",
    "\n",
    "class VocabularyAdapter:\n",
    "    \n",
    "    def __init__(self, vocabulary_bin):\n",
    "        self._vocab = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(vocabulary_bin)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._vocab.vocabulary_)\n",
    "    \n",
    "    @property\n",
    "    def vector_length(self):\n",
    "        return self._vocab.max_document_length\n",
    "\n",
    "\n",
    "def features_train(vector_length):\n",
    "    return [\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='label', shape=1, dtype=tf.int64),\n",
    "    ]\n",
    "\n",
    "def features_eval(vector_length):\n",
    "    features = []\n",
    "    keys = ['context', 'utterance']\n",
    "    keys += ['distractor_{}'.format(i) for i in range(9)]\n",
    "    for key in keys:\n",
    "        features += [\n",
    "            tf.feature_column.numeric_column(\n",
    "                key=key, shape=vector_length, dtype=tf.int64),\n",
    "            tf.feature_column.numeric_column(\n",
    "                key=key + '_len', shape=1, dtype=tf.int64),\n",
    "        ]\n",
    "    return features\n",
    "\n",
    "def _input_reader(name, filenames, features, batch_size, num_epochs):\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "    return tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=filenames,\n",
    "        features=example_features,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        randomize_input=True,\n",
    "        queue_capacity=200000 + batch_size * 10,\n",
    "        name='read_batch_record_features_' + name\n",
    "    )\n",
    "\n",
    "\n",
    "def input_train(name, filenames, features, batch_size, num_epochs=None):\n",
    "    batch_example = _input_reader(name, filenames, features, batch_size, num_epochs)\n",
    "    batch_target = batch_example.pop('label')\n",
    "    return batch_example, batch_target\n",
    "\n",
    "def input_eval(name, filenames, features, batch_size, num_epochs=None):\n",
    "    batch_example = _input_reader(name, filenames, features, batch_size, num_epochs)\n",
    "    batch_target = tf.zeros_like(batch_example['context_len'])\n",
    "    return batch_example, batch_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = 'ubuntu'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "VOCAB_BIN = os.path.join(DATA_DIR, 'vocabulary.bin')\n",
    "TRAIN_TFR = os.path.join(DATA_DIR, 'train.tfrecords')\n",
    "VALID_TFR = os.path.join(DATA_DIR, 'valid.tfrecords')\n",
    "TEST_TFR = os.path.join(DATA_DIR, 'test.tfrecords')\n",
    "\n",
    "def has_file(file):\n",
    "    if not os.path.isfile(file):\n",
    "        raise Exception('File not found: {}'.format(file))\n",
    "\n",
    "has_file(VOCAB_BIN)\n",
    "has_file(TRAIN_TFR)\n",
    "has_file(VALID_TFR)\n",
    "has_file(TEST_TFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = VocabularyAdapter(VOCAB_BIN)\n",
    "train_features = features_train(vocab.vector_length)\n",
    "eval_features = features_eval(vocab.vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'vocab_size': vocab.size,\n",
    "    'embed_size': 100,\n",
    "    'hidden_size': 200,\n",
    "    'learning_rate': 0.001,\n",
    "    'optimizer': 'Adam',\n",
    "    'batch_size': 256,\n",
    "    'num_epochs': 2,\n",
    "}\n",
    "\n",
    "input_fn_train = lambda: input_train('train', [TRAIN_TFR], train_features, params['batch_size'], 1)\n",
    "input_fn_valid = lambda: input_eval('valid', [VALID_TFR], eval_features, 16, 1)\n",
    "input_fn_test = lambda: input_eval('test', [TEST_TFR], eval_features, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def remove_dir(path):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "MODEL_DIR = os.path.join(HOME_DIR, 'model')\n",
    "\n",
    "remove_dir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir=MODEL_DIR,\n",
    "    params=params)\n",
    "\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epoch_range(i, num_epochs):\n",
    "    range_start = i * num_epochs + 1\n",
    "    range_end = range_start + num_epochs\n",
    "    return range(range_start, range_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in epoch_range(0, params['num_epochs']):\n",
    "    print('[ Epoch {} ]\\n'.format(epoch))\n",
    "    print('Training...\\n')\n",
    "    %time estimator.train(input_fn_train, steps=None)\n",
    "    print()\n",
    "    print('Validation...\\n')\n",
    "    %time estimator.evaluate(input_fn_valid, steps=None)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "estimator.evaluate(input_fn_test, steps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-gpu-1.2)",
   "language": "python",
   "name": "tensorflow-gpu-1.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
