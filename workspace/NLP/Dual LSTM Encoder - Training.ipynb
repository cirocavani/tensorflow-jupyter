{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dual LSTM Encoder for Dialog Response Generation**\n",
    "\n",
    "http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "\n",
    "https://github.com/dennybritz/chatbot-retrieval\n",
    "\n",
    "https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "\n",
    "https://arxiv.org/abs/1506.08909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Estimator in module tensorflow.python.estimator.estimator:\n",
      "\n",
      "class Estimator(builtins.object)\n",
      " |  Estimator class to train and evaluate TensorFlow models.\n",
      " |  \n",
      " |  The `Estimator` object wraps a model which is specified by a `model_fn`,\n",
      " |  which, given inputs and a number of other parameters, returns the ops\n",
      " |  necessary to perform training, evaluation, or predictions.\n",
      " |  \n",
      " |  All outputs (checkpoints, event files, etc.) are written to `model_dir`, or a\n",
      " |  subdirectory thereof. If `model_dir` is not set, a temporary directory is\n",
      " |  used.\n",
      " |  \n",
      " |  The `config` argument can be passed `RunConfig` object containing information\n",
      " |  about the execution environment. It is passed on to the `model_fn`, if the\n",
      " |  `model_fn` has a parameter named \"config\" (and input functions in the same\n",
      " |  manner). If the `config` parameter is not passed, it is instantiated by the\n",
      " |  `Estimator`. Not passing config means that defaults useful for local execution\n",
      " |  are used. `Estimator` makes config available to the model (for instance, to\n",
      " |  allow specialization based on the number of workers available), and also uses\n",
      " |  some of its fields to control internals, especially regarding checkpointing.\n",
      " |  \n",
      " |  The `params` argument contains hyperparameters. It is passed to the\n",
      " |  `model_fn`, if the `model_fn` has a parameter named \"params\", and to the input\n",
      " |  functions in the same manner. `Estimator` only passes params along, it does\n",
      " |  not inspect it. The structure of `params` is therefore entirely up to the\n",
      " |  developer.\n",
      " |  \n",
      " |  None of `Estimator`'s methods can be overridden in subclasses (its\n",
      " |  constructor enforces this). Subclasses should use `model_fn` to configure\n",
      " |  the base class, and may add methods implementing specialized functionality.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model_fn, model_dir=None, config=None, params=None)\n",
      " |      Constructs an `Estimator` instance.\n",
      " |      \n",
      " |      Args:\n",
      " |        model_fn: Model function. Follows the signature:\n",
      " |      \n",
      " |          * Args:\n",
      " |      \n",
      " |            * `features`: This is the first item returned from the `input_fn`\n",
      " |                   passed to `train`, 'evaluate`, and `predict`. This should be a\n",
      " |                   single `Tensor` or `dict` of same.\n",
      " |            * `labels`: This is the second item returned from the `input_fn`\n",
      " |                   passed to `train`, 'evaluate`, and `predict`. This should be a\n",
      " |                   single `Tensor` or `dict` of same (for multi-head models). If\n",
      " |                   mode is `ModeKeys.PREDICT`, `labels=None` will be passed. If\n",
      " |                   the `model_fn`'s signature does not accept `mode`, the\n",
      " |                   `model_fn` must still be able to handle `labels=None`.\n",
      " |            * `mode`: Optional. Specifies if this training, evaluation or\n",
      " |                   prediction. See `ModeKeys`.\n",
      " |            * `params`: Optional `dict` of hyperparameters.  Will receive what\n",
      " |                   is passed to Estimator in `params` parameter. This allows\n",
      " |                   to configure Estimators from hyper parameter tuning.\n",
      " |            * `config`: Optional configuration object. Will receive what is passed\n",
      " |                   to Estimator in `config` parameter, or the default `config`.\n",
      " |                   Allows updating things in your model_fn based on configuration\n",
      " |                   such as `num_ps_replicas`, or `model_dir`.\n",
      " |      \n",
      " |          * Returns:\n",
      " |            `EstimatorSpec`\n",
      " |      \n",
      " |        model_dir: Directory to save model parameters, graph and etc. This can\n",
      " |          also be used to load checkpoints from the directory into a estimator to\n",
      " |          continue training a previously saved model. If `None`, the model_dir in\n",
      " |          `config` will be used if set. If both are set, they must be same. If\n",
      " |          both are `None`, a temporary directory will be used.\n",
      " |        config: Configuration object.\n",
      " |        params: `dict` of hyper parameters that will be passed into `model_fn`.\n",
      " |                Keys are names of parameters, values are basic python types.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: parameters of `model_fn` don't match `params`.\n",
      " |        ValueError: if this is called via a subclass and if that class overrides\n",
      " |          a member of `Estimator`.\n",
      " |  \n",
      " |  evaluate(self, input_fn, steps=None, hooks=None, checkpoint_path=None, name=None)\n",
      " |      Evaluates the model given evaluation data input_fn.\n",
      " |      \n",
      " |      For each step, calls `input_fn`, which returns one batch of data.\n",
      " |      Evaluates until:\n",
      " |      - `steps` batches are processed, or\n",
      " |      - `input_fn` raises an end-of-input exception (`OutOfRangeError` or\n",
      " |      `StopIteration`).\n",
      " |      \n",
      " |      Args:\n",
      " |        input_fn: Input function returning a tuple of:\n",
      " |            features - Dictionary of string feature name to `Tensor` or\n",
      " |              `SparseTensor`.\n",
      " |            labels - `Tensor` or dictionary of `Tensor` with labels.\n",
      " |        steps: Number of steps for which to evaluate model. If `None`, evaluates\n",
      " |          until `input_fn` raises an end-of-input exception.\n",
      " |        hooks: List of `SessionRunHook` subclass instances. Used for callbacks\n",
      " |          inside the evaluation call.\n",
      " |        checkpoint_path: Path of a specific checkpoint to evaluate. If `None`, the\n",
      " |          latest checkpoint in `model_dir` is used.\n",
      " |        name: Name of the evaluation if user needs to run multiple evaluations on\n",
      " |          different data sets, such as on training data vs test data. Metrics for\n",
      " |          different evaluations are saved in separate folders, and appear\n",
      " |          separately in tensorboard.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dict containing the evaluation metrics specified in `model_fn` keyed by\n",
      " |        name, as well as an entry `global_step` which contains the value of the\n",
      " |        global step for which this evaluation was performed.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `steps <= 0`.\n",
      " |        ValueError: If no model has been trained, namely `model_dir`, or the\n",
      " |          given `checkpoint_path` is empty.\n",
      " |  \n",
      " |  export_savedmodel(self, export_dir_base, serving_input_receiver_fn, assets_extra=None, as_text=False, checkpoint_path=None)\n",
      " |      Exports inference graph as a SavedModel into given dir.\n",
      " |      \n",
      " |      This method builds a new graph by first calling the\n",
      " |      serving_input_receiver_fn to obtain feature `Tensor`s, and then calling\n",
      " |      this `Estimator`'s model_fn to generate the model graph based on those\n",
      " |      features. It restores the given checkpoint (or, lacking that, the most\n",
      " |      recent checkpoint) into this graph in a fresh session.  Finally it creates\n",
      " |      a timestamped export directory below the given export_dir_base, and writes\n",
      " |      a `SavedModel` into it containing a single `MetaGraphDef` saved from this\n",
      " |      session.\n",
      " |      \n",
      " |      The exported `MetaGraphDef` will provide one `SignatureDef` for each\n",
      " |      element of the export_outputs dict returned from the model_fn, named using\n",
      " |      the same keys.  One of these keys is always\n",
      " |      signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY, indicating which\n",
      " |      signature will be served when a serving request does not specify one.\n",
      " |      For each signature, the outputs are provided by the corresponding\n",
      " |      `ExportOutput`s, and the inputs are always the input receivers provided by\n",
      " |      the serving_input_receiver_fn.\n",
      " |      \n",
      " |      Extra assets may be written into the SavedModel via the extra_assets\n",
      " |      argument.  This should be a dict, where each key gives a destination path\n",
      " |      (including the filename) relative to the assets.extra directory.  The\n",
      " |      corresponding value gives the full path of the source file to be copied.\n",
      " |      For example, the simple case of copying a single file without renaming it\n",
      " |      is specified as `{'my_asset_file.txt': '/path/to/my_asset_file.txt'}`.\n",
      " |      \n",
      " |      Args:\n",
      " |        export_dir_base: A string containing a directory in which to create\n",
      " |          timestamped subdirectories containing exported SavedModels.\n",
      " |        serving_input_receiver_fn: A function that takes no argument and\n",
      " |          returns a `ServingInputReceiver`.\n",
      " |        assets_extra: A dict specifying how to populate the assets.extra directory\n",
      " |          within the exported SavedModel, or `None` if no extra assets are needed.\n",
      " |        as_text: whether to write the SavedModel proto in text format.\n",
      " |        checkpoint_path: The checkpoint path to export.  If `None` (the default),\n",
      " |          the most recent checkpoint found within the model directory is chosen.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The string path to the exported directory.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if no serving_input_receiver_fn is provided, no export_outputs\n",
      " |            are provided, or no checkpoint can be found.\n",
      " |  \n",
      " |  predict(self, input_fn, predict_keys=None, hooks=None, checkpoint_path=None)\n",
      " |      Returns predictions for given features.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_fn: Input function returning features which is a dictionary of\n",
      " |          string feature name to `Tensor` or `SparseTensor`. If it returns a\n",
      " |          tuple, first item is extracted as features. Prediction continues until\n",
      " |          `input_fn` raises an end-of-input exception (`OutOfRangeError` or\n",
      " |          `StopIteration`).\n",
      " |        predict_keys: list of `str`, name of the keys to predict. It is used if\n",
      " |          the `EstimatorSpec.predictions` is a `dict`. If `predict_keys` is used\n",
      " |          then rest of the predictions will be filtered from the dictionary. If\n",
      " |          `None`, returns all.\n",
      " |        hooks: List of `SessionRunHook` subclass instances. Used for callbacks\n",
      " |          inside the prediction call.\n",
      " |        checkpoint_path: Path of a specific checkpoint to predict. If `None`, the\n",
      " |          latest checkpoint in `model_dir` is used.\n",
      " |      \n",
      " |      Yields:\n",
      " |        Evaluated values of `predictions` tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: Could not find a trained model in model_dir.\n",
      " |        ValueError: if batch length of predictions are not same.\n",
      " |        ValueError: If there is a conflict between `predict_keys` and\n",
      " |          `predictions`. For example if `predict_keys` is not `None` but\n",
      " |          `EstimatorSpec.predictions` is not a `dict`.\n",
      " |  \n",
      " |  train(self, input_fn, hooks=None, steps=None, max_steps=None)\n",
      " |      Trains a model given training data input_fn.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_fn: Input function returning a tuple of:\n",
      " |            features - `Tensor` or dictionary of string feature name to `Tensor`.\n",
      " |            labels - `Tensor` or dictionary of `Tensor` with labels.\n",
      " |        hooks: List of `SessionRunHook` subclass instances. Used for callbacks\n",
      " |          inside the training loop.\n",
      " |        steps: Number of steps for which to train model. If `None`, train forever\n",
      " |          or train until input_fn generates the `OutOfRange` or `StopIteration`\n",
      " |          error. 'steps' works incrementally. If you call two times\n",
      " |          train(steps=10) then training occurs in total 20 steps. If `OutOfRange`\n",
      " |          or `StopIteration` error occurs in the middle, training stops before 20\n",
      " |          steps. If you don't want to have incremental behaviour please set\n",
      " |          `max_steps` instead. If set, `max_steps` must be `None`.\n",
      " |        max_steps: Number of total steps for which to train model. If `None`,\n",
      " |          train forever or train until input_fn generates the `OutOfRange` or\n",
      " |          `StopIteration` error. If set, `steps` must be `None`. If `OutOfRange`\n",
      " |          or `StopIteration` error occurs in the middle, training stops before\n",
      " |          `max_steps` steps.\n",
      " |      \n",
      " |          Two calls to `train(steps=100)` means 200 training\n",
      " |          iterations. On the other hand, two calls to `train(max_steps=100)` means\n",
      " |          that the second call will not do any iteration since first call did\n",
      " |          all 100 steps.\n",
      " |      \n",
      " |      Returns:\n",
      " |        `self`, for chaining.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If both `steps` and `max_steps` are not `None`.\n",
      " |        ValueError: If either `steps` or `max_steps` is <= 0.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  config\n",
      " |  \n",
      " |  model_dir\n",
      " |  \n",
      " |  params\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.estimator.Estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_fn**\n",
    "```text\n",
    " |        model_fn: Model function. Follows the signature:\n",
    " |      \n",
    " |          * Args:\n",
    " |      \n",
    " |            * `features`: This is the first item returned from the `input_fn`\n",
    " |                   passed to `train`, 'evaluate`, and `predict`. This should be a\n",
    " |                   single `Tensor` or `dict` of same.\n",
    " |            * `labels`: This is the second item returned from the `input_fn`\n",
    " |                   passed to `train`, 'evaluate`, and `predict`. This should be a\n",
    " |                   single `Tensor` or `dict` of same (for multi-head models). If\n",
    " |                   mode is `ModeKeys.PREDICT`, `labels=None` will be passed. If\n",
    " |                   the `model_fn`'s signature does not accept `mode`, the\n",
    " |                   `model_fn` must still be able to handle `labels=None`.\n",
    " |            * `mode`: Optional. Specifies if this training, evaluation or\n",
    " |                   prediction. See `ModeKeys`.\n",
    " |            * `params`: Optional `dict` of hyperparameters.  Will receive what\n",
    " |                   is passed to Estimator in `params` parameter. This allows\n",
    " |                   to configure Estimators from hyper parameter tuning.\n",
    " |            * `config`: Optional configuration object. Will receive what is passed\n",
    " |                   to Estimator in `config` parameter, or the default `config`.\n",
    " |                   Allows updating things in your model_fn based on configuration\n",
    " |                   such as `num_ps_replicas`, or `model_dir`.\n",
    " |      \n",
    " |          * Returns:\n",
    " |            `EstimatorSpec`\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dual_encoder(vocab_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 input_context,\n",
    "                 input_context_len,\n",
    "                 input_utterance,\n",
    "                 input_utterance_len,\n",
    "                 targets):\n",
    "\n",
    "    with tf.variable_scope('embedding'):\n",
    "        embeddings = tf.get_variable(\n",
    "            'embeddings',\n",
    "            shape=(vocab_size, embed_size),\n",
    "            initializer=tf.random_uniform_initializer(-0.25, 0.25))\n",
    "\n",
    "        context_embed = tf.nn.embedding_lookup(\n",
    "            embeddings, input_context, name='context_embed')\n",
    "        utterance_embed = tf.nn.embedding_lookup(\n",
    "            embeddings, input_utterance, name='utterance_embed')\n",
    "\n",
    "        input_embed = tf.concat([context_embed, utterance_embed], axis=0)\n",
    "        input_length = tf.concat([input_context_len, input_utterance_len], axis=0)\n",
    "        input_length = tf.reshape(input_length, [-1])\n",
    "\n",
    "    with tf.variable_scope('rnn'):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(\n",
    "            hidden_size,\n",
    "            forget_bias=2.0,\n",
    "            use_peepholes=True,\n",
    "            state_is_tuple=True)\n",
    "\n",
    "        outputs, states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            input_embed,\n",
    "            sequence_length=input_length,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        context_encoding, utterance_encoding = tf.split(\n",
    "            states.h, num_or_size_splits=2, axis=0)\n",
    "\n",
    "    with tf.variable_scope('prediction'):\n",
    "        ct = context_encoding\n",
    "        rt = utterance_encoding\n",
    "        M = tf.get_variable(\n",
    "            'M',\n",
    "            shape=(hidden_size, hidden_size),\n",
    "            initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        ct_M = tf.matmul(ct, M)\n",
    "        batch_ct_M = tf.expand_dims(ct_M, axis=2)\n",
    "        batch_rt = tf.expand_dims(rt, axis=2)\n",
    "        batch_ct_M_r = tf.matmul(batch_ct_M, batch_rt, transpose_a=True)\n",
    "        ct_M_r = tf.squeeze(batch_ct_M_r, axis=2)\n",
    "\n",
    "        b = tf.get_variable(\n",
    "            'b', shape=(), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        logits = ct_M_r + b\n",
    "        \n",
    "        probs = tf.sigmoid(logits)\n",
    "\n",
    "    if targets is None:\n",
    "        return probs, None\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.to_float(targets), logits=logits)\n",
    "    loss = tf.reduce_mean(loss, name=\"loss\")\n",
    "    \n",
    "    return probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    vocab_size = params['vocab_size']\n",
    "    embed_size = params['embed_size']\n",
    "    hidden_size = params['hidden_size']\n",
    "\n",
    "    input_context = features['context']\n",
    "    input_context_len = features['context_len']\n",
    "    input_utterance = features['utterance']\n",
    "    input_utterance_len = features['utterance_len']\n",
    "\n",
    "    probs, loss = dual_encoder(\n",
    "        vocab_size,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        input_context,\n",
    "        input_context_len,\n",
    "        input_utterance,\n",
    "        input_utterance_len,\n",
    "        labels)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        _learning_rate = params['learning_rate']\n",
    "        _optimizer =  params['optimizer']\n",
    "        \n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=_learning_rate,\n",
    "            clip_gradients=10.0,\n",
    "            optimizer=_optimizer)\n",
    "    else:\n",
    "        train_op = None\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=probs,\n",
    "        loss=loss,\n",
    "        train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `tokenizer` function must be defined before restoring the vocabulary object\n",
    "# (pickle does not serialize functions)\n",
    "def tokenizer(sentences):\n",
    "    return (sentence.split() for sentence in sentences)\n",
    "\n",
    "class VocabularyAdapter:\n",
    "    \n",
    "    def __init__(self, vocabulary_bin):\n",
    "        self._vocab = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(vocabulary_bin)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._vocab.vocabulary_)\n",
    "    \n",
    "    @property\n",
    "    def vector_length(self):\n",
    "        return self._vocab.max_document_length\n",
    "\n",
    "\n",
    "def input_features(vector_length):\n",
    "    return [\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='context_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance', shape=vector_length, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='utterance_len', shape=1, dtype=tf.int64),\n",
    "        tf.feature_column.numeric_column(\n",
    "            key='label', shape=1, dtype=tf.int64),\n",
    "    ]\n",
    "\n",
    "\n",
    "def input_fn(name, filenames, features, batch_size, num_epochs=None):\n",
    "    example_features = tf.feature_column.make_parse_example_spec(features)\n",
    "\n",
    "    batch_example = tf.contrib.learn.read_batch_record_features(\n",
    "        file_pattern=filenames,\n",
    "        features=example_features,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        name='read_batch_record_features_' + name\n",
    "    )\n",
    "\n",
    "    batch_target = batch_example.pop('label')\n",
    "\n",
    "    return batch_example, batch_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = 'ubuntu'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "VOCAB_BIN = os.path.join(DATA_DIR, 'vocabulary.bin')\n",
    "TRAIN_TFR = os.path.join(DATA_DIR, 'train.tfrecords')\n",
    "VALID_TFR = os.path.join(DATA_DIR, 'valid.tfrecords')\n",
    "TEST_TFR = os.path.join(DATA_DIR, 'test.tfrecords')\n",
    "\n",
    "if not os.path.isfile(VOCAB_BIN):\n",
    "    raise Exception('File not found: {}'.format(VOCAB_BIN))\n",
    "\n",
    "if not os.path.isfile(TRAIN_TFR):\n",
    "    raise Exception('File not found: {}'.format(TRAIN_TFR))\n",
    "\n",
    "if not os.path.isfile(VALID_TFR):\n",
    "    raise Exception('File not found: {}'.format(VALID_TFR))\n",
    "\n",
    "if not os.path.isfile(TEST_TFR):\n",
    "    raise Exception('File not found: {}'.format(TEST_TFR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def remove_dir(path):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "MODEL_DIR = os.path.join(HOME_DIR, 'model')\n",
    "\n",
    "remove_dir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = VocabularyAdapter(VOCAB_BIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'vocab_size': vocab.size,\n",
    "    'embed_size': 100,\n",
    "    'hidden_size': 256,\n",
    "    'learning_rate': 0.001,\n",
    "    'optimizer': 'Adam',\n",
    "    'batch_size': 128,\n",
    "    'num_epochs': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = input_features(vocab.vector_length)\n",
    "batch_size = params['batch_size']\n",
    "num_epochs = params['num_epochs']\n",
    "\n",
    "input_fn_train = lambda: input_fn('train', [TRAIN_TFR], features, batch_size, num_epochs)\n",
    "input_fn_valid = lambda: input_fn('valid', [VALID_TFR], features, 32, 1)\n",
    "input_fn_test = lambda: input_fn('test', [TEST_TFR], features, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'ubuntu/model', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7efcca82f5c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir=MODEL_DIR,\n",
    "    params=params)\n",
    "\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.896316, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.711419\n",
      "INFO:tensorflow:loss = 0.681102, step = 101 (140.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711863\n",
      "INFO:tensorflow:loss = 0.719473, step = 201 (140.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71131\n",
      "INFO:tensorflow:loss = 0.6546, step = 301 (140.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711669\n",
      "INFO:tensorflow:loss = 0.655473, step = 401 (140.514 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 428 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.709543\n",
      "INFO:tensorflow:loss = 0.626053, step = 501 (140.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711691\n",
      "INFO:tensorflow:loss = 0.6248, step = 601 (140.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711667\n",
      "INFO:tensorflow:loss = 0.657699, step = 701 (140.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711738\n",
      "INFO:tensorflow:loss = 0.645597, step = 801 (140.500 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 855 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.70971\n",
      "INFO:tensorflow:loss = 0.674234, step = 901 (140.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711451\n",
      "INFO:tensorflow:loss = 0.64129, step = 1001 (140.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711634\n",
      "INFO:tensorflow:loss = 0.68319, step = 1101 (140.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711776\n",
      "INFO:tensorflow:loss = 0.623314, step = 1201 (140.495 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1282 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.71046\n",
      "INFO:tensorflow:loss = 0.641878, step = 1301 (140.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71198\n",
      "INFO:tensorflow:loss = 0.631996, step = 1401 (140.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711889\n",
      "INFO:tensorflow:loss = 0.659496, step = 1501 (140.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711932\n",
      "INFO:tensorflow:loss = 0.64025, step = 1601 (140.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711826\n",
      "INFO:tensorflow:loss = 0.634104, step = 1701 (140.483 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1709 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710565\n",
      "INFO:tensorflow:loss = 0.566833, step = 1801 (140.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.712017\n",
      "INFO:tensorflow:loss = 0.604354, step = 1901 (140.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711837\n",
      "INFO:tensorflow:loss = 0.582987, step = 2001 (140.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71171\n",
      "INFO:tensorflow:loss = 0.595847, step = 2101 (140.507 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2136 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710233\n",
      "INFO:tensorflow:loss = 0.549791, step = 2201 (140.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711629\n",
      "INFO:tensorflow:loss = 0.59111, step = 2301 (140.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711804\n",
      "INFO:tensorflow:loss = 0.598596, step = 2401 (140.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711951\n",
      "INFO:tensorflow:loss = 0.608362, step = 2501 (140.459 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2563 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710419\n",
      "INFO:tensorflow:loss = 0.564222, step = 2601 (140.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711713\n",
      "INFO:tensorflow:loss = 0.664016, step = 2701 (140.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711936\n",
      "INFO:tensorflow:loss = 0.657545, step = 2801 (140.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711787\n",
      "INFO:tensorflow:loss = 0.60847, step = 2901 (140.492 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2990 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710171\n",
      "INFO:tensorflow:loss = 0.662911, step = 3001 (140.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711726\n",
      "INFO:tensorflow:loss = 0.575839, step = 3101 (140.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711848\n",
      "INFO:tensorflow:loss = 0.6141, step = 3201 (140.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.7119\n",
      "INFO:tensorflow:loss = 0.509513, step = 3301 (140.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71184\n",
      "INFO:tensorflow:loss = 0.541189, step = 3401 (140.481 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3417 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710329\n",
      "INFO:tensorflow:loss = 0.580719, step = 3501 (140.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711831\n",
      "INFO:tensorflow:loss = 0.62054, step = 3601 (140.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711738\n",
      "INFO:tensorflow:loss = 0.59211, step = 3701 (140.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711753\n",
      "INFO:tensorflow:loss = 0.535274, step = 3801 (140.499 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3844 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710295\n",
      "INFO:tensorflow:loss = 0.571855, step = 3901 (140.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711812\n",
      "INFO:tensorflow:loss = 0.553732, step = 4001 (140.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711849\n",
      "INFO:tensorflow:loss = 0.493411, step = 4101 (140.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711815\n",
      "INFO:tensorflow:loss = 0.583008, step = 4201 (140.485 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4271 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710412\n",
      "INFO:tensorflow:loss = 0.617386, step = 4301 (140.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711709\n",
      "INFO:tensorflow:loss = 0.493296, step = 4401 (140.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711671\n",
      "INFO:tensorflow:loss = 0.516003, step = 4501 (140.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.7117\n",
      "INFO:tensorflow:loss = 0.599991, step = 4601 (140.508 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4698 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710266\n",
      "INFO:tensorflow:loss = 0.533398, step = 4701 (140.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711735\n",
      "INFO:tensorflow:loss = 0.47893, step = 4801 (140.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71175\n",
      "INFO:tensorflow:loss = 0.544761, step = 4901 (140.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711667\n",
      "INFO:tensorflow:loss = 0.527387, step = 5001 (140.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71154\n",
      "INFO:tensorflow:loss = 0.467721, step = 5101 (140.539 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5125 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710379\n",
      "INFO:tensorflow:loss = 0.468616, step = 5201 (140.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711704\n",
      "INFO:tensorflow:loss = 0.529716, step = 5301 (140.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711563\n",
      "INFO:tensorflow:loss = 0.46867, step = 5401 (140.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711766\n",
      "INFO:tensorflow:loss = 0.481706, step = 5501 (140.496 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5552 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710045\n",
      "INFO:tensorflow:loss = 0.526499, step = 5601 (140.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711832\n",
      "INFO:tensorflow:loss = 0.534328, step = 5701 (140.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711728\n",
      "INFO:tensorflow:loss = 0.487174, step = 5801 (140.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711581\n",
      "INFO:tensorflow:loss = 0.507786, step = 5901 (140.532 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5979 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710441\n",
      "INFO:tensorflow:loss = 0.503793, step = 6001 (140.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711836\n",
      "INFO:tensorflow:loss = 0.433621, step = 6101 (140.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711579\n",
      "INFO:tensorflow:loss = 0.455662, step = 6201 (140.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711425\n",
      "INFO:tensorflow:loss = 0.441664, step = 6301 (140.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711746\n",
      "INFO:tensorflow:loss = 0.512094, step = 6401 (140.500 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6406 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710245\n",
      "INFO:tensorflow:loss = 0.491722, step = 6501 (140.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711793\n",
      "INFO:tensorflow:loss = 0.568682, step = 6601 (140.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711423\n",
      "INFO:tensorflow:loss = 0.469581, step = 6701 (140.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.500292, step = 6801 (140.530 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6833 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710237\n",
      "INFO:tensorflow:loss = 0.458765, step = 6901 (140.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711761\n",
      "INFO:tensorflow:loss = 0.478114, step = 7001 (140.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711525\n",
      "INFO:tensorflow:loss = 0.417596, step = 7101 (140.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711664\n",
      "INFO:tensorflow:loss = 0.467996, step = 7201 (140.515 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7260 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710176\n",
      "INFO:tensorflow:loss = 0.479495, step = 7301 (140.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711639\n",
      "INFO:tensorflow:loss = 0.423785, step = 7401 (140.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711543\n",
      "INFO:tensorflow:loss = 0.46031, step = 7501 (140.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711418\n",
      "INFO:tensorflow:loss = 0.464887, step = 7601 (140.565 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7687 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.71005\n",
      "INFO:tensorflow:loss = 0.472432, step = 7701 (140.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711577\n",
      "INFO:tensorflow:loss = 0.478625, step = 7801 (140.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711561\n",
      "INFO:tensorflow:loss = 0.460407, step = 7901 (140.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711411\n",
      "INFO:tensorflow:loss = 0.458831, step = 8001 (140.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711634\n",
      "INFO:tensorflow:loss = 0.449801, step = 8101 (140.521 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8114 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710079\n",
      "INFO:tensorflow:loss = 0.415137, step = 8201 (140.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711559\n",
      "INFO:tensorflow:loss = 0.466668, step = 8301 (140.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711528\n",
      "INFO:tensorflow:loss = 0.503622, step = 8401 (140.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711726\n",
      "INFO:tensorflow:loss = 0.500406, step = 8501 (140.504 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8541 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710176\n",
      "INFO:tensorflow:loss = 0.493429, step = 8601 (140.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711515\n",
      "INFO:tensorflow:loss = 0.483166, step = 8701 (140.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711593\n",
      "INFO:tensorflow:loss = 0.447238, step = 8801 (140.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711791\n",
      "INFO:tensorflow:loss = 0.455791, step = 8901 (140.491 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8968 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710223\n",
      "INFO:tensorflow:loss = 0.48028, step = 9001 (140.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711616\n",
      "INFO:tensorflow:loss = 0.528377, step = 9101 (140.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711538\n",
      "INFO:tensorflow:loss = 0.390297, step = 9201 (140.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711502\n",
      "INFO:tensorflow:loss = 0.49701, step = 9301 (140.548 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9395 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710077\n",
      "INFO:tensorflow:loss = 0.498935, step = 9401 (140.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711482\n",
      "INFO:tensorflow:loss = 0.440009, step = 9501 (140.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711421\n",
      "INFO:tensorflow:loss = 0.47145, step = 9601 (140.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711622\n",
      "INFO:tensorflow:loss = 0.440351, step = 9701 (140.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711531\n",
      "INFO:tensorflow:loss = 0.430697, step = 9801 (140.542 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9822 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710245\n",
      "INFO:tensorflow:loss = 0.400876, step = 9901 (140.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711583\n",
      "INFO:tensorflow:loss = 0.392895, step = 10001 (140.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711565\n",
      "INFO:tensorflow:loss = 0.496312, step = 10101 (140.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711527\n",
      "INFO:tensorflow:loss = 0.449239, step = 10201 (140.544 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10249 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710071\n",
      "INFO:tensorflow:loss = 0.383175, step = 10301 (140.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711466\n",
      "INFO:tensorflow:loss = 0.400688, step = 10401 (140.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71154\n",
      "INFO:tensorflow:loss = 0.427782, step = 10501 (140.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711644\n",
      "INFO:tensorflow:loss = 0.460515, step = 10601 (140.520 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10676 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710279\n",
      "INFO:tensorflow:loss = 0.4281, step = 10701 (140.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711771\n",
      "INFO:tensorflow:loss = 0.390073, step = 10801 (140.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711698\n",
      "INFO:tensorflow:loss = 0.351128, step = 10901 (140.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711508\n",
      "INFO:tensorflow:loss = 0.379299, step = 11001 (140.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711629\n",
      "INFO:tensorflow:loss = 0.389134, step = 11101 (140.522 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11103 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.71026\n",
      "INFO:tensorflow:loss = 0.327527, step = 11201 (140.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711714\n",
      "INFO:tensorflow:loss = 0.376691, step = 11301 (140.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711544\n",
      "INFO:tensorflow:loss = 0.39683, step = 11401 (140.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711531\n",
      "INFO:tensorflow:loss = 0.519856, step = 11501 (140.542 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11530 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710216\n",
      "INFO:tensorflow:loss = 0.393584, step = 11601 (140.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711323\n",
      "INFO:tensorflow:loss = 0.387184, step = 11701 (140.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711578\n",
      "INFO:tensorflow:loss = 0.395281, step = 11801 (140.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711565\n",
      "INFO:tensorflow:loss = 0.382049, step = 11901 (140.535 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11957 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710265\n",
      "INFO:tensorflow:loss = 0.440387, step = 12001 (140.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711728\n",
      "INFO:tensorflow:loss = 0.300175, step = 12101 (140.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711398\n",
      "INFO:tensorflow:loss = 0.440845, step = 12201 (140.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711414\n",
      "INFO:tensorflow:loss = 0.425121, step = 12301 (140.564 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12384 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710151\n",
      "INFO:tensorflow:loss = 0.418687, step = 12401 (140.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711544\n",
      "INFO:tensorflow:loss = 0.494147, step = 12501 (140.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711409\n",
      "INFO:tensorflow:loss = 0.367892, step = 12601 (140.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711358\n",
      "INFO:tensorflow:loss = 0.375902, step = 12701 (140.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711457\n",
      "INFO:tensorflow:loss = 0.376503, step = 12801 (140.556 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12811 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710004\n",
      "INFO:tensorflow:loss = 0.391355, step = 12901 (140.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711371\n",
      "INFO:tensorflow:loss = 0.407059, step = 13001 (140.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711456\n",
      "INFO:tensorflow:loss = 0.386425, step = 13101 (140.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711498\n",
      "INFO:tensorflow:loss = 0.373175, step = 13201 (140.549 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13238 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710061\n",
      "INFO:tensorflow:loss = 0.375915, step = 13301 (140.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711457\n",
      "INFO:tensorflow:loss = 0.345417, step = 13401 (140.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711511\n",
      "INFO:tensorflow:loss = 0.461014, step = 13501 (140.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711421\n",
      "INFO:tensorflow:loss = 0.338167, step = 13601 (140.564 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13665 into ubuntu/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.709939\n",
      "INFO:tensorflow:loss = 0.302359, step = 13701 (140.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711511\n",
      "INFO:tensorflow:loss = 0.336253, step = 13801 (140.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711351\n",
      "INFO:tensorflow:loss = 0.402984, step = 13901 (140.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711398\n",
      "INFO:tensorflow:loss = 0.456657, step = 14001 (140.569 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14092 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710024\n",
      "INFO:tensorflow:loss = 0.420469, step = 14101 (140.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711363\n",
      "INFO:tensorflow:loss = 0.35533, step = 14201 (140.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711328\n",
      "INFO:tensorflow:loss = 0.298576, step = 14301 (140.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711243\n",
      "INFO:tensorflow:loss = 0.615326, step = 14401 (140.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711302\n",
      "INFO:tensorflow:loss = 0.479245, step = 14501 (140.588 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14519 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.710004\n",
      "INFO:tensorflow:loss = 0.425395, step = 14601 (140.844 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14666 into ubuntu/model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.380509.\n",
      "CPU times: user 5h 34min 4s, sys: 1h 7min 40s, total: 6h 41min 45s\n",
      "Wall time: 5h 43min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7efcca82f5c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# estimator.train(input_fn=input_fn_train, steps=1001)\n",
    "estimator.train(input_fn=input_fn_train, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-24-22:34:13\n",
      "INFO:tensorflow:Restoring parameters from ubuntu/model/model.ckpt-14666\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-24-22:45:56\n",
      "INFO:tensorflow:Saving dict for global step 14666: global_step = 14666, loss = 0.446515\n",
      "CPU times: user 20min 28s, sys: 1min 40s, total: 22min 8s\n",
      "Wall time: 11min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'global_step': 14666, 'loss': 0.44651476}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimator.evaluate(input_fn=input_fn_valid, steps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-gpu-1.2)",
   "language": "python",
   "name": "tensorflow-gpu-1.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
