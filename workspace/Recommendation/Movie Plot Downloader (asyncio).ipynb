{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline started...\n",
      "Fail Sink started...\n",
      "CSV Writer (filename=movielens/ml-latest-small/plots2.csv) started...\n",
      "Request worker 1 started...\n",
      "Request worker 2 started...\n",
      "Request worker 3 started...\n",
      "Request worker 4 started...\n",
      "Request worker 5 started...\n",
      "Request producer started...\n",
      "Requests... 1,000\n",
      "CSV rows... 1,000\n",
      "Requests... 2,000\n",
      "CSV rows... 2,000\n",
      "Requests... 3,000\n",
      "CSV rows... 3,000\n",
      "Requests... 4,000\n",
      "CSV rows... 4,000\n",
      "Requests... 5,000\n",
      "CSV rows... 5,000\n",
      "Requests... 6,000\n",
      "CSV rows... 6,000\n",
      "Requests... 7,000\n",
      "CSV rows... 7,000\n",
      "Requests... 8,000\n",
      "CSV rows... 8,000\n",
      "Requests... 9,000\n",
      "CSV rows... 9,000\n",
      "Request producer done!\n",
      "Request worker 2 done! 1,838 requests, 3 retries, 0 fails\n",
      "Fail sink done! 0 fails\n",
      "Request worker 1 done! 1,813 requests, 2 retries, 0 fails\n",
      "Request worker 3 done! 1,790 requests, 2 retries, 0 fails\n",
      "Request worker 4 done! 1,861 requests, 0 retries, 0 fails\n",
      "Request worker 5 done! 1,823 requests, 1 retries, 0 fails\n",
      "CSV Writer done! 9,125 rows\n",
      "Pipeline done!\n",
      "0\n",
      "0\n",
      "0\n",
      "CPU times: user 1min 14s, sys: 1.89 s, total: 1min 15s\n",
      "Wall time: 9min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import asyncio\n",
    "import collections\n",
    "import csv\n",
    "import functools\n",
    "import requests\n",
    "\n",
    "LINKS_CSV = 'movielens/ml-latest-small/links.csv'\n",
    "#PLOTS_CSV = 'movielens/ml-latest-small/plots.csv'\n",
    "PLOTS_CSV = 'movielens/ml-latest-small/plots2.csv'\n",
    "\n",
    "MOVIE_DATA_URL = 'http://www.omdbapi.com'\n",
    "\n",
    "MovieRequest = collections.namedtuple('MovieRequest', ['movie_id', 'imdb_id', 'tries'])\n",
    "MovieData = collections.namedtuple('MovieData', ['movie_id', 'plot'])\n",
    "\n",
    "request_queue = asyncio.Queue(100)\n",
    "fail_queue = asyncio.Queue(100)\n",
    "data_queue = asyncio.Queue(100)\n",
    "\n",
    "pipeline_active = asyncio.Event()\n",
    "producer_done = asyncio.Event()\n",
    "\n",
    "async def pipeline():\n",
    "    print('Pipeline started...')\n",
    "    pipeline_active.set()\n",
    "    await asyncio.sleep(2)\n",
    "    await producer_done.wait()\n",
    "    await request_queue.join()\n",
    "    await fail_queue.join()\n",
    "    await data_queue.join()\n",
    "    pipeline_active.clear()\n",
    "    await asyncio.sleep(2)\n",
    "    print('Pipeline done!')\n",
    "\n",
    "\n",
    "async def request_producer(filename, request_queue):\n",
    "    await pipeline_active.wait()\n",
    "    print('Request producer started...')\n",
    "    N = 3 * request_queue.maxsize // 4\n",
    "    with open(filename, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) # skip header\n",
    "        for n, (movie_id, imdb_id, tmdb_id) in enumerate(reader):\n",
    "            while request_queue.qsize() > N:\n",
    "                await asyncio.sleep(2)\n",
    "            await request_queue.put(MovieRequest(movie_id, imdb_id, 0))\n",
    "            if (n+1) % 1000 == 0:\n",
    "                print('Requests... {:,d}'.format(n+1))\n",
    "    producer_done.set()\n",
    "    print('Request producer done!')\n",
    "\n",
    "\n",
    "s = requests.Session()\n",
    "adapter = requests.adapters.HTTPAdapter(pool_connections=20, pool_maxsize=20, max_retries=3)\n",
    "s.mount(MOVIE_DATA_URL, adapter)\n",
    "s.params['plot'] = 'full'\n",
    "\n",
    "def load_movie_data(imdb_id, timeout=5):\n",
    "    r = s.get(MOVIE_DATA_URL, params={'i': 'tt' + imdb_id}, timeout=timeout)\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "async def request_worker(name, loop, request_queue, data_queue, fail_queue, retries=3):\n",
    "    await pipeline_active.wait()\n",
    "    print('Request worker {} started...'.format(name))\n",
    "    n, t, f = 0, 0, 0\n",
    "    while pipeline_active.is_set():\n",
    "        try:\n",
    "            req = await asyncio.wait_for(request_queue.get(), 1)\n",
    "        except asyncio.TimeoutError:\n",
    "            #print('Request worker {} timeout...'.format(name))\n",
    "            continue\n",
    "        try:\n",
    "            data = await loop.run_in_executor(None, functools.partial(load_movie_data, req.imdb_id))\n",
    "            n += 1\n",
    "            await data_queue.put(MovieData(req.movie_id, data[\"Plot\"]))\n",
    "        except Exception as e:\n",
    "            #print('Request worker {} fail...'.format(name))\n",
    "            #print(e)\n",
    "            if req.tries < retries:\n",
    "                t += 1\n",
    "                await request_queue.put(req._replace(tries=req.tries+1))\n",
    "            else:\n",
    "                f += 1\n",
    "                await fail_queue.put(req)\n",
    "        request_queue.task_done()\n",
    "    print('Request worker {} done! {:,d} requests, {:,d} retries, {:,d} fails'.format(name, n, t, f))\n",
    "\n",
    "\n",
    "async def csv_writer(filename, data_queue):\n",
    "    await pipeline_active.wait()\n",
    "    print('CSV Writer (filename={}) started...'.format(filename))\n",
    "    n = 0\n",
    "    with open(filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['movieId', 'plot'])\n",
    "\n",
    "        while pipeline_active.is_set():\n",
    "            try:\n",
    "                data = await asyncio.wait_for(data_queue.get(), 1)\n",
    "            except asyncio.TimeoutError:\n",
    "                #print('CSV Plot timeout...')\n",
    "                continue\n",
    "            movie_id, movie_plot = data\n",
    "            writer.writerow([movie_id, movie_plot])\n",
    "            n += 1\n",
    "            data_queue.task_done()\n",
    "            \n",
    "            if n % 1000 == 0:\n",
    "                print('CSV rows... {:,d}'.format(n))\n",
    "\n",
    "    print('CSV Writer done! {:,d} rows'.format(n))\n",
    "\n",
    "\n",
    "async def fail_sink(fail_queue):\n",
    "    await pipeline_active.wait()\n",
    "    print('Fail Sink started...')\n",
    "    n = 0\n",
    "    while pipeline_active.is_set():\n",
    "        try:\n",
    "            fail = await asyncio.wait_for(fail_queue.get(), 1)\n",
    "        except asyncio.TimeoutError:\n",
    "            #print('Fail Sink timeout...')\n",
    "            continue\n",
    "        n += 1\n",
    "        if n <= 100:\n",
    "            print('Lost: {}'.format(fail))\n",
    "        if n % 1000 == 0:\n",
    "            print('Lost: {:,d}'.format(n))\n",
    "        fail_queue.task_done()\n",
    "    print('Fail sink done! {:,d} fails'.format(n))\n",
    "\n",
    "    \n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "loop.create_task(fail_sink(fail_queue))\n",
    "\n",
    "loop.create_task(csv_writer(PLOTS_CSV, data_queue))\n",
    "\n",
    "for i in range(5):\n",
    "    loop.create_task(request_worker(str(i+1), loop, request_queue, data_queue, fail_queue))\n",
    "\n",
    "loop.create_task(request_producer(LINKS_CSV, request_queue))\n",
    "\n",
    "t = loop.create_task(pipeline())\n",
    "\n",
    "loop.run_until_complete(t)\n",
    "\n",
    "print(request_queue.qsize())\n",
    "print(fail_queue.qsize())\n",
    "print(data_queue.qsize())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
