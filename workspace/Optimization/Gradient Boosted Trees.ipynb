{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.boosted_trees.estimator_batch.estimator import GradientBoostedDecisionTreeClassifier\n",
    "from tensorflow.contrib.boosted_trees.proto.learner_pb2 import LearnerConfig\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GradientBoostedDecisionTreeClassifier in module tensorflow.contrib.boosted_trees.estimator_batch.estimator:\n",
      "\n",
      "class GradientBoostedDecisionTreeClassifier(tensorflow.contrib.learn.python.learn.estimators.estimator.Estimator)\n",
      " |  An estimator using gradient boosted decision trees.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GradientBoostedDecisionTreeClassifier\n",
      " |      tensorflow.contrib.learn.python.learn.estimators.estimator.Estimator\n",
      " |      tensorflow.contrib.learn.python.learn.estimators.estimator.BaseEstimator\n",
      " |      tensorflow.contrib.learn.python.learn.estimators._sklearn._BaseEstimator\n",
      " |      tensorflow.contrib.learn.python.learn.evaluable.Evaluable\n",
      " |      tensorflow.contrib.learn.python.learn.trainable.Trainable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, learner_config, examples_per_layer, n_classes=2, num_trees=None, feature_columns=None, weight_column_name=None, model_dir=None, config=None, label_keys=None, feature_engineering_fn=None, logits_modifier_function=None, center_bias=True)\n",
      " |      Initializes a GradientBoostedDecisionTreeClassifier estimator instance.\n",
      " |      \n",
      " |      Args:\n",
      " |        learner_config: A config for the learner.\n",
      " |        examples_per_layer: Number of examples to accumulate before growing a\n",
      " |          layer. It can also be a function that computes the number of examples\n",
      " |          based on the depth of the layer that's being built.\n",
      " |        n_classes: Number of classes in the classification.\n",
      " |        num_trees: An int, number of trees to build.\n",
      " |        feature_columns: A list of feature columns.\n",
      " |        weight_column_name: Name of the column for weights, or None if not\n",
      " |          weighted.\n",
      " |        model_dir: Directory for model exports, etc.\n",
      " |        config: `RunConfig` object to configure the runtime settings.\n",
      " |        label_keys: Optional list of strings with size `[n_classes]` defining the\n",
      " |          label vocabulary. Only supported for `n_classes` > 2.\n",
      " |        feature_engineering_fn: Feature engineering function. Takes features and\n",
      " |          labels which are the output of `input_fn` and returns features and\n",
      " |          labels which will be fed into the model.\n",
      " |        logits_modifier_function: A modifier function for the logits.\n",
      " |        center_bias: Whether a separate tree should be created for first fitting\n",
      " |          the bias.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If learner_config is not valid.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.contrib.learn.python.learn.estimators.estimator.Estimator:\n",
      " |  \n",
      " |  export_savedmodel(self, export_dir_base, serving_input_fn, default_output_alternative_key=None, assets_extra=None, as_text=False, checkpoint_path=None, graph_rewrite_specs=(GraphRewriteSpec(tags=('serve',), transforms=()),))\n",
      " |      Exports inference graph as a SavedModel into given dir.\n",
      " |      \n",
      " |      Args:\n",
      " |        export_dir_base: A string containing a directory to write the exported\n",
      " |          graph and checkpoints.\n",
      " |        serving_input_fn: A function that takes no argument and\n",
      " |          returns an `InputFnOps`.\n",
      " |        default_output_alternative_key: the name of the head to serve when none is\n",
      " |          specified.  Not needed for single-headed models.\n",
      " |        assets_extra: A dict specifying how to populate the assets.extra directory\n",
      " |          within the exported SavedModel.  Each key should give the destination\n",
      " |          path (including the filename) relative to the assets.extra directory.\n",
      " |          The corresponding value gives the full path of the source file to be\n",
      " |          copied.  For example, the simple case of copying a single file without\n",
      " |          renaming it is specified as\n",
      " |          `{'my_asset_file.txt': '/path/to/my_asset_file.txt'}`.\n",
      " |        as_text: whether to write the SavedModel proto in text format.\n",
      " |        checkpoint_path: The checkpoint path to export.  If None (the default),\n",
      " |          the most recent checkpoint found within the model directory is chosen.\n",
      " |        graph_rewrite_specs: an iterable of `GraphRewriteSpec`.  Each element will\n",
      " |          produce a separate MetaGraphDef within the exported SavedModel, tagged\n",
      " |          and rewritten as specified.  Defaults to a single entry using the\n",
      " |          default serving tag (\"serve\") and no rewriting.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The string path to the exported directory.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if an unrecognized export_type is requested.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.contrib.learn.python.learn.estimators.estimator.BaseEstimator:\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, input_fn=None, feed_fn=None, batch_size=None, steps=None, metrics=None, name=None, checkpoint_path=None, hooks=None, log_progress=True)\n",
      " |      See `Evaluable`. (deprecated arguments)\n",
      " |      \n",
      " |      SOME ARGUMENTS ARE DEPRECATED. They will be removed after 2016-12-01.\n",
      " |      Instructions for updating:\n",
      " |      Estimator is decoupled from Scikit Learn interface by moving into\n",
      " |      separate class SKCompat. Arguments x, y and batch_size are only\n",
      " |      available in the SKCompat class, Estimator will only accept input_fn.\n",
      " |      Example conversion:\n",
      " |        est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If at least one of `x` or `y` is provided, and at least one of\n",
      " |            `input_fn` or `feed_fn` is provided.\n",
      " |            Or if `metrics` is not `None` or `dict`.\n",
      " |  \n",
      " |  export(self, export_dir, input_fn=<function _default_input_fn at 0x7fa2d5f8bea0>, input_feature_key=None, use_deprecated_input_fn=True, signature_fn=None, prediction_key=None, default_batch_size=1, exports_to_keep=None, checkpoint_path=None)\n",
      " |      Exports inference graph into given dir. (deprecated)\n",
      " |      \n",
      " |      THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-25.\n",
      " |      Instructions for updating:\n",
      " |      Please use Estimator.export_savedmodel() instead.\n",
      " |      \n",
      " |      Args:\n",
      " |        export_dir: A string containing a directory to write the exported graph\n",
      " |          and checkpoints.\n",
      " |        input_fn: If `use_deprecated_input_fn` is true, then a function that given\n",
      " |          `Tensor` of `Example` strings, parses it into features that are then\n",
      " |          passed to the model. Otherwise, a function that takes no argument and\n",
      " |          returns a tuple of (features, labels), where features is a dict of\n",
      " |          string key to `Tensor` and labels is a `Tensor` that's currently not\n",
      " |          used (and so can be `None`).\n",
      " |        input_feature_key: Only used if `use_deprecated_input_fn` is false. String\n",
      " |          key into the features dict returned by `input_fn` that corresponds to a\n",
      " |          the raw `Example` strings `Tensor` that the exported model will take as\n",
      " |          input. Can only be `None` if you're using a custom `signature_fn` that\n",
      " |          does not use the first arg (examples).\n",
      " |        use_deprecated_input_fn: Determines the signature format of `input_fn`.\n",
      " |        signature_fn: Function that returns a default signature and a named\n",
      " |          signature map, given `Tensor` of `Example` strings, `dict` of `Tensor`s\n",
      " |          for features and `Tensor` or `dict` of `Tensor`s for predictions.\n",
      " |        prediction_key: The key for a tensor in the `predictions` dict (output\n",
      " |          from the `model_fn`) to use as the `predictions` input to the\n",
      " |          `signature_fn`. Optional. If `None`, predictions will pass to\n",
      " |          `signature_fn` without filtering.\n",
      " |        default_batch_size: Default batch size of the `Example` placeholder.\n",
      " |        exports_to_keep: Number of exports to keep.\n",
      " |        checkpoint_path: the checkpoint path of the model to be exported. If it is\n",
      " |            `None` (which is default), will use the latest checkpoint in\n",
      " |            export_dir.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The string path to the exported directory. NB: this functionality was\n",
      " |        added ca. 2016/09/25; clients that depend on the return value may need\n",
      " |        to handle the case where this function returns None because subclasses\n",
      " |        are not returning a value.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, input_fn=None, steps=None, batch_size=None, monitors=None, max_steps=None)\n",
      " |      See `Trainable`. (deprecated arguments)\n",
      " |      \n",
      " |      SOME ARGUMENTS ARE DEPRECATED. They will be removed after 2016-12-01.\n",
      " |      Instructions for updating:\n",
      " |      Estimator is decoupled from Scikit Learn interface by moving into\n",
      " |      separate class SKCompat. Arguments x, y and batch_size are only\n",
      " |      available in the SKCompat class, Estimator will only accept input_fn.\n",
      " |      Example conversion:\n",
      " |        est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `x` or `y` are not `None` while `input_fn` is not `None`.\n",
      " |        ValueError: If both `steps` and `max_steps` are not `None`.\n",
      " |  \n",
      " |  get_variable_names(self)\n",
      " |      Returns list of all variable names in this model.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of names.\n",
      " |  \n",
      " |  get_variable_value(self, name)\n",
      " |      Returns value of the variable given by name.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: string, name of the tensor.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Numpy array - value of the tensor.\n",
      " |  \n",
      " |  partial_fit(self, x=None, y=None, input_fn=None, steps=1, batch_size=None, monitors=None)\n",
      " |      Incremental fit on a batch of samples. (deprecated arguments)\n",
      " |      \n",
      " |      SOME ARGUMENTS ARE DEPRECATED. They will be removed after 2016-12-01.\n",
      " |      Instructions for updating:\n",
      " |      Estimator is decoupled from Scikit Learn interface by moving into\n",
      " |      separate class SKCompat. Arguments x, y and batch_size are only\n",
      " |      available in the SKCompat class, Estimator will only accept input_fn.\n",
      " |      Example conversion:\n",
      " |        est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      " |      \n",
      " |      This method is expected to be called several times consecutively\n",
      " |      on different or the same chunks of the dataset. This either can\n",
      " |      implement iterative training or out-of-core/online training.\n",
      " |      \n",
      " |      This is especially useful when the whole dataset is too big to\n",
      " |      fit in memory at the same time. Or when model is taking long time\n",
      " |      to converge, and you want to split up training into subparts.\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Matrix of shape [n_samples, n_features...]. Can be iterator that\n",
      " |           returns arrays of features. The training input samples for fitting the\n",
      " |           model. If set, `input_fn` must be `None`.\n",
      " |        y: Vector or matrix [n_samples] or [n_samples, n_outputs]. Can be\n",
      " |           iterator that returns array of labels. The training label values\n",
      " |           (class labels in classification, real numbers in regression). If set,\n",
      " |           `input_fn` must be `None`.\n",
      " |        input_fn: Input function. If set, `x`, `y`, and `batch_size` must be\n",
      " |          `None`.\n",
      " |        steps: Number of steps for which to train model. If `None`, train forever.\n",
      " |        batch_size: minibatch size to use on the input, defaults to first\n",
      " |          dimension of `x`. Must be `None` if `input_fn` is provided.\n",
      " |        monitors: List of `BaseMonitor` subclass instances. Used for callbacks\n",
      " |          inside the training loop.\n",
      " |      \n",
      " |      Returns:\n",
      " |        `self`, for chaining.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If at least one of `x` and `y` is provided, and `input_fn` is\n",
      " |            provided.\n",
      " |  \n",
      " |  predict(self, x=None, input_fn=None, batch_size=None, outputs=None, as_iterable=True)\n",
      " |      Returns predictions for given features. (deprecated arguments)\n",
      " |      \n",
      " |      SOME ARGUMENTS ARE DEPRECATED. They will be removed after 2016-12-01.\n",
      " |      Instructions for updating:\n",
      " |      Estimator is decoupled from Scikit Learn interface by moving into\n",
      " |      separate class SKCompat. Arguments x, y and batch_size are only\n",
      " |      available in the SKCompat class, Estimator will only accept input_fn.\n",
      " |      Example conversion:\n",
      " |        est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Matrix of shape [n_samples, n_features...]. Can be iterator that\n",
      " |           returns arrays of features. The training input samples for fitting the\n",
      " |           model. If set, `input_fn` must be `None`.\n",
      " |        input_fn: Input function. If set, `x` and 'batch_size' must be `None`.\n",
      " |        batch_size: Override default batch size. If set, 'input_fn' must be\n",
      " |          'None'.\n",
      " |        outputs: list of `str`, name of the output to predict.\n",
      " |          If `None`, returns all.\n",
      " |        as_iterable: If True, return an iterable which keeps yielding predictions\n",
      " |          for each example until inputs are exhausted. Note: The inputs must\n",
      " |          terminate if you want the iterable to terminate (e.g. be sure to pass\n",
      " |          num_epochs=1 if you are using something like read_batch_features).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A numpy array of predicted classes or regression values if the\n",
      " |        constructor's `model_fn` returns a `Tensor` for `predictions` or a `dict`\n",
      " |        of numpy arrays if `model_fn` returns a `dict`. Returns an iterable of\n",
      " |        predictions if as_iterable is True.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If x and input_fn are both provided or both `None`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.contrib.learn.python.learn.estimators.estimator.BaseEstimator:\n",
      " |  \n",
      " |  config\n",
      " |  \n",
      " |  model_dir\n",
      " |      Returns a path in which the eval process will look for checkpoints.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from tensorflow.contrib.learn.python.learn.estimators.estimator.BaseEstimator:\n",
      " |  \n",
      " |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      " |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      " |      \n",
      " |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      " |      directly, and then acts as a mix-in class.  You can also register\n",
      " |      unrelated concrete classes (even built-in classes) and unrelated\n",
      " |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      " |      be considered subclasses of the registering ABC by the built-in\n",
      " |      issubclass() function, but the registering ABC won't show up in\n",
      " |      their MRO (Method Resolution Order) nor will method\n",
      " |      implementations defined by the registering ABC be callable (not\n",
      " |      even via super()).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.contrib.learn.python.learn.estimators._sklearn._BaseEstimator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Args:\n",
      " |        deep: boolean, optional\n",
      " |      \n",
      " |          If `True`, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns:\n",
      " |        params : mapping of string to any\n",
      " |        Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The former have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Args:\n",
      " |        **params: Parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |        self\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If params contain invalid names.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.contrib.learn.python.learn.estimators._sklearn._BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GradientBoostedDecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(dataset_split,\n",
    "             batch_size,\n",
    "             capacity=10000,\n",
    "             min_after_dequeue=3000):\n",
    "\n",
    "    images_batch, labels_batch = tf.train.shuffle_batch(\n",
    "        tensors=[dataset_split.images,\n",
    "                 dataset_split.labels.astype(np.int32)],\n",
    "        batch_size=batch_size,\n",
    "        capacity=capacity,\n",
    "        min_after_dequeue=min_after_dequeue,\n",
    "        enqueue_many=True,\n",
    "        num_threads=4)\n",
    "    features_map = {\"images\": images_batch}\n",
    "    return features_map, labels_batch\n",
    "\n",
    "def gbt_classifier(output_dir,\n",
    "                   learning_rate,\n",
    "                   num_classes,\n",
    "                   regularization_l1,\n",
    "                   regularization_l2,\n",
    "                   max_tree_depth,\n",
    "                   examples_per_layer,\n",
    "                   num_trees):\n",
    "\n",
    "    learner_config = LearnerConfig()\n",
    "\n",
    "    learner_config.learning_rate_tuner.fixed.learning_rate = learning_rate\n",
    "    learner_config.num_classes = num_classes\n",
    "    learner_config.regularization.l1 = regularization_l1\n",
    "    learner_config.regularization.l2 = regularization_l2 / examples_per_layer\n",
    "    learner_config.constraints.max_tree_depth = max_tree_depth\n",
    "\n",
    "    run_config = tf.contrib.learn.RunConfig(save_checkpoints_secs=300)\n",
    "\n",
    "    # Create a TF Boosted trees estimator that can take in custom loss.\n",
    "    return GradientBoostedDecisionTreeClassifier(\n",
    "        learner_config=learner_config,\n",
    "        n_classes=num_classes,\n",
    "        examples_per_layer=examples_per_layer,\n",
    "        model_dir=output_dir,\n",
    "        num_trees=num_trees,\n",
    "        center_bias=False,\n",
    "        config=run_config)\n",
    "\n",
    "\n",
    "def gbt_mnist(output_dir,\n",
    "              train_batch_size,\n",
    "              eval_batch_size,\n",
    "              num_eval_steps,\n",
    "              gbt_params):\n",
    "\n",
    "    data = tf.contrib.learn.datasets.mnist.load_mnist()\n",
    "    train_input_fn = lambda: input_fn(data.train, train_batch_size)\n",
    "    eval_input_fn = lambda: input_fn(data.validation, eval_batch_size)\n",
    "\n",
    "    return tf.contrib.learn.Experiment(\n",
    "        estimator=gbt_classifier(output_dir, **gbt_params),\n",
    "        train_input_fn=train_input_fn,\n",
    "        eval_input_fn=eval_input_fn,\n",
    "        train_steps=None,\n",
    "        eval_steps=num_eval_steps,\n",
    "        eval_metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa2d48d4e48>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 300, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'gbt_minist'}\n",
      "WARNING:tensorflow:From /home/cavani/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-25f94527387e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mexperiment_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gbt_minist'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     schedule=\"train_and_evaluate\")\n\u001b[0m",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(experiment_fn, output_dir, schedule, run_config, hparams)\u001b[0m\n\u001b[1;32m    216\u001b[0m   \u001b[0mschedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_default_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_execute_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\u001b[0m in \u001b[0;36m_execute_schedule\u001b[0;34m(experiment, schedule)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Allowed values for this experiment are: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Schedule references non-callable member %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m                   hooks=self._eval_hooks)\n\u001b[1;32m    624\u001b[0m           ]\n\u001b[0;32m--> 625\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;31m# If the checkpoint_and_export flag and appropriate estimator configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, delay_secs)\u001b[0m\n\u001b[1;32m    365\u001b[0m     return self._call_train(input_fn=self._train_input_fn,\n\u001b[1;32m    366\u001b[0m                             \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                             hooks=self._train_monitors + extra_hooks)\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36m_call_train\u001b[0;34m(self, _sentinel, input_fn, steps, hooks, max_steps)\u001b[0m\n\u001b[1;32m    810\u001b[0m                                  \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                                  \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m                                  monitors=hooks)\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m   def _call_evaluate(self, _sentinel=None,  # pylint: disable=invalid-name,\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 instructions)\n\u001b[0;32m--> 316\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    318\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    478\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mglobal_step_read_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_or_create_global_step_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step_read_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m         \u001b[0mmodel_fn_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOSSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0mall_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_get_train_ops\u001b[0;34m(self, features, labels)\u001b[0m\n\u001b[1;32m   1200\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mModelFnOps\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \"\"\"\n\u001b[0;32m-> 1202\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_eval_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, metrics)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'model_dir'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_dir'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelFnOps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/boosted_trees/estimator_batch/model.py\u001b[0m in \u001b[0;36mmodel_builder\u001b[0;34m(features, labels, mode, params, config)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m       \u001b[0mlogits_dimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_dimension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       features=features)\n\u001b[0m\u001b[1;32m     97\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gbdt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gbdt_optimizer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mpredictions_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbdt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/boosted_trees/python/training/functions/gbdt_batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, is_chief, num_ps_replicas, ensemble_handle, center_bias, examples_per_layer, learner_config, features, logits_dimension, feature_columns)\u001b[0m\n\u001b[1;32m    330\u001b[0m     (fc_names, dense_floats, sparse_float_indices, sparse_float_values,\n\u001b[1;32m    331\u001b[0m      \u001b[0msparse_float_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_int_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_int_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m      sparse_int_shapes) = extract_features(features, self._feature_columns)\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Active Feature Columns: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fc_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/tensorflow-jupyter/software/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/contrib/boosted_trees/python/training/functions/gbdt_batch.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(features, feature_columns)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m           \u001b[0munstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munstacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mdense_float_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_FEATURE_NAME_TEMPLATE\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mdense_floats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munstacked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "gbt_params = dict(\n",
    "    learning_rate=0.1,\n",
    "    num_classes=10,\n",
    "    regularization_l1=0.,\n",
    "    regularization_l2=1.,\n",
    "    max_tree_depth=4,\n",
    "    examples_per_layer=1000,\n",
    "    num_trees=10,\n",
    ")\n",
    "\n",
    "experiment_fn = lambda output_dir: gbt_mnist(output_dir,\n",
    "                                             train_batch_size=1000,\n",
    "                                             eval_batch_size=1000,\n",
    "                                             num_eval_steps=1,\n",
    "                                             gbt_params=gbt_params)\n",
    "\n",
    "learn_runner.run(\n",
    "    experiment_fn=experiment_fn,\n",
    "    output_dir='gbt_minist',\n",
    "    schedule=\"train_and_evaluate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow-cpu)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
